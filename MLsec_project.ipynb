{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelboi/MLsec_project/blob/main/MLsec_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models:\n",
        "1. Fixing Data Augmentation to Improve Adversarial Robustness\n",
        "2. Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?\n",
        "3. MMA Training: Direct Input Space Margin Maximization through Adversarial Training"
      ],
      "metadata": {
        "id": "CcZOaHCtHRqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General imports"
      ],
      "metadata": {
        "id": "CHr8lWVj_FFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CzCcoczZsmbn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Various\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import importlib.util\n",
        "import re\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# RobustBench\n",
        "!pip install git+https://github.com/manuelboi/robustbench\n",
        "from robustbench.utils import load_model\n",
        "from robustbench.eval import benchmark\n",
        "from robustbench.data import load_cifar10\n",
        "from robustbench.model_zoo.enums import ThreatModel\n",
        "\n",
        "# Smoothing\n",
        "!git clone https://github.com/matteoturnu/smoothing.git\n",
        "!conda create -n smoothing\n",
        "!conda activate smoothing\n",
        "!conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n",
        "!conda install scipy pandas statsmodels matplotlib seaborn\n",
        "!pip install setGPU\n",
        "from smoothing.code.core import Smooth\n",
        "from smoothing.code.train import train, test\n",
        "from smoothing.code.train_utils import AverageMeter, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "bRZkGSpiPFiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "labels_dct = {0: \"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}\n",
        "# use GPU if available, otherwise use CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Computing device used: \", device)\n",
        "\n",
        "# Preparing trainset and testset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "n_test_samples_benchmark = 100\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Define the number of samples you want to take\n",
        "num_samples = 1000\n",
        "# Create a subset of the dataset\n",
        "indices = list(range(num_samples))\n",
        "train_subset = Subset(trainset, indices)\n",
        "test_subset = Subset(testset, indices)\n",
        "\n",
        "# Preparing trainloader and testloader\n",
        "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "'''\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "'''\n",
        "\n",
        "# Load test samples for predict and certify\n",
        "x_test, y_test = load_cifar10(n_test_samples_benchmark)\n",
        "x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "# Setting various parameters\n",
        "epochs = 3 # used for training\n",
        "sigma = 0.5 # gaussian noise standard deviation\n",
        "n_examples = 20 # to be perturbed by AutoAttack\n",
        "eps_L2 = 0.5 # epsilon of the perturbancy for L2 norm\n",
        "eps_Linf = 8/255 # epsilon of the perturbancy with Linf norm\n",
        "version = 'custom'\n",
        "attacks_to_run=['apgd-ce', 'apgd-dlr'] # Attacks to run on the models"
      ],
      "metadata": {
        "id": "ur-xfxzJPEo3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "QwmN0U3EC3To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "Symqohu2KxSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(trainloader, testloader, model, epochs, sigma, device):\n",
        "  criterion = CrossEntropyLoss().to(device)\n",
        "  optimizer = SGD(model.parameters())\n",
        "  scheduler = StepLR(optimizer, step_size=30)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    scheduler.step(epoch)\n",
        "    before = time.time()\n",
        "    train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, sigma, device)\n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, sigma, device)\n",
        "    after = time.time()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cntdRl_hD0TB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smooth model performances on perturbed images"
      ],
      "metadata": {
        "id": "1w6B16vREnO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def certify(model, sigma, x_text, y_test, L):\n",
        "  n_classes = 10\n",
        "  alpha = 1 # (1 - alpha) is the confidence level (in this case is 0)\n",
        "  n0 = 10 # number of samples for selection\n",
        "  n = 20 # number of samples for estimation (certify) (too few samples but computation time is strongly affected with more)\n",
        "\n",
        "  smooth_model = Smooth(model, n_classes, sigma)\n",
        "\n",
        "  top_classes = list()\n",
        "  radiuses = list()\n",
        "  for x, y in zip(x_test, y_test):\n",
        "    top_class = smooth_model.predict(x, n0, alpha, batch_size=n0, device=device,)\n",
        "    top_class, radius = smooth_model.certify(x, n0, n, alpha, batch_size=n0, device=device, L=L)\n",
        "    top_classes.append(top_class)\n",
        "    radiuses.append(radius)\n",
        "\n",
        "  top_classes = torch.tensor(top_classes, dtype=torch.float64).to(device)\n",
        "  accuracy = torch.mean(top_classes == y_test, dtype=torch.float64)\n",
        "\n",
        "  print(\"Top classes: \", top_classes)\n",
        "  print(\"Y classes: \", y_test)\n",
        "  print(\"Accuracy on smooth model: \", accuracy)"
      ],
      "metadata": {
        "id": "tGu5x_t8EabV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing Data Augmentation to Improve Adversarial Robustness"
      ],
      "metadata": {
        "id": "RmnI2rBDeOEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "AvnvKSRLBp9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_L2 = load_model(model_name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='L2')\n",
        "model_1_L2 = model_1_L2.to(device)\n",
        "\n",
        "# Model training\n",
        "model_1_L2 = train_model(trainloader, testloader, model_1_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_1_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 1 with L2\n",
        "benchmark(model_1_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "TbLV6iYN_UuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9931817d-f149-4152-dac0-ad6c2afe3c2b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.823 (0.823)\tData 0.130 (0.130)\tLoss 0.4228 (0.4228)\tAcc@1 92.188 (92.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 2.014 (1.419)\tData 0.004 (0.067)\tLoss 0.5178 (0.4703)\tAcc@1 89.062 (90.625)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][2/16]\tTime 2.030 (1.622)\tData 0.003 (0.045)\tLoss 0.4912 (0.4773)\tAcc@1 89.062 (90.104)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 2.051 (1.729)\tData 0.003 (0.035)\tLoss 0.4701 (0.4755)\tAcc@1 92.188 (90.625)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][4/16]\tTime 2.060 (1.795)\tData 0.003 (0.028)\tLoss 0.4440 (0.4692)\tAcc@1 92.188 (90.938)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [0][5/16]\tTime 2.082 (1.843)\tData 0.010 (0.025)\tLoss 0.3478 (0.4489)\tAcc@1 93.750 (91.406)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][6/16]\tTime 2.102 (1.880)\tData 0.003 (0.022)\tLoss 0.5419 (0.4622)\tAcc@1 87.500 (90.848)\tAcc@5 98.438 (99.107)\n",
            "Epoch: [0][7/16]\tTime 2.111 (1.909)\tData 0.003 (0.020)\tLoss 0.4816 (0.4646)\tAcc@1 84.375 (90.039)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][8/16]\tTime 2.105 (1.931)\tData 0.003 (0.018)\tLoss 0.3910 (0.4565)\tAcc@1 92.188 (90.278)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [0][9/16]\tTime 2.103 (1.948)\tData 0.003 (0.016)\tLoss 0.4419 (0.4550)\tAcc@1 90.625 (90.312)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [0][10/16]\tTime 2.100 (1.962)\tData 0.003 (0.015)\tLoss 0.3782 (0.4480)\tAcc@1 92.188 (90.483)\tAcc@5 100.000 (99.432)\n",
            "Epoch: [0][11/16]\tTime 2.086 (1.972)\tData 0.010 (0.015)\tLoss 0.3704 (0.4416)\tAcc@1 95.312 (90.885)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][12/16]\tTime 2.074 (1.980)\tData 0.004 (0.014)\tLoss 0.2884 (0.4298)\tAcc@1 96.875 (91.346)\tAcc@5 100.000 (99.519)\n",
            "Epoch: [0][13/16]\tTime 2.052 (1.985)\tData 0.003 (0.013)\tLoss 0.3687 (0.4254)\tAcc@1 93.750 (91.518)\tAcc@5 98.438 (99.442)\n",
            "Epoch: [0][14/16]\tTime 2.035 (1.988)\tData 0.003 (0.012)\tLoss 0.4189 (0.4250)\tAcc@1 89.062 (91.354)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][15/16]\tTime 1.838 (1.979)\tData 0.003 (0.012)\tLoss 0.3798 (0.4232)\tAcc@1 92.500 (91.400)\tAcc@5 100.000 (99.500)\n",
            "Epoch: [0][0/16]\tTime 1.456 (1.456)\tData 0.116 (0.116)\tLoss 0.7211 (0.7211)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.619 (1.037)\tData 0.006 (0.061)\tLoss 0.5600 (0.6406)\tAcc@1 87.500 (81.250)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.619 (0.898)\tData 0.001 (0.041)\tLoss 0.5964 (0.6259)\tAcc@1 84.375 (82.292)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 0.629 (0.831)\tData 0.003 (0.031)\tLoss 0.7117 (0.6473)\tAcc@1 82.812 (82.422)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.617 (0.788)\tData 0.008 (0.027)\tLoss 0.7373 (0.6653)\tAcc@1 78.125 (81.562)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][5/16]\tTime 0.612 (0.759)\tData 0.003 (0.023)\tLoss 0.7366 (0.6772)\tAcc@1 78.125 (80.990)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][6/16]\tTime 0.622 (0.739)\tData 0.004 (0.020)\tLoss 0.6914 (0.6792)\tAcc@1 73.438 (79.911)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][7/16]\tTime 0.613 (0.723)\tData 0.017 (0.020)\tLoss 0.6147 (0.6712)\tAcc@1 85.938 (80.664)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][8/16]\tTime 0.616 (0.711)\tData 0.014 (0.019)\tLoss 0.5541 (0.6582)\tAcc@1 89.062 (81.597)\tAcc@5 100.000 (98.611)\n",
            "Epoch: [0][9/16]\tTime 0.608 (0.701)\tData 0.003 (0.018)\tLoss 0.6214 (0.6545)\tAcc@1 81.250 (81.562)\tAcc@5 100.000 (98.750)\n",
            "Epoch: [0][10/16]\tTime 0.606 (0.693)\tData 0.003 (0.016)\tLoss 0.8692 (0.6740)\tAcc@1 73.438 (80.824)\tAcc@5 96.875 (98.580)\n",
            "Epoch: [0][11/16]\tTime 0.614 (0.686)\tData 0.003 (0.015)\tLoss 0.5060 (0.6600)\tAcc@1 90.625 (81.641)\tAcc@5 98.438 (98.568)\n",
            "Epoch: [0][12/16]\tTime 0.615 (0.680)\tData 0.003 (0.014)\tLoss 0.7423 (0.6663)\tAcc@1 76.562 (81.250)\tAcc@5 100.000 (98.678)\n",
            "Epoch: [0][13/16]\tTime 0.609 (0.675)\tData 0.003 (0.013)\tLoss 0.6539 (0.6654)\tAcc@1 82.812 (81.362)\tAcc@5 100.000 (98.772)\n",
            "Epoch: [0][14/16]\tTime 0.606 (0.671)\tData 0.003 (0.013)\tLoss 0.5811 (0.6598)\tAcc@1 82.812 (81.458)\tAcc@5 100.000 (98.854)\n",
            "Epoch: [0][15/16]\tTime 0.452 (0.657)\tData 0.003 (0.012)\tLoss 0.5035 (0.6536)\tAcc@1 90.000 (81.800)\tAcc@5 100.000 (98.900)\n",
            "Epoch: [1][0/16]\tTime 0.788 (0.788)\tData 0.129 (0.129)\tLoss 0.2965 (0.2965)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 1.953 (1.370)\tData 0.003 (0.066)\tLoss 0.2625 (0.2795)\tAcc@1 96.875 (97.656)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][2/16]\tTime 1.936 (1.559)\tData 0.003 (0.045)\tLoss 0.3392 (0.2994)\tAcc@1 95.312 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][3/16]\tTime 1.922 (1.650)\tData 0.003 (0.035)\tLoss 0.3063 (0.3011)\tAcc@1 95.312 (96.484)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [1][4/16]\tTime 1.929 (1.706)\tData 0.016 (0.031)\tLoss 0.3744 (0.3158)\tAcc@1 93.750 (95.938)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 1.936 (1.744)\tData 0.003 (0.026)\tLoss 0.3506 (0.3216)\tAcc@1 92.188 (95.312)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 1.908 (1.767)\tData 0.003 (0.023)\tLoss 0.3300 (0.3228)\tAcc@1 96.875 (95.536)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 1.921 (1.787)\tData 0.003 (0.020)\tLoss 0.4453 (0.3381)\tAcc@1 95.312 (95.508)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [1][8/16]\tTime 1.918 (1.801)\tData 0.003 (0.018)\tLoss 0.2921 (0.3330)\tAcc@1 95.312 (95.486)\tAcc@5 100.000 (99.653)\n",
            "Epoch: [1][9/16]\tTime 1.921 (1.813)\tData 0.003 (0.017)\tLoss 0.2789 (0.3276)\tAcc@1 96.875 (95.625)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][10/16]\tTime 1.920 (1.823)\tData 0.003 (0.016)\tLoss 0.3692 (0.3314)\tAcc@1 93.750 (95.455)\tAcc@5 100.000 (99.716)\n",
            "Epoch: [1][11/16]\tTime 1.924 (1.831)\tData 0.009 (0.015)\tLoss 0.3386 (0.3320)\tAcc@1 95.312 (95.443)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][12/16]\tTime 1.922 (1.838)\tData 0.003 (0.014)\tLoss 0.3240 (0.3313)\tAcc@1 93.750 (95.312)\tAcc@5 100.000 (99.760)\n",
            "Epoch: [1][13/16]\tTime 1.923 (1.844)\tData 0.003 (0.013)\tLoss 0.4035 (0.3365)\tAcc@1 87.500 (94.754)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][14/16]\tTime 1.928 (1.850)\tData 0.003 (0.013)\tLoss 0.2979 (0.3339)\tAcc@1 96.875 (94.896)\tAcc@5 100.000 (99.792)\n",
            "Epoch: [1][15/16]\tTime 1.757 (1.844)\tData 0.003 (0.012)\tLoss 0.2852 (0.3320)\tAcc@1 95.000 (94.900)\tAcc@5 100.000 (99.800)\n",
            "Epoch: [1][0/16]\tTime 1.408 (1.408)\tData 0.113 (0.113)\tLoss 0.5715 (0.5715)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.604 (1.006)\tData 0.004 (0.058)\tLoss 0.5496 (0.5606)\tAcc@1 81.250 (82.812)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.603 (0.872)\tData 0.003 (0.040)\tLoss 0.4430 (0.5214)\tAcc@1 89.062 (84.896)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.605 (0.805)\tData 0.003 (0.031)\tLoss 0.5565 (0.5302)\tAcc@1 84.375 (84.766)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.593 (0.763)\tData 0.003 (0.025)\tLoss 0.5001 (0.5241)\tAcc@1 85.938 (85.000)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.604 (0.736)\tData 0.010 (0.023)\tLoss 0.6875 (0.5514)\tAcc@1 82.812 (84.635)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][6/16]\tTime 0.611 (0.718)\tData 0.003 (0.020)\tLoss 0.4274 (0.5337)\tAcc@1 90.625 (85.491)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [1][7/16]\tTime 0.601 (0.704)\tData 0.016 (0.019)\tLoss 0.4652 (0.5251)\tAcc@1 89.062 (85.938)\tAcc@5 100.000 (99.414)\n",
            "Epoch: [1][8/16]\tTime 0.615 (0.694)\tData 0.003 (0.018)\tLoss 0.4432 (0.5160)\tAcc@1 89.062 (86.285)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][9/16]\tTime 0.603 (0.685)\tData 0.012 (0.017)\tLoss 0.4672 (0.5111)\tAcc@1 85.938 (86.250)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [1][10/16]\tTime 0.608 (0.678)\tData 0.010 (0.016)\tLoss 0.7369 (0.5316)\tAcc@1 73.438 (85.085)\tAcc@5 98.438 (99.432)\n",
            "Epoch: [1][11/16]\tTime 0.613 (0.672)\tData 0.003 (0.015)\tLoss 0.5462 (0.5329)\tAcc@1 82.812 (84.896)\tAcc@5 98.438 (99.349)\n",
            "Epoch: [1][12/16]\tTime 0.600 (0.667)\tData 0.003 (0.014)\tLoss 0.4716 (0.5281)\tAcc@1 84.375 (84.856)\tAcc@5 100.000 (99.399)\n",
            "Epoch: [1][13/16]\tTime 0.618 (0.663)\tData 0.003 (0.014)\tLoss 0.4082 (0.5196)\tAcc@1 90.625 (85.268)\tAcc@5 100.000 (99.442)\n",
            "Epoch: [1][14/16]\tTime 0.606 (0.660)\tData 0.003 (0.013)\tLoss 0.4650 (0.5159)\tAcc@1 92.188 (85.729)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][15/16]\tTime 0.452 (0.647)\tData 0.003 (0.012)\tLoss 0.4397 (0.5129)\tAcc@1 90.000 (85.900)\tAcc@5 100.000 (99.500)\n",
            "Epoch: [2][0/16]\tTime 0.788 (0.788)\tData 0.124 (0.124)\tLoss 0.2596 (0.2596)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 1.970 (1.379)\tData 0.008 (0.066)\tLoss 0.3607 (0.3102)\tAcc@1 89.062 (92.969)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 1.979 (1.579)\tData 0.002 (0.045)\tLoss 0.2698 (0.2967)\tAcc@1 96.875 (94.271)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 1.984 (1.680)\tData 0.003 (0.034)\tLoss 0.3213 (0.3028)\tAcc@1 96.875 (94.922)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 1.989 (1.742)\tData 0.003 (0.028)\tLoss 0.2589 (0.2940)\tAcc@1 98.438 (95.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 1.990 (1.783)\tData 0.004 (0.024)\tLoss 0.2524 (0.2871)\tAcc@1 98.438 (96.094)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 2.004 (1.815)\tData 0.003 (0.021)\tLoss 0.2446 (0.2810)\tAcc@1 95.312 (95.982)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 2.006 (1.838)\tData 0.003 (0.019)\tLoss 0.3398 (0.2884)\tAcc@1 92.188 (95.508)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][8/16]\tTime 2.003 (1.857)\tData 0.003 (0.017)\tLoss 0.2216 (0.2810)\tAcc@1 98.438 (95.833)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][9/16]\tTime 2.005 (1.872)\tData 0.003 (0.015)\tLoss 0.2293 (0.2758)\tAcc@1 95.312 (95.781)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][10/16]\tTime 2.004 (1.884)\tData 0.003 (0.014)\tLoss 0.3340 (0.2811)\tAcc@1 93.750 (95.597)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][11/16]\tTime 2.009 (1.894)\tData 0.005 (0.014)\tLoss 0.3329 (0.2854)\tAcc@1 95.312 (95.573)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][12/16]\tTime 1.996 (1.902)\tData 0.003 (0.013)\tLoss 0.2582 (0.2833)\tAcc@1 95.312 (95.553)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][13/16]\tTime 2.007 (1.909)\tData 0.002 (0.012)\tLoss 0.2660 (0.2821)\tAcc@1 93.750 (95.424)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][14/16]\tTime 1.997 (1.915)\tData 0.003 (0.011)\tLoss 0.2699 (0.2813)\tAcc@1 98.438 (95.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][15/16]\tTime 1.819 (1.909)\tData 0.003 (0.011)\tLoss 0.2802 (0.2812)\tAcc@1 97.500 (95.700)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][0/16]\tTime 1.455 (1.455)\tData 0.127 (0.127)\tLoss 0.5779 (0.5779)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.624 (1.039)\tData 0.005 (0.066)\tLoss 0.4125 (0.4952)\tAcc@1 89.062 (85.156)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.617 (0.899)\tData 0.002 (0.045)\tLoss 0.4648 (0.4851)\tAcc@1 89.062 (86.458)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.622 (0.830)\tData 0.013 (0.037)\tLoss 0.5398 (0.4987)\tAcc@1 82.812 (85.547)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [2][4/16]\tTime 0.613 (0.786)\tData 0.003 (0.030)\tLoss 0.4918 (0.4974)\tAcc@1 85.938 (85.625)\tAcc@5 98.438 (99.375)\n",
            "Epoch: [2][5/16]\tTime 0.617 (0.758)\tData 0.003 (0.026)\tLoss 0.5670 (0.5090)\tAcc@1 85.938 (85.677)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][6/16]\tTime 0.617 (0.738)\tData 0.003 (0.022)\tLoss 0.3684 (0.4889)\tAcc@1 89.062 (86.161)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [2][7/16]\tTime 0.621 (0.723)\tData 0.004 (0.020)\tLoss 0.4510 (0.4841)\tAcc@1 89.062 (86.523)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][8/16]\tTime 0.622 (0.712)\tData 0.014 (0.019)\tLoss 0.3699 (0.4714)\tAcc@1 89.062 (86.806)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [2][9/16]\tTime 0.614 (0.702)\tData 0.007 (0.018)\tLoss 0.3483 (0.4591)\tAcc@1 96.875 (87.812)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][10/16]\tTime 0.608 (0.694)\tData 0.003 (0.017)\tLoss 0.5946 (0.4714)\tAcc@1 78.125 (86.932)\tAcc@5 98.438 (99.290)\n",
            "Epoch: [2][11/16]\tTime 0.619 (0.688)\tData 0.003 (0.016)\tLoss 0.4451 (0.4692)\tAcc@1 87.500 (86.979)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][12/16]\tTime 0.614 (0.682)\tData 0.003 (0.015)\tLoss 0.4931 (0.4711)\tAcc@1 89.062 (87.139)\tAcc@5 100.000 (99.279)\n",
            "Epoch: [2][13/16]\tTime 0.621 (0.678)\tData 0.003 (0.014)\tLoss 0.4034 (0.4662)\tAcc@1 90.625 (87.388)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [2][14/16]\tTime 0.613 (0.673)\tData 0.003 (0.013)\tLoss 0.4151 (0.4628)\tAcc@1 84.375 (87.188)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][15/16]\tTime 0.459 (0.660)\tData 0.003 (0.013)\tLoss 0.5287 (0.4655)\tAcc@1 80.000 (86.900)\tAcc@5 97.500 (99.300)\n",
            "Top classes:  tensor([3., 0., 0., 0., 4., 4., 3., 4., 4., 9., 0., 9., 4., 7., 9., 8., 3., 7.,\n",
            "        8., 6., 7., 2., 4., 9., 4., 4., 4., 0., 9., 4., 6., 4., 4., 3., 9., 3.,\n",
            "        4., 9., 9., 4., 0., 4., 3., 4., 4., 9., 3., 3., 4., 4., 9., 4., 3., 4.,\n",
            "        8., 4., 7., 7., 3., 4., 4., 4., 4., 9., 6., 4., 0., 2., 3., 7., 4., 4.,\n",
            "        8., 8., 0., 4., 0., 3., 3., 8., 4., 9., 0., 7., 2., 4., 0., 3., 8., 0.,\n",
            "        0., 4., 8., 6., 4., 3., 4., 4., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4600, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 60.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
            "    sys.settrace(tracefunc)\n",
            "\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy: 60.00%\n",
            "apgd-ce - 1/1 - 4 out of 12 successfully perturbed\n",
            "robust accuracy after APGD-CE: 40.00% (total time 181.4 s)\n",
            "apgd-dlr - 1/1 - 0 out of 8 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 40.00% (total time 358.4 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 40.00%\n",
            "Adversarial accuracy: 40.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6, 0.4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n6gPMiYKByXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_Linf = load_model(model_name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='Linf')\n",
        "model_1_Linf = model_1_Linf.to(device)\n",
        "\n",
        "# Model training\n",
        "model_1_Linf = train_model(trainloader, testloader, model_1_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_1_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 1 with Linf\n",
        "benchmark(model_1_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "rA09MQ0lZ34c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?"
      ],
      "metadata": {
        "id": "mtma9ehWeKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "qSW7z1l1Iten"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_L2 = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='L2')\n",
        "model_2_L2 = model_2_L2.to(device)\n",
        "\n",
        "# Model training\n",
        "model_2_L2 = train_model(trainloader, testloader, model_2_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_2_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 2 with L2\n",
        "benchmark(model_2_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "hOl_1rinc4IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "fajFJ2DaI5x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_Linf = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='Linf')\n",
        "model_2_Linf = model_2_Linf.to(device)\n",
        "\n",
        "# Model training\n",
        "model_2_Linf = train_model(trainloader, testloader, model_2_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_2_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 2 with Linf\n",
        "benchmark(model_2_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "mAv_TuSXtC9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMA Training: Direct Input Space Margin Maximization through Adversarial Training"
      ],
      "metadata": {
        "id": "I2nOuLxdeSz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "R-6Nq9NPJ_Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_L2 = load_model(model_name='Ding2020MMA', dataset='cifar10', threat_model='L2')\n",
        "model_3_L2 = model_3_L2.to(device)\n",
        "\n",
        "# Model training\n",
        "model_3_L2 = train_model(trainloader, testloader, model_3_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_3_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 3 with L2\n",
        "benchmark(model_3_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "SA8WQsoZeWIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n4dNHMZQKP9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_Linf = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='Linf')\n",
        "model_3_Linf = model_3_Linf.to(device)\n",
        "\n",
        "# Model training\n",
        "model_3_Linf = train_model(trainloader, testloader, model_3_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_3_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 3 with Linf\n",
        "benchmark(model_3_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "DbXlugPutzr6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}