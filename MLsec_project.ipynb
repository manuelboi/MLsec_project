{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelboi/MLsec_project/blob/main/MLsec_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models:\n",
        "1. Fixing Data Augmentation to Improve Adversarial Robustness\n",
        "2. Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?\n",
        "3. MMA Training: Direct Input Space Margin Maximization through Adversarial Training"
      ],
      "metadata": {
        "id": "CcZOaHCtHRqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General imports"
      ],
      "metadata": {
        "id": "CHr8lWVj_FFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CzCcoczZsmbn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Various\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import importlib.util\n",
        "import re\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# RobustBench\n",
        "!pip install git+https://github.com/manuelboi/robustbench\n",
        "from robustbench.utils import load_model\n",
        "from robustbench.eval import benchmark\n",
        "from robustbench.data import load_cifar10\n",
        "from robustbench.model_zoo.enums import ThreatModel\n",
        "\n",
        "# Smoothing\n",
        "!git clone https://github.com/matteoturnu/smoothing.git\n",
        "!conda create -n smoothing\n",
        "!conda activate smoothing\n",
        "!conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n",
        "!conda install scipy pandas statsmodels matplotlib seaborn\n",
        "!pip install setGPU\n",
        "from smoothing.code.core import Smooth\n",
        "from smoothing.code.train import train, test\n",
        "from smoothing.code.train_utils import AverageMeter, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "bRZkGSpiPFiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "labels_dct = {0: \"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}\n",
        "# use GPU if available, otherwise use CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Computing device used: \", device)\n",
        "\n",
        "# Preparing trainset and testset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "n_test_samples_benchmark = 100\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Define the number of samples you want to take\n",
        "num_samples = 1000\n",
        "# Create a subset of the dataset\n",
        "indices = list(range(num_samples))\n",
        "train_subset = Subset(trainset, indices)\n",
        "test_subset = Subset(testset, indices)\n",
        "\n",
        "# Preparing trainloader and testloader\n",
        "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "'''\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "'''\n",
        "\n",
        "# Load test samples for predict and certify\n",
        "x_test, y_test = load_cifar10(n_test_samples_benchmark)\n",
        "x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "# Setting various parameters\n",
        "epochs = 3 # used for training\n",
        "sigma = 0.5 # gaussian noise standard deviation\n",
        "n_examples = 20 # to be perturbed by AutoAttack\n",
        "eps_L2 = 0.5 # epsilon of the perturbancy for L2 norm\n",
        "eps_Linf = 8/255 # epsilon of the perturbancy with Linf norm\n",
        "version = 'custom'\n",
        "attacks_to_run=['apgd-ce', 'apgd-dlr'] # Attacks to run on the models"
      ],
      "metadata": {
        "id": "ur-xfxzJPEo3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "QwmN0U3EC3To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "Symqohu2KxSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(trainloader, testloader, model, epochs, sigma, device):\n",
        "  criterion = CrossEntropyLoss().to(device)\n",
        "  optimizer = SGD(model.parameters())\n",
        "  scheduler = StepLR(optimizer, step_size=30)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    scheduler.step(epoch)\n",
        "    before = time.time()\n",
        "    train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, sigma, device)\n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, sigma, device)\n",
        "    after = time.time()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cntdRl_hD0TB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smooth model performances on perturbed images"
      ],
      "metadata": {
        "id": "1w6B16vREnO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def certify(model, sigma, x_text, y_test, L):\n",
        "  n_classes = 10\n",
        "  alpha = 1 # (1 - alpha) is the confidence level (in this case is 0)\n",
        "  n0 = 10 # number of samples for selection\n",
        "  n = 20 # number of samples for estimation (certify) (too few samples but computation time is strongly affected with more)\n",
        "\n",
        "  smooth_model = Smooth(model, n_classes, sigma)\n",
        "\n",
        "  top_classes = list()\n",
        "  radiuses = list()\n",
        "  for x, y in zip(x_test, y_test):\n",
        "    top_class = smooth_model.predict(x, n0, alpha, batch_size=n0, device=device,)\n",
        "    top_class, radius = smooth_model.certify(x, n0, n, alpha, batch_size=n0, device=device, L=L)\n",
        "    top_classes.append(top_class)\n",
        "    radiuses.append(radius)\n",
        "\n",
        "  top_classes = torch.tensor(top_classes, dtype=torch.float64).to(device)\n",
        "  accuracy = torch.mean(top_classes == y_test, dtype=torch.float64)\n",
        "\n",
        "  print(\"Top classes: \", top_classes)\n",
        "  print(\"Y classes: \", y_test)\n",
        "  print(\"Accuracy on smooth model: \", accuracy)"
      ],
      "metadata": {
        "id": "tGu5x_t8EabV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing Data Augmentation to Improve Adversarial Robustness (WideResNet-70-16)"
      ],
      "metadata": {
        "id": "RmnI2rBDeOEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "AvnvKSRLBp9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_L2 = load_model(model_name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='L2')\n",
        "model_1_L2 = model_1_L2.to(device)\n",
        "model_1_L2.eval()\n",
        "\n",
        "# Model training\n",
        "model_1_L2 = train_model(trainloader, testloader, model_1_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_1_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 1 with L2\n",
        "benchmark(model_1_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "TbLV6iYN_UuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078c761b-74a8-46a9-a2f7-da974bbc2579"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/L2/Rebuffi2021Fixing_70_16_cutmix_extra.pt (gdrive_id=1JX82BDVBNO-Ffa2J37EuB8C-aFCbz708).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JX82BDVBNO-Ffa2J37EuB8C-aFCbz708\n",
            "From (redirected): https://drive.google.com/uc?id=1JX82BDVBNO-Ffa2J37EuB8C-aFCbz708&confirm=t&uuid=cfe4a3f6-b1bb-4ca3-84e7-3916c2d8b340\n",
            "To: /content/models/cifar10/L2/Rebuffi2021Fixing_70_16_cutmix_extra.pt\n",
            "100%|██████████| 1.07G/1.07G [00:19<00:00, 53.8MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 3.605 (3.605)\tData 0.161 (0.161)\tLoss 0.5563 (0.5563)\tAcc@1 89.062 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.579 (2.092)\tData 0.014 (0.087)\tLoss 0.5093 (0.5328)\tAcc@1 87.500 (88.281)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][2/16]\tTime 1.688 (1.958)\tData 0.011 (0.062)\tLoss 0.5026 (0.5227)\tAcc@1 89.062 (88.542)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [0][3/16]\tTime 1.673 (1.887)\tData 0.003 (0.047)\tLoss 0.4389 (0.5018)\tAcc@1 92.188 (89.453)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][4/16]\tTime 1.675 (1.844)\tData 0.003 (0.038)\tLoss 0.4663 (0.4947)\tAcc@1 89.062 (89.375)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [0][5/16]\tTime 1.677 (1.816)\tData 0.003 (0.032)\tLoss 0.3340 (0.4679)\tAcc@1 93.750 (90.104)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][6/16]\tTime 1.678 (1.797)\tData 0.003 (0.028)\tLoss 0.4582 (0.4665)\tAcc@1 89.062 (89.955)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [0][7/16]\tTime 1.681 (1.782)\tData 0.003 (0.025)\tLoss 0.3918 (0.4572)\tAcc@1 96.875 (90.820)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][8/16]\tTime 1.687 (1.772)\tData 0.003 (0.022)\tLoss 0.4071 (0.4516)\tAcc@1 92.188 (90.972)\tAcc@5 98.438 (99.132)\n",
            "Epoch: [0][9/16]\tTime 1.694 (1.764)\tData 0.003 (0.020)\tLoss 0.3701 (0.4435)\tAcc@1 92.188 (91.094)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][10/16]\tTime 1.696 (1.758)\tData 0.013 (0.020)\tLoss 0.3748 (0.4372)\tAcc@1 89.062 (90.909)\tAcc@5 100.000 (99.290)\n",
            "Epoch: [0][11/16]\tTime 1.698 (1.753)\tData 0.003 (0.018)\tLoss 0.3305 (0.4283)\tAcc@1 95.312 (91.276)\tAcc@5 100.000 (99.349)\n",
            "Epoch: [0][12/16]\tTime 1.702 (1.749)\tData 0.003 (0.017)\tLoss 0.4364 (0.4289)\tAcc@1 93.750 (91.466)\tAcc@5 100.000 (99.399)\n",
            "Epoch: [0][13/16]\tTime 1.702 (1.745)\tData 0.002 (0.016)\tLoss 0.3342 (0.4222)\tAcc@1 95.312 (91.741)\tAcc@5 100.000 (99.442)\n",
            "Epoch: [0][14/16]\tTime 1.699 (1.742)\tData 0.003 (0.015)\tLoss 0.4691 (0.4253)\tAcc@1 87.500 (91.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][15/16]\tTime 2.317 (1.778)\tData 0.002 (0.014)\tLoss 0.3735 (0.4232)\tAcc@1 90.000 (91.400)\tAcc@5 100.000 (99.500)\n",
            "Epoch: [0][0/16]\tTime 0.739 (0.739)\tData 0.218 (0.218)\tLoss 0.6172 (0.6172)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.538 (0.639)\tData 0.013 (0.115)\tLoss 0.6368 (0.6270)\tAcc@1 81.250 (79.688)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.516 (0.598)\tData 0.010 (0.080)\tLoss 0.6590 (0.6377)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 0.531 (0.581)\tData 0.008 (0.062)\tLoss 0.7396 (0.6632)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.522 (0.569)\tData 0.014 (0.053)\tLoss 0.8034 (0.6912)\tAcc@1 70.312 (77.812)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [0][5/16]\tTime 0.525 (0.562)\tData 0.011 (0.046)\tLoss 0.7807 (0.7061)\tAcc@1 82.812 (78.646)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][6/16]\tTime 0.520 (0.556)\tData 0.003 (0.040)\tLoss 0.7444 (0.7116)\tAcc@1 70.312 (77.455)\tAcc@5 100.000 (98.661)\n",
            "Epoch: [0][7/16]\tTime 0.520 (0.551)\tData 0.003 (0.035)\tLoss 0.6847 (0.7082)\tAcc@1 76.562 (77.344)\tAcc@5 98.438 (98.633)\n",
            "Epoch: [0][8/16]\tTime 0.517 (0.548)\tData 0.003 (0.031)\tLoss 0.5401 (0.6896)\tAcc@1 85.938 (78.299)\tAcc@5 100.000 (98.785)\n",
            "Epoch: [0][9/16]\tTime 0.518 (0.545)\tData 0.003 (0.029)\tLoss 0.6621 (0.6868)\tAcc@1 81.250 (78.594)\tAcc@5 100.000 (98.906)\n",
            "Epoch: [0][10/16]\tTime 0.519 (0.542)\tData 0.003 (0.026)\tLoss 0.9453 (0.7103)\tAcc@1 65.625 (77.415)\tAcc@5 96.875 (98.722)\n",
            "Epoch: [0][11/16]\tTime 0.519 (0.540)\tData 0.003 (0.024)\tLoss 0.5143 (0.6940)\tAcc@1 89.062 (78.385)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [0][12/16]\tTime 0.517 (0.539)\tData 0.003 (0.023)\tLoss 0.7406 (0.6976)\tAcc@1 71.875 (77.885)\tAcc@5 100.000 (98.798)\n",
            "Epoch: [0][13/16]\tTime 0.519 (0.537)\tData 0.003 (0.021)\tLoss 0.6447 (0.6938)\tAcc@1 79.688 (78.013)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [0][14/16]\tTime 0.525 (0.536)\tData 0.003 (0.020)\tLoss 0.6036 (0.6878)\tAcc@1 78.125 (78.021)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][15/16]\tTime 0.388 (0.527)\tData 0.003 (0.019)\tLoss 0.5833 (0.6836)\tAcc@1 82.500 (78.200)\tAcc@5 100.000 (99.000)\n",
            "Epoch: [1][0/16]\tTime 0.703 (0.703)\tData 0.116 (0.116)\tLoss 0.3747 (0.3747)\tAcc@1 89.062 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 1.744 (1.223)\tData 0.007 (0.062)\tLoss 0.2955 (0.3351)\tAcc@1 96.875 (92.969)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][2/16]\tTime 1.742 (1.396)\tData 0.002 (0.042)\tLoss 0.2882 (0.3195)\tAcc@1 96.875 (94.271)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][3/16]\tTime 1.734 (1.481)\tData 0.003 (0.032)\tLoss 0.3006 (0.3148)\tAcc@1 95.312 (94.531)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][4/16]\tTime 1.739 (1.532)\tData 0.008 (0.027)\tLoss 0.2773 (0.3073)\tAcc@1 96.875 (95.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][5/16]\tTime 1.740 (1.567)\tData 0.003 (0.023)\tLoss 0.3215 (0.3096)\tAcc@1 95.312 (95.052)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][6/16]\tTime 1.744 (1.592)\tData 0.003 (0.020)\tLoss 0.2985 (0.3080)\tAcc@1 98.438 (95.536)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][7/16]\tTime 1.755 (1.613)\tData 0.003 (0.018)\tLoss 0.3775 (0.3167)\tAcc@1 92.188 (95.117)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][8/16]\tTime 1.764 (1.629)\tData 0.003 (0.016)\tLoss 0.3156 (0.3166)\tAcc@1 93.750 (94.965)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][9/16]\tTime 1.767 (1.643)\tData 0.003 (0.015)\tLoss 0.2522 (0.3102)\tAcc@1 98.438 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][10/16]\tTime 1.778 (1.656)\tData 0.003 (0.014)\tLoss 0.2776 (0.3072)\tAcc@1 96.875 (95.455)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][11/16]\tTime 1.808 (1.668)\tData 0.004 (0.013)\tLoss 0.4365 (0.3180)\tAcc@1 89.062 (94.922)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][12/16]\tTime 1.771 (1.676)\tData 0.020 (0.014)\tLoss 0.3906 (0.3236)\tAcc@1 93.750 (94.832)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][13/16]\tTime 1.790 (1.684)\tData 0.003 (0.013)\tLoss 0.3398 (0.3247)\tAcc@1 95.312 (94.866)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][14/16]\tTime 1.796 (1.692)\tData 0.008 (0.013)\tLoss 0.4004 (0.3298)\tAcc@1 89.062 (94.479)\tAcc@5 98.438 (99.896)\n",
            "Epoch: [1][15/16]\tTime 1.645 (1.689)\tData 0.003 (0.012)\tLoss 0.2697 (0.3274)\tAcc@1 97.500 (94.600)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [1][0/16]\tTime 1.327 (1.327)\tData 0.118 (0.118)\tLoss 0.5262 (0.5262)\tAcc@1 85.938 (85.938)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.551 (0.939)\tData 0.005 (0.061)\tLoss 0.4794 (0.5028)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.560 (0.813)\tData 0.002 (0.041)\tLoss 0.4238 (0.4765)\tAcc@1 90.625 (87.500)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.554 (0.748)\tData 0.003 (0.032)\tLoss 0.4874 (0.4792)\tAcc@1 89.062 (87.891)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.567 (0.712)\tData 0.005 (0.026)\tLoss 0.4969 (0.4827)\tAcc@1 87.500 (87.812)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.556 (0.686)\tData 0.003 (0.023)\tLoss 0.6505 (0.5107)\tAcc@1 84.375 (87.240)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [1][6/16]\tTime 0.558 (0.668)\tData 0.003 (0.020)\tLoss 0.4780 (0.5060)\tAcc@1 87.500 (87.277)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [1][7/16]\tTime 0.558 (0.654)\tData 0.003 (0.018)\tLoss 0.4842 (0.5033)\tAcc@1 90.625 (87.695)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][8/16]\tTime 0.554 (0.643)\tData 0.003 (0.016)\tLoss 0.4738 (0.5000)\tAcc@1 85.938 (87.500)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [1][9/16]\tTime 0.559 (0.634)\tData 0.003 (0.015)\tLoss 0.3899 (0.4890)\tAcc@1 96.875 (88.438)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][10/16]\tTime 0.558 (0.628)\tData 0.013 (0.014)\tLoss 0.6954 (0.5078)\tAcc@1 75.000 (87.216)\tAcc@5 98.438 (99.290)\n",
            "Epoch: [1][11/16]\tTime 0.566 (0.622)\tData 0.003 (0.014)\tLoss 0.4243 (0.5008)\tAcc@1 87.500 (87.240)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][12/16]\tTime 0.560 (0.618)\tData 0.003 (0.013)\tLoss 0.4968 (0.5005)\tAcc@1 84.375 (87.019)\tAcc@5 100.000 (99.279)\n",
            "Epoch: [1][13/16]\tTime 0.566 (0.614)\tData 0.003 (0.012)\tLoss 0.4349 (0.4958)\tAcc@1 84.375 (86.830)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [1][14/16]\tTime 0.555 (0.610)\tData 0.003 (0.011)\tLoss 0.4299 (0.4914)\tAcc@1 90.625 (87.083)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][15/16]\tTime 0.412 (0.598)\tData 0.003 (0.011)\tLoss 0.4057 (0.4880)\tAcc@1 85.000 (87.000)\tAcc@5 100.000 (99.400)\n",
            "Epoch: [2][0/16]\tTime 0.762 (0.762)\tData 0.152 (0.152)\tLoss 0.3028 (0.3028)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 1.816 (1.289)\tData 0.006 (0.079)\tLoss 0.3794 (0.3411)\tAcc@1 92.188 (94.531)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][2/16]\tTime 1.794 (1.457)\tData 0.001 (0.053)\tLoss 0.2790 (0.3204)\tAcc@1 95.312 (94.792)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 1.790 (1.540)\tData 0.003 (0.041)\tLoss 0.2828 (0.3110)\tAcc@1 96.875 (95.312)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][4/16]\tTime 1.791 (1.590)\tData 0.001 (0.033)\tLoss 0.2659 (0.3020)\tAcc@1 100.000 (96.250)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][5/16]\tTime 1.779 (1.622)\tData 0.003 (0.028)\tLoss 0.3005 (0.3017)\tAcc@1 96.875 (96.354)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [2][6/16]\tTime 1.779 (1.644)\tData 0.003 (0.024)\tLoss 0.3174 (0.3040)\tAcc@1 93.750 (95.982)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [2][7/16]\tTime 1.767 (1.660)\tData 0.003 (0.022)\tLoss 0.2341 (0.2952)\tAcc@1 100.000 (96.484)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [2][8/16]\tTime 1.786 (1.674)\tData 0.005 (0.020)\tLoss 0.3325 (0.2994)\tAcc@1 93.750 (96.181)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [2][9/16]\tTime 1.777 (1.684)\tData 0.003 (0.018)\tLoss 0.2678 (0.2962)\tAcc@1 92.188 (95.781)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [2][10/16]\tTime 1.768 (1.692)\tData 0.003 (0.017)\tLoss 0.2839 (0.2951)\tAcc@1 93.750 (95.597)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [2][11/16]\tTime 1.757 (1.697)\tData 0.003 (0.015)\tLoss 0.2681 (0.2929)\tAcc@1 98.438 (95.833)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [2][12/16]\tTime 1.768 (1.702)\tData 0.003 (0.015)\tLoss 0.2925 (0.2928)\tAcc@1 96.875 (95.913)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [2][13/16]\tTime 1.754 (1.706)\tData 0.003 (0.014)\tLoss 0.2337 (0.2886)\tAcc@1 96.875 (95.982)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [2][14/16]\tTime 1.749 (1.709)\tData 0.003 (0.013)\tLoss 0.3045 (0.2897)\tAcc@1 95.312 (95.938)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [2][15/16]\tTime 1.607 (1.703)\tData 0.003 (0.012)\tLoss 0.2797 (0.2893)\tAcc@1 92.500 (95.800)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [2][0/16]\tTime 1.275 (1.275)\tData 0.183 (0.183)\tLoss 0.5926 (0.5926)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.530 (0.902)\tData 0.004 (0.093)\tLoss 0.4771 (0.5348)\tAcc@1 89.062 (84.375)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.540 (0.782)\tData 0.005 (0.064)\tLoss 0.3881 (0.4859)\tAcc@1 90.625 (86.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.530 (0.719)\tData 0.002 (0.048)\tLoss 0.5466 (0.5011)\tAcc@1 82.812 (85.547)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [2][4/16]\tTime 0.537 (0.682)\tData 0.003 (0.039)\tLoss 0.6118 (0.5232)\tAcc@1 78.125 (84.062)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [2][5/16]\tTime 0.531 (0.657)\tData 0.003 (0.033)\tLoss 0.6743 (0.5484)\tAcc@1 79.688 (83.333)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [2][6/16]\tTime 0.540 (0.640)\tData 0.004 (0.029)\tLoss 0.4346 (0.5321)\tAcc@1 90.625 (84.375)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [2][7/16]\tTime 0.530 (0.627)\tData 0.003 (0.026)\tLoss 0.4300 (0.5194)\tAcc@1 90.625 (85.156)\tAcc@5 100.000 (99.023)\n",
            "Epoch: [2][8/16]\tTime 0.540 (0.617)\tData 0.003 (0.023)\tLoss 0.4383 (0.5104)\tAcc@1 84.375 (85.069)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [2][9/16]\tTime 0.529 (0.608)\tData 0.003 (0.021)\tLoss 0.4808 (0.5074)\tAcc@1 89.062 (85.469)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][10/16]\tTime 0.540 (0.602)\tData 0.003 (0.019)\tLoss 0.7055 (0.5254)\tAcc@1 76.562 (84.659)\tAcc@5 95.312 (98.864)\n",
            "Epoch: [2][11/16]\tTime 0.528 (0.596)\tData 0.003 (0.018)\tLoss 0.4093 (0.5157)\tAcc@1 89.062 (85.026)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [2][12/16]\tTime 0.536 (0.591)\tData 0.003 (0.017)\tLoss 0.5395 (0.5176)\tAcc@1 82.812 (84.856)\tAcc@5 100.000 (98.918)\n",
            "Epoch: [2][13/16]\tTime 0.529 (0.587)\tData 0.003 (0.016)\tLoss 0.3873 (0.5083)\tAcc@1 90.625 (85.268)\tAcc@5 100.000 (98.996)\n",
            "Epoch: [2][14/16]\tTime 0.534 (0.583)\tData 0.003 (0.015)\tLoss 0.3806 (0.4998)\tAcc@1 90.625 (85.625)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [2][15/16]\tTime 0.394 (0.571)\tData 0.003 (0.014)\tLoss 0.4138 (0.4963)\tAcc@1 92.500 (85.900)\tAcc@5 97.500 (99.000)\n",
            "Top classes:  tensor([3., 0., 0., 0., 4., 4., 3., 6., 4., 9., 4., 9., 4., 7., 9., 8., 3., 7.,\n",
            "        8., 6., 7., 2., 4., 9., 4., 4., 4., 0., 9., 4., 4., 4., 4., 3., 9., 3.,\n",
            "        4., 9., 9., 3., 0., 4., 3., 6., 4., 9., 3., 3., 4., 4., 9., 8., 0., 4.,\n",
            "        8., 8., 5., 7., 3., 4., 4., 4., 4., 9., 6., 4., 0., 2., 3., 7., 4., 4.,\n",
            "        8., 8., 0., 4., 0., 3., 3., 3., 4., 8., 4., 7., 2., 4., 4., 3., 8., 9.,\n",
            "        0., 4., 8., 6., 4., 4., 4., 4., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4800, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 60.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
            "    sys.settrace(tracefunc)\n",
            "\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy: 60.00%\n",
            "apgd-ce - 1/1 - 4 out of 12 successfully perturbed\n",
            "robust accuracy after APGD-CE: 40.00% (total time 164.6 s)\n",
            "apgd-dlr - 1/1 - 0 out of 8 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 40.00% (total time 326.9 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 40.00%\n",
            "Adversarial accuracy: 40.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6, 0.4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n6gPMiYKByXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_Linf = load_model(model_name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='Linf')\n",
        "model_1_Linf = model_1_Linf.to(device)\n",
        "model_1_Linf.eval()\n",
        "\n",
        "# Model training\n",
        "model_1_Linf = train_model(trainloader, testloader, model_1_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_1_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 1 with Linf\n",
        "benchmark(model_1_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "rA09MQ0lZ34c",
        "outputId": "8a62b450-7f63-4991-97f1-9b4b50339d7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt (gdrive_id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg\n",
            "From (redirected): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg&confirm=t&uuid=919c7b17-957c-4129-8022-9ebede38e43c\n",
            "To: /content/models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt\n",
            "100%|██████████| 1.07G/1.07G [00:23<00:00, 44.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.770 (0.770)\tData 0.132 (0.132)\tLoss 0.7303 (0.7303)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 1.743 (1.257)\tData 0.004 (0.068)\tLoss 0.6788 (0.7046)\tAcc@1 89.062 (87.500)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][2/16]\tTime 1.735 (1.416)\tData 0.004 (0.046)\tLoss 0.7634 (0.7242)\tAcc@1 84.375 (86.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 1.758 (1.502)\tData 0.002 (0.035)\tLoss 0.7559 (0.7321)\tAcc@1 81.250 (85.156)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][4/16]\tTime 1.770 (1.555)\tData 0.010 (0.030)\tLoss 0.7610 (0.7379)\tAcc@1 85.938 (85.312)\tAcc@5 98.438 (99.375)\n",
            "Epoch: [0][5/16]\tTime 1.762 (1.590)\tData 0.003 (0.026)\tLoss 0.7749 (0.7440)\tAcc@1 81.250 (84.635)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][6/16]\tTime 1.769 (1.615)\tData 0.014 (0.024)\tLoss 0.7323 (0.7424)\tAcc@1 85.938 (84.821)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [0][7/16]\tTime 1.787 (1.637)\tData 0.003 (0.021)\tLoss 0.6940 (0.7363)\tAcc@1 85.938 (84.961)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][8/16]\tTime 1.794 (1.654)\tData 0.003 (0.019)\tLoss 0.6777 (0.7298)\tAcc@1 85.938 (85.069)\tAcc@5 98.438 (99.132)\n",
            "Epoch: [0][9/16]\tTime 1.809 (1.670)\tData 0.003 (0.018)\tLoss 0.6115 (0.7180)\tAcc@1 90.625 (85.625)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [0][10/16]\tTime 1.809 (1.682)\tData 0.004 (0.016)\tLoss 0.5574 (0.7034)\tAcc@1 92.188 (86.222)\tAcc@5 98.438 (99.006)\n",
            "Epoch: [0][11/16]\tTime 1.814 (1.693)\tData 0.003 (0.015)\tLoss 0.6133 (0.6959)\tAcc@1 89.062 (86.458)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [0][12/16]\tTime 1.824 (1.703)\tData 0.003 (0.014)\tLoss 0.6312 (0.6909)\tAcc@1 82.812 (86.178)\tAcc@5 100.000 (99.038)\n",
            "Epoch: [0][13/16]\tTime 1.824 (1.712)\tData 0.003 (0.013)\tLoss 0.6616 (0.6888)\tAcc@1 82.812 (85.938)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [0][14/16]\tTime 1.829 (1.720)\tData 0.003 (0.013)\tLoss 0.5605 (0.6803)\tAcc@1 90.625 (86.250)\tAcc@5 100.000 (99.167)\n",
            "Epoch: [0][15/16]\tTime 1.674 (1.717)\tData 0.003 (0.012)\tLoss 0.5021 (0.6731)\tAcc@1 87.500 (86.300)\tAcc@5 100.000 (99.200)\n",
            "Epoch: [0][0/16]\tTime 1.327 (1.327)\tData 0.140 (0.140)\tLoss 0.8665 (0.8665)\tAcc@1 71.875 (71.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.564 (0.945)\tData 0.005 (0.073)\tLoss 0.8937 (0.8801)\tAcc@1 76.562 (74.219)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.566 (0.819)\tData 0.002 (0.049)\tLoss 0.8421 (0.8674)\tAcc@1 87.500 (78.646)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 0.565 (0.756)\tData 0.003 (0.037)\tLoss 0.8358 (0.8595)\tAcc@1 76.562 (78.125)\tAcc@5 95.312 (98.438)\n",
            "Epoch: [0][4/16]\tTime 0.561 (0.717)\tData 0.003 (0.031)\tLoss 0.8260 (0.8528)\tAcc@1 76.562 (77.812)\tAcc@5 100.000 (98.750)\n",
            "Epoch: [0][5/16]\tTime 0.560 (0.691)\tData 0.003 (0.026)\tLoss 0.9182 (0.8637)\tAcc@1 73.438 (77.083)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][6/16]\tTime 0.560 (0.672)\tData 0.003 (0.023)\tLoss 0.8928 (0.8679)\tAcc@1 71.875 (76.339)\tAcc@5 100.000 (98.661)\n",
            "Epoch: [0][7/16]\tTime 0.569 (0.659)\tData 0.003 (0.020)\tLoss 0.8524 (0.8659)\tAcc@1 71.875 (75.781)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][8/16]\tTime 0.559 (0.648)\tData 0.003 (0.018)\tLoss 0.7626 (0.8544)\tAcc@1 75.000 (75.694)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][9/16]\tTime 0.559 (0.639)\tData 0.003 (0.017)\tLoss 0.8365 (0.8527)\tAcc@1 76.562 (75.781)\tAcc@5 100.000 (98.594)\n",
            "Epoch: [0][10/16]\tTime 0.557 (0.632)\tData 0.003 (0.015)\tLoss 0.9938 (0.8655)\tAcc@1 64.062 (74.716)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][11/16]\tTime 0.564 (0.626)\tData 0.003 (0.014)\tLoss 0.7269 (0.8539)\tAcc@1 82.812 (75.391)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][12/16]\tTime 0.564 (0.621)\tData 0.005 (0.014)\tLoss 0.8381 (0.8527)\tAcc@1 71.875 (75.120)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][13/16]\tTime 0.561 (0.617)\tData 0.003 (0.013)\tLoss 0.8101 (0.8497)\tAcc@1 73.438 (75.000)\tAcc@5 96.875 (98.326)\n",
            "Epoch: [0][14/16]\tTime 0.557 (0.613)\tData 0.003 (0.012)\tLoss 0.8085 (0.8469)\tAcc@1 73.438 (74.896)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][15/16]\tTime 0.411 (0.600)\tData 0.003 (0.012)\tLoss 0.7884 (0.8446)\tAcc@1 80.000 (75.100)\tAcc@5 97.500 (98.400)\n",
            "Epoch: [1][0/16]\tTime 0.818 (0.818)\tData 0.212 (0.212)\tLoss 0.5294 (0.5294)\tAcc@1 90.625 (90.625)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 1.815 (1.316)\tData 0.002 (0.107)\tLoss 0.5437 (0.5366)\tAcc@1 90.625 (90.625)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][2/16]\tTime 1.797 (1.477)\tData 0.004 (0.073)\tLoss 0.6537 (0.5756)\tAcc@1 81.250 (87.500)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][3/16]\tTime 1.775 (1.551)\tData 0.001 (0.055)\tLoss 0.5452 (0.5680)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][4/16]\tTime 1.774 (1.596)\tData 0.003 (0.044)\tLoss 0.5494 (0.5643)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 1.779 (1.626)\tData 0.003 (0.037)\tLoss 0.6061 (0.5712)\tAcc@1 85.938 (87.240)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][6/16]\tTime 1.776 (1.648)\tData 0.003 (0.033)\tLoss 0.5035 (0.5616)\tAcc@1 89.062 (87.500)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [1][7/16]\tTime 1.779 (1.664)\tData 0.007 (0.029)\tLoss 0.5569 (0.5610)\tAcc@1 92.188 (88.086)\tAcc@5 98.438 (99.414)\n",
            "Epoch: [1][8/16]\tTime 1.770 (1.676)\tData 0.012 (0.027)\tLoss 0.4864 (0.5527)\tAcc@1 89.062 (88.194)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][9/16]\tTime 1.759 (1.684)\tData 0.003 (0.025)\tLoss 0.5097 (0.5484)\tAcc@1 92.188 (88.594)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [1][10/16]\tTime 1.763 (1.691)\tData 0.003 (0.023)\tLoss 0.4326 (0.5379)\tAcc@1 96.875 (89.347)\tAcc@5 100.000 (99.574)\n",
            "Epoch: [1][11/16]\tTime 1.753 (1.696)\tData 0.003 (0.021)\tLoss 0.4587 (0.5313)\tAcc@1 92.188 (89.583)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [1][12/16]\tTime 1.756 (1.701)\tData 0.003 (0.020)\tLoss 0.4961 (0.5286)\tAcc@1 93.750 (89.904)\tAcc@5 100.000 (99.639)\n",
            "Epoch: [1][13/16]\tTime 1.753 (1.705)\tData 0.003 (0.019)\tLoss 0.4851 (0.5255)\tAcc@1 93.750 (90.179)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [1][14/16]\tTime 1.742 (1.707)\tData 0.003 (0.018)\tLoss 0.5332 (0.5260)\tAcc@1 92.188 (90.312)\tAcc@5 98.438 (99.583)\n",
            "Epoch: [1][15/16]\tTime 1.589 (1.700)\tData 0.003 (0.017)\tLoss 0.4367 (0.5224)\tAcc@1 97.500 (90.600)\tAcc@5 100.000 (99.600)\n",
            "Epoch: [1][0/16]\tTime 1.226 (1.226)\tData 0.181 (0.181)\tLoss 0.6980 (0.6980)\tAcc@1 85.938 (85.938)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.525 (0.876)\tData 0.006 (0.093)\tLoss 0.6523 (0.6751)\tAcc@1 84.375 (85.156)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.533 (0.761)\tData 0.002 (0.063)\tLoss 0.6177 (0.6560)\tAcc@1 89.062 (86.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.529 (0.703)\tData 0.003 (0.048)\tLoss 0.6406 (0.6521)\tAcc@1 89.062 (87.109)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.534 (0.669)\tData 0.003 (0.039)\tLoss 0.6874 (0.6592)\tAcc@1 81.250 (85.938)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.528 (0.646)\tData 0.003 (0.033)\tLoss 0.7911 (0.6812)\tAcc@1 73.438 (83.854)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [1][6/16]\tTime 0.534 (0.630)\tData 0.003 (0.029)\tLoss 0.6475 (0.6764)\tAcc@1 84.375 (83.929)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [1][7/16]\tTime 0.537 (0.618)\tData 0.018 (0.027)\tLoss 0.6245 (0.6699)\tAcc@1 85.938 (84.180)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][8/16]\tTime 0.537 (0.609)\tData 0.003 (0.025)\tLoss 0.5908 (0.6611)\tAcc@1 87.500 (84.549)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [1][9/16]\tTime 0.527 (0.601)\tData 0.003 (0.022)\tLoss 0.6111 (0.6561)\tAcc@1 85.938 (84.688)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][10/16]\tTime 0.532 (0.595)\tData 0.005 (0.021)\tLoss 0.8160 (0.6706)\tAcc@1 75.000 (83.807)\tAcc@5 100.000 (99.432)\n",
            "Epoch: [1][11/16]\tTime 0.529 (0.589)\tData 0.003 (0.019)\tLoss 0.5994 (0.6647)\tAcc@1 84.375 (83.854)\tAcc@5 98.438 (99.349)\n",
            "Epoch: [1][12/16]\tTime 0.534 (0.585)\tData 0.003 (0.018)\tLoss 0.6694 (0.6651)\tAcc@1 79.688 (83.534)\tAcc@5 100.000 (99.399)\n",
            "Epoch: [1][13/16]\tTime 0.530 (0.581)\tData 0.003 (0.017)\tLoss 0.6512 (0.6641)\tAcc@1 76.562 (83.036)\tAcc@5 100.000 (99.442)\n",
            "Epoch: [1][14/16]\tTime 0.531 (0.578)\tData 0.003 (0.016)\tLoss 0.6314 (0.6619)\tAcc@1 81.250 (82.917)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][15/16]\tTime 0.392 (0.566)\tData 0.003 (0.015)\tLoss 0.6487 (0.6614)\tAcc@1 90.000 (83.200)\tAcc@5 97.500 (99.400)\n",
            "Epoch: [2][0/16]\tTime 0.704 (0.704)\tData 0.122 (0.122)\tLoss 0.4782 (0.4782)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 1.800 (1.252)\tData 0.004 (0.063)\tLoss 0.4516 (0.4649)\tAcc@1 93.750 (94.531)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 1.760 (1.421)\tData 0.008 (0.045)\tLoss 0.4605 (0.4634)\tAcc@1 90.625 (93.229)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 1.757 (1.505)\tData 0.015 (0.037)\tLoss 0.4960 (0.4716)\tAcc@1 90.625 (92.578)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 1.742 (1.553)\tData 0.003 (0.030)\tLoss 0.5770 (0.4927)\tAcc@1 90.625 (92.188)\tAcc@5 96.875 (99.375)\n",
            "Epoch: [2][5/16]\tTime 1.752 (1.586)\tData 0.003 (0.026)\tLoss 0.4639 (0.4879)\tAcc@1 93.750 (92.448)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][6/16]\tTime 1.742 (1.608)\tData 0.003 (0.022)\tLoss 0.4405 (0.4811)\tAcc@1 96.875 (93.080)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [2][7/16]\tTime 1.759 (1.627)\tData 0.003 (0.020)\tLoss 0.4737 (0.4802)\tAcc@1 90.625 (92.773)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][8/16]\tTime 1.754 (1.641)\tData 0.011 (0.019)\tLoss 0.4547 (0.4773)\tAcc@1 93.750 (92.882)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [2][9/16]\tTime 1.764 (1.653)\tData 0.003 (0.017)\tLoss 0.4373 (0.4733)\tAcc@1 93.750 (92.969)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [2][10/16]\tTime 1.757 (1.663)\tData 0.004 (0.016)\tLoss 0.4206 (0.4685)\tAcc@1 93.750 (93.040)\tAcc@5 100.000 (99.574)\n",
            "Epoch: [2][11/16]\tTime 1.757 (1.671)\tData 0.014 (0.016)\tLoss 0.4667 (0.4684)\tAcc@1 90.625 (92.839)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][12/16]\tTime 1.762 (1.678)\tData 0.002 (0.015)\tLoss 0.4836 (0.4696)\tAcc@1 92.188 (92.788)\tAcc@5 100.000 (99.639)\n",
            "Epoch: [2][13/16]\tTime 1.758 (1.684)\tData 0.003 (0.014)\tLoss 0.4334 (0.4670)\tAcc@1 90.625 (92.634)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [2][14/16]\tTime 1.766 (1.689)\tData 0.003 (0.013)\tLoss 0.4456 (0.4655)\tAcc@1 90.625 (92.500)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][15/16]\tTime 1.618 (1.685)\tData 0.003 (0.013)\tLoss 0.4389 (0.4645)\tAcc@1 95.000 (92.600)\tAcc@5 100.000 (99.700)\n",
            "Epoch: [2][0/16]\tTime 1.277 (1.277)\tData 0.129 (0.129)\tLoss 0.6289 (0.6289)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][1/16]\tTime 0.537 (0.907)\tData 0.005 (0.067)\tLoss 0.5865 (0.6077)\tAcc@1 90.625 (89.062)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.549 (0.788)\tData 0.008 (0.048)\tLoss 0.6125 (0.6093)\tAcc@1 85.938 (88.021)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.541 (0.726)\tData 0.010 (0.038)\tLoss 0.6216 (0.6124)\tAcc@1 82.812 (86.719)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][4/16]\tTime 0.548 (0.691)\tData 0.003 (0.031)\tLoss 0.6100 (0.6119)\tAcc@1 84.375 (86.250)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [2][5/16]\tTime 0.543 (0.666)\tData 0.003 (0.026)\tLoss 0.7087 (0.6280)\tAcc@1 79.688 (85.156)\tAcc@5 96.875 (98.698)\n",
            "Epoch: [2][6/16]\tTime 0.547 (0.649)\tData 0.003 (0.023)\tLoss 0.5786 (0.6210)\tAcc@1 87.500 (85.491)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [2][7/16]\tTime 0.548 (0.636)\tData 0.004 (0.021)\tLoss 0.6472 (0.6242)\tAcc@1 90.625 (86.133)\tAcc@5 100.000 (99.023)\n",
            "Epoch: [2][8/16]\tTime 0.546 (0.626)\tData 0.013 (0.020)\tLoss 0.5458 (0.6155)\tAcc@1 89.062 (86.458)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [2][9/16]\tTime 0.545 (0.618)\tData 0.003 (0.018)\tLoss 0.5999 (0.6140)\tAcc@1 92.188 (87.031)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][10/16]\tTime 0.545 (0.611)\tData 0.003 (0.017)\tLoss 0.7273 (0.6243)\tAcc@1 76.562 (86.080)\tAcc@5 100.000 (99.290)\n",
            "Epoch: [2][11/16]\tTime 0.546 (0.606)\tData 0.003 (0.016)\tLoss 0.5939 (0.6217)\tAcc@1 87.500 (86.198)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][12/16]\tTime 0.547 (0.601)\tData 0.003 (0.015)\tLoss 0.6642 (0.6250)\tAcc@1 81.250 (85.817)\tAcc@5 98.438 (99.159)\n",
            "Epoch: [2][13/16]\tTime 0.545 (0.597)\tData 0.003 (0.014)\tLoss 0.5383 (0.6188)\tAcc@1 82.812 (85.603)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][14/16]\tTime 0.545 (0.594)\tData 0.003 (0.013)\tLoss 0.5153 (0.6119)\tAcc@1 87.500 (85.729)\tAcc@5 100.000 (99.271)\n",
            "Epoch: [2][15/16]\tTime 0.403 (0.582)\tData 0.003 (0.012)\tLoss 0.5789 (0.6106)\tAcc@1 90.000 (85.900)\tAcc@5 97.500 (99.200)\n",
            "Top classes:  tensor([6., 8., 8., 0., 4., 4., 3., 4., 4., 8., 4., 8., 4., 7., 8., 8., 3., 7.,\n",
            "        8., 4., 7., 0., 8., 9., 4., 4., 4., 0., 3., 4., 4., 4., 4., 3., 8., 5.,\n",
            "        4., 8., 8., 5., 4., 4., 2., 6., 0., 9., 3., 8., 4., 4., 8., 8., 0., 4.,\n",
            "        8., 8., 5., 4., 4., 4., 4., 4., 4., 0., 4., 4., 8., 2., 3., 8., 4., 4.,\n",
            "        8., 8., 8., 2., 2., 3., 3., 8., 8., 8., 0., 7., 2., 2., 2., 8., 8., 8.,\n",
            "        0., 4., 8., 6., 8., 6., 4., 0., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4500, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 45.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 45.00%\n",
            "apgd-ce - 1/1 - 3 out of 9 successfully perturbed\n",
            "robust accuracy after APGD-CE: 30.00% (total time 148.2 s)\n",
            "apgd-dlr - 1/1 - 1 out of 6 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 25.00% (total time 268.6 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 25.00%\n",
            "Adversarial accuracy: 25.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.45, 0.25)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness? (ResNet-18)"
      ],
      "metadata": {
        "id": "mtma9ehWeKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "qSW7z1l1Iten"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_L2 = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='L2')\n",
        "model_2_L2 = model_2_L2.to(device)\n",
        "model_2_L2.eval()\n",
        "\n",
        "# Model training\n",
        "model_2_L2 = train_model(trainloader, testloader, model_2_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_2_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 2 with L2\n",
        "benchmark(model_2_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "hOl_1rinc4IX",
        "outputId": "3bb4969e-7034-4c60-a41c-a0af7f159501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/L2/Sehwag2021Proxy.pt (gdrive_id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S\n",
            "From (redirected): https://drive.google.com/uc?id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S&confirm=t&uuid=3da971c8-0254-4ff4-a0d0-c741487d7e67\n",
            "To: /content/models/cifar10/L2/Sehwag2021Proxy.pt\n",
            "100%|██████████| 1.11G/1.11G [00:29<00:00, 38.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.437 (0.437)\tData 0.162 (0.162)\tLoss 0.2338 (0.2338)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.355 (0.396)\tData 0.002 (0.082)\tLoss 0.1599 (0.1969)\tAcc@1 96.875 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 0.368 (0.387)\tData 0.003 (0.056)\tLoss 0.2277 (0.2072)\tAcc@1 92.188 (94.271)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][3/16]\tTime 0.377 (0.384)\tData 0.003 (0.042)\tLoss 0.2850 (0.2266)\tAcc@1 92.188 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][4/16]\tTime 0.371 (0.382)\tData 0.003 (0.034)\tLoss 0.1648 (0.2143)\tAcc@1 95.312 (94.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][5/16]\tTime 0.371 (0.380)\tData 0.003 (0.029)\tLoss 0.2147 (0.2143)\tAcc@1 93.750 (94.010)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][6/16]\tTime 0.378 (0.380)\tData 0.004 (0.026)\tLoss 0.1222 (0.2012)\tAcc@1 96.875 (94.420)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][7/16]\tTime 0.374 (0.379)\tData 0.003 (0.023)\tLoss 0.2738 (0.2103)\tAcc@1 93.750 (94.336)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][8/16]\tTime 0.376 (0.379)\tData 0.003 (0.021)\tLoss 0.2304 (0.2125)\tAcc@1 92.188 (94.097)\tAcc@5 98.438 (99.826)\n",
            "Epoch: [0][9/16]\tTime 0.377 (0.379)\tData 0.010 (0.019)\tLoss 0.2378 (0.2150)\tAcc@1 92.188 (93.906)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [0][10/16]\tTime 0.374 (0.378)\tData 0.013 (0.019)\tLoss 0.1582 (0.2099)\tAcc@1 96.875 (94.176)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [0][11/16]\tTime 0.378 (0.378)\tData 0.014 (0.018)\tLoss 0.1477 (0.2047)\tAcc@1 96.875 (94.401)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [0][12/16]\tTime 0.373 (0.378)\tData 0.003 (0.017)\tLoss 0.1482 (0.2003)\tAcc@1 95.312 (94.471)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [0][13/16]\tTime 0.376 (0.378)\tData 0.002 (0.016)\tLoss 0.3009 (0.2075)\tAcc@1 92.188 (94.308)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [0][14/16]\tTime 0.379 (0.378)\tData 0.003 (0.015)\tLoss 0.2043 (0.2073)\tAcc@1 93.750 (94.271)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [0][15/16]\tTime 0.345 (0.376)\tData 0.003 (0.014)\tLoss 0.4375 (0.2165)\tAcc@1 90.000 (94.100)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [0][0/16]\tTime 0.309 (0.309)\tData 0.174 (0.174)\tLoss 0.7210 (0.7210)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.143 (0.226)\tData 0.004 (0.089)\tLoss 0.6280 (0.6745)\tAcc@1 81.250 (79.688)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.142 (0.198)\tData 0.001 (0.060)\tLoss 0.6506 (0.6665)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][3/16]\tTime 0.145 (0.185)\tData 0.003 (0.046)\tLoss 0.4921 (0.6229)\tAcc@1 82.812 (80.469)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][4/16]\tTime 0.141 (0.176)\tData 0.001 (0.037)\tLoss 0.5118 (0.6007)\tAcc@1 71.875 (78.750)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [0][5/16]\tTime 0.142 (0.170)\tData 0.003 (0.031)\tLoss 0.7080 (0.6186)\tAcc@1 75.000 (78.125)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][6/16]\tTime 0.161 (0.169)\tData 0.002 (0.027)\tLoss 0.7651 (0.6395)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [0][7/16]\tTime 0.142 (0.166)\tData 0.002 (0.024)\tLoss 0.6149 (0.6364)\tAcc@1 84.375 (78.906)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][8/16]\tTime 0.142 (0.163)\tData 0.002 (0.021)\tLoss 0.4732 (0.6183)\tAcc@1 85.938 (79.688)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [0][9/16]\tTime 0.141 (0.161)\tData 0.003 (0.020)\tLoss 0.4406 (0.6005)\tAcc@1 81.250 (79.844)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [0][10/16]\tTime 0.141 (0.159)\tData 0.002 (0.018)\tLoss 0.7445 (0.6136)\tAcc@1 73.438 (79.261)\tAcc@5 96.875 (99.290)\n",
            "Epoch: [0][11/16]\tTime 0.142 (0.158)\tData 0.002 (0.017)\tLoss 0.5969 (0.6122)\tAcc@1 85.938 (79.818)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][12/16]\tTime 0.145 (0.157)\tData 0.002 (0.016)\tLoss 0.7870 (0.6257)\tAcc@1 75.000 (79.447)\tAcc@5 98.438 (99.159)\n",
            "Epoch: [0][13/16]\tTime 0.148 (0.156)\tData 0.003 (0.015)\tLoss 0.4981 (0.6166)\tAcc@1 85.938 (79.911)\tAcc@5 96.875 (98.996)\n",
            "Epoch: [0][14/16]\tTime 0.146 (0.155)\tData 0.002 (0.014)\tLoss 0.5339 (0.6111)\tAcc@1 84.375 (80.208)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [0][15/16]\tTime 0.100 (0.152)\tData 0.003 (0.013)\tLoss 0.4231 (0.6035)\tAcc@1 87.500 (80.500)\tAcc@5 100.000 (99.100)\n",
            "Epoch: [1][0/16]\tTime 0.290 (0.290)\tData 0.147 (0.147)\tLoss 0.1447 (0.1447)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.371 (0.331)\tData 0.003 (0.075)\tLoss 0.2751 (0.2099)\tAcc@1 85.938 (90.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][2/16]\tTime 0.390 (0.350)\tData 0.003 (0.051)\tLoss 0.0790 (0.1663)\tAcc@1 98.438 (93.229)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][3/16]\tTime 0.384 (0.359)\tData 0.003 (0.039)\tLoss 0.3030 (0.2005)\tAcc@1 89.062 (92.188)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [1][4/16]\tTime 0.375 (0.362)\tData 0.003 (0.032)\tLoss 0.1868 (0.1977)\tAcc@1 95.312 (92.812)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 0.383 (0.365)\tData 0.002 (0.027)\tLoss 0.2162 (0.2008)\tAcc@1 90.625 (92.448)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 0.378 (0.367)\tData 0.003 (0.023)\tLoss 0.1341 (0.1913)\tAcc@1 95.312 (92.857)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 0.375 (0.368)\tData 0.003 (0.021)\tLoss 0.2923 (0.2039)\tAcc@1 93.750 (92.969)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [1][8/16]\tTime 0.385 (0.370)\tData 0.002 (0.019)\tLoss 0.1480 (0.1977)\tAcc@1 92.188 (92.882)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [1][9/16]\tTime 0.378 (0.371)\tData 0.003 (0.017)\tLoss 0.1219 (0.1901)\tAcc@1 96.875 (93.281)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [1][10/16]\tTime 0.380 (0.372)\tData 0.002 (0.016)\tLoss 0.1161 (0.1834)\tAcc@1 96.875 (93.608)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [1][11/16]\tTime 0.384 (0.373)\tData 0.005 (0.015)\tLoss 0.1809 (0.1832)\tAcc@1 96.875 (93.880)\tAcc@5 98.438 (99.740)\n",
            "Epoch: [1][12/16]\tTime 0.377 (0.373)\tData 0.002 (0.014)\tLoss 0.0846 (0.1756)\tAcc@1 100.000 (94.351)\tAcc@5 100.000 (99.760)\n",
            "Epoch: [1][13/16]\tTime 0.383 (0.374)\tData 0.002 (0.013)\tLoss 0.2177 (0.1786)\tAcc@1 95.312 (94.420)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][14/16]\tTime 0.382 (0.374)\tData 0.002 (0.012)\tLoss 0.3283 (0.1886)\tAcc@1 92.188 (94.271)\tAcc@5 98.438 (99.688)\n",
            "Epoch: [1][15/16]\tTime 0.333 (0.372)\tData 0.002 (0.012)\tLoss 0.0781 (0.1842)\tAcc@1 100.000 (94.500)\tAcc@5 100.000 (99.700)\n",
            "Epoch: [1][0/16]\tTime 0.270 (0.270)\tData 0.135 (0.135)\tLoss 0.5285 (0.5285)\tAcc@1 85.938 (85.938)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.148 (0.209)\tData 0.004 (0.070)\tLoss 0.4752 (0.5018)\tAcc@1 84.375 (85.156)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.145 (0.188)\tData 0.001 (0.047)\tLoss 0.4185 (0.4740)\tAcc@1 85.938 (85.417)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.145 (0.177)\tData 0.003 (0.036)\tLoss 0.6686 (0.5227)\tAcc@1 84.375 (85.156)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.145 (0.171)\tData 0.001 (0.029)\tLoss 0.5729 (0.5327)\tAcc@1 79.688 (84.062)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.150 (0.167)\tData 0.002 (0.024)\tLoss 0.5392 (0.5338)\tAcc@1 84.375 (84.115)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][6/16]\tTime 0.157 (0.166)\tData 0.002 (0.021)\tLoss 0.5134 (0.5309)\tAcc@1 85.938 (84.375)\tAcc@5 98.438 (99.107)\n",
            "Epoch: [1][7/16]\tTime 0.145 (0.163)\tData 0.002 (0.019)\tLoss 0.5598 (0.5345)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (99.023)\n",
            "Epoch: [1][8/16]\tTime 0.145 (0.161)\tData 0.002 (0.017)\tLoss 0.2888 (0.5072)\tAcc@1 89.062 (84.896)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [1][9/16]\tTime 0.146 (0.160)\tData 0.002 (0.016)\tLoss 0.3646 (0.4929)\tAcc@1 87.500 (85.156)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [1][10/16]\tTime 0.146 (0.158)\tData 0.004 (0.014)\tLoss 0.7829 (0.5193)\tAcc@1 76.562 (84.375)\tAcc@5 95.312 (98.722)\n",
            "Epoch: [1][11/16]\tTime 0.146 (0.157)\tData 0.002 (0.013)\tLoss 0.7382 (0.5375)\tAcc@1 85.938 (84.505)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [1][12/16]\tTime 0.151 (0.157)\tData 0.003 (0.013)\tLoss 0.6817 (0.5486)\tAcc@1 79.688 (84.135)\tAcc@5 98.438 (98.678)\n",
            "Epoch: [1][13/16]\tTime 0.150 (0.156)\tData 0.003 (0.012)\tLoss 0.3639 (0.5354)\tAcc@1 85.938 (84.263)\tAcc@5 100.000 (98.772)\n",
            "Epoch: [1][14/16]\tTime 0.149 (0.156)\tData 0.003 (0.011)\tLoss 0.4752 (0.5314)\tAcc@1 85.938 (84.375)\tAcc@5 100.000 (98.854)\n",
            "Epoch: [1][15/16]\tTime 0.100 (0.152)\tData 0.002 (0.011)\tLoss 0.3759 (0.5252)\tAcc@1 87.500 (84.500)\tAcc@5 100.000 (98.900)\n",
            "Epoch: [2][0/16]\tTime 0.363 (0.363)\tData 0.213 (0.213)\tLoss 0.1548 (0.1548)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.379 (0.371)\tData 0.016 (0.114)\tLoss 0.1705 (0.1627)\tAcc@1 95.312 (96.094)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.389 (0.377)\tData 0.008 (0.079)\tLoss 0.1702 (0.1652)\tAcc@1 93.750 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.393 (0.381)\tData 0.004 (0.060)\tLoss 0.1649 (0.1651)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 0.380 (0.381)\tData 0.001 (0.048)\tLoss 0.1575 (0.1636)\tAcc@1 96.875 (95.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 0.390 (0.382)\tData 0.002 (0.040)\tLoss 0.1051 (0.1539)\tAcc@1 96.875 (95.833)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 0.383 (0.382)\tData 0.004 (0.035)\tLoss 0.1489 (0.1531)\tAcc@1 96.875 (95.982)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 0.380 (0.382)\tData 0.003 (0.031)\tLoss 0.1330 (0.1506)\tAcc@1 96.875 (96.094)\tAcc@5 98.438 (99.805)\n",
            "Epoch: [2][8/16]\tTime 0.391 (0.383)\tData 0.003 (0.028)\tLoss 0.1899 (0.1550)\tAcc@1 95.312 (96.007)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [2][9/16]\tTime 0.386 (0.383)\tData 0.003 (0.025)\tLoss 0.0954 (0.1490)\tAcc@1 96.875 (96.094)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [2][10/16]\tTime 0.385 (0.383)\tData 0.003 (0.023)\tLoss 0.0855 (0.1433)\tAcc@1 100.000 (96.449)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [2][11/16]\tTime 0.388 (0.384)\tData 0.002 (0.022)\tLoss 0.1048 (0.1401)\tAcc@1 98.438 (96.615)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [2][12/16]\tTime 0.384 (0.384)\tData 0.003 (0.020)\tLoss 0.0797 (0.1354)\tAcc@1 98.438 (96.755)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [2][13/16]\tTime 0.385 (0.384)\tData 0.002 (0.019)\tLoss 0.0548 (0.1297)\tAcc@1 100.000 (96.987)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [2][14/16]\tTime 0.390 (0.384)\tData 0.002 (0.018)\tLoss 0.1333 (0.1299)\tAcc@1 93.750 (96.771)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [2][15/16]\tTime 0.339 (0.382)\tData 0.002 (0.017)\tLoss 0.0970 (0.1286)\tAcc@1 95.000 (96.700)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [2][0/16]\tTime 0.280 (0.280)\tData 0.139 (0.139)\tLoss 0.6729 (0.6729)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][1/16]\tTime 0.147 (0.213)\tData 0.004 (0.072)\tLoss 0.4561 (0.5645)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.145 (0.190)\tData 0.001 (0.048)\tLoss 0.4630 (0.5306)\tAcc@1 85.938 (86.979)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.149 (0.180)\tData 0.002 (0.037)\tLoss 0.6485 (0.5601)\tAcc@1 78.125 (84.766)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][4/16]\tTime 0.146 (0.173)\tData 0.002 (0.030)\tLoss 0.4009 (0.5283)\tAcc@1 81.250 (84.062)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][5/16]\tTime 0.155 (0.170)\tData 0.002 (0.025)\tLoss 0.5215 (0.5271)\tAcc@1 82.812 (83.854)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [2][6/16]\tTime 0.167 (0.170)\tData 0.002 (0.022)\tLoss 0.4663 (0.5184)\tAcc@1 84.375 (83.929)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [2][7/16]\tTime 0.146 (0.167)\tData 0.002 (0.020)\tLoss 0.3661 (0.4994)\tAcc@1 87.500 (84.375)\tAcc@5 98.438 (99.414)\n",
            "Epoch: [2][8/16]\tTime 0.147 (0.165)\tData 0.003 (0.018)\tLoss 0.3044 (0.4777)\tAcc@1 92.188 (85.243)\tAcc@5 98.438 (99.306)\n",
            "Epoch: [2][9/16]\tTime 0.147 (0.163)\tData 0.003 (0.016)\tLoss 0.3686 (0.4668)\tAcc@1 87.500 (85.469)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][10/16]\tTime 0.145 (0.161)\tData 0.002 (0.015)\tLoss 0.8663 (0.5031)\tAcc@1 75.000 (84.517)\tAcc@5 98.438 (99.290)\n",
            "Epoch: [2][11/16]\tTime 0.148 (0.160)\tData 0.003 (0.014)\tLoss 0.6766 (0.5176)\tAcc@1 82.812 (84.375)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][12/16]\tTime 0.162 (0.160)\tData 0.002 (0.013)\tLoss 0.5405 (0.5194)\tAcc@1 82.812 (84.255)\tAcc@5 98.438 (99.159)\n",
            "Epoch: [2][13/16]\tTime 0.154 (0.160)\tData 0.002 (0.012)\tLoss 0.4205 (0.5123)\tAcc@1 90.625 (84.710)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][14/16]\tTime 0.149 (0.159)\tData 0.002 (0.012)\tLoss 0.4153 (0.5058)\tAcc@1 93.750 (85.312)\tAcc@5 100.000 (99.271)\n",
            "Epoch: [2][15/16]\tTime 0.101 (0.155)\tData 0.002 (0.011)\tLoss 0.5997 (0.5096)\tAcc@1 85.000 (85.300)\tAcc@5 100.000 (99.300)\n",
            "Top classes:  tensor([5., 8., 8., 0., 4., 6., 5., 4., 5., 0., 0., 9., 5., 7., 9., 8., 5., 7.,\n",
            "        8., 5., 4., 2., 0., 9., 4., 4., 4., 0., 3., 6., 6., 4., 4., 3., 0., 3.,\n",
            "        4., 9., 0., 5., 0., 6., 5., 6., 0., 9., 5., 0., 4., 2., 9., 8., 5., 5.,\n",
            "        8., 8., 5., 5., 5., 4., 4., 5., 4., 0., 6., 2., 0., 2., 5., 7., 0., 4.,\n",
            "        8., 8., 0., 2., 0., 5., 5., 8., 8., 8., 0., 5., 2., 4., 5., 8., 8., 0.,\n",
            "        0., 2., 8., 6., 4., 5., 6., 0., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.5000, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 25.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 25.00%\n",
            "apgd-ce - 1/1 - 2 out of 5 successfully perturbed\n",
            "robust accuracy after APGD-CE: 15.00% (total time 13.6 s)\n",
            "apgd-dlr - 1/1 - 0 out of 3 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 15.00% (total time 26.5 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 15.00%\n",
            "Adversarial accuracy: 15.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.25, 0.15)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "fajFJ2DaI5x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_Linf = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='Linf')\n",
        "model_2_Linf = model_2_Linf.to(device)\n",
        "model_2_Linf.eval()\n",
        "\n",
        "# Model training\n",
        "model_2_Linf = train_model(trainloader, testloader, model_2_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_2_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 2 with Linf\n",
        "benchmark(model_2_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "mAv_TuSXtC9H",
        "outputId": "43b105f3-526c-41ee-e546-6e9779c7fac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Sehwag2021Proxy.pt (gdrive_id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm\n",
            "From (redirected): https://drive.google.com/uc?id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm&confirm=t&uuid=56a4d53f-91aa-4bf1-b826-ee7fda184205\n",
            "To: /content/models/cifar10/Linf/Sehwag2021Proxy.pt\n",
            "100%|██████████| 1.11G/1.11G [00:19<00:00, 56.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.427 (0.427)\tData 0.214 (0.214)\tLoss 0.2920 (0.2920)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.365 (0.396)\tData 0.003 (0.108)\tLoss 0.3638 (0.3279)\tAcc@1 87.500 (91.406)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 0.364 (0.385)\tData 0.009 (0.075)\tLoss 0.3006 (0.3188)\tAcc@1 92.188 (91.667)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][3/16]\tTime 0.379 (0.384)\tData 0.003 (0.057)\tLoss 0.3908 (0.3368)\tAcc@1 84.375 (89.844)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][4/16]\tTime 0.373 (0.382)\tData 0.011 (0.048)\tLoss 0.3637 (0.3422)\tAcc@1 89.062 (89.688)\tAcc@5 96.875 (99.375)\n",
            "Epoch: [0][5/16]\tTime 0.360 (0.378)\tData 0.013 (0.042)\tLoss 0.2927 (0.3339)\tAcc@1 95.312 (90.625)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][6/16]\tTime 0.375 (0.377)\tData 0.003 (0.037)\tLoss 0.2849 (0.3269)\tAcc@1 92.188 (90.848)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [0][7/16]\tTime 0.371 (0.377)\tData 0.002 (0.032)\tLoss 0.3642 (0.3316)\tAcc@1 85.938 (90.234)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][8/16]\tTime 0.376 (0.376)\tData 0.002 (0.029)\tLoss 0.2528 (0.3228)\tAcc@1 93.750 (90.625)\tAcc@5 100.000 (99.653)\n",
            "Epoch: [0][9/16]\tTime 0.373 (0.376)\tData 0.003 (0.026)\tLoss 0.2600 (0.3165)\tAcc@1 92.188 (90.781)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][10/16]\tTime 0.370 (0.376)\tData 0.002 (0.024)\tLoss 0.1472 (0.3011)\tAcc@1 95.312 (91.193)\tAcc@5 100.000 (99.716)\n",
            "Epoch: [0][11/16]\tTime 0.377 (0.376)\tData 0.003 (0.022)\tLoss 0.0952 (0.2840)\tAcc@1 100.000 (91.927)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [0][12/16]\tTime 0.372 (0.375)\tData 0.002 (0.021)\tLoss 0.2606 (0.2822)\tAcc@1 93.750 (92.067)\tAcc@5 98.438 (99.639)\n",
            "Epoch: [0][13/16]\tTime 0.369 (0.375)\tData 0.003 (0.020)\tLoss 0.1325 (0.2715)\tAcc@1 96.875 (92.411)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [0][14/16]\tTime 0.377 (0.375)\tData 0.003 (0.018)\tLoss 0.1001 (0.2601)\tAcc@1 98.438 (92.812)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][15/16]\tTime 0.326 (0.372)\tData 0.003 (0.017)\tLoss 0.1292 (0.2548)\tAcc@1 95.000 (92.900)\tAcc@5 100.000 (99.700)\n",
            "Epoch: [0][0/16]\tTime 0.277 (0.277)\tData 0.148 (0.148)\tLoss 0.7901 (0.7901)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.144 (0.211)\tData 0.005 (0.076)\tLoss 0.7424 (0.7663)\tAcc@1 78.125 (77.344)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.142 (0.188)\tData 0.001 (0.051)\tLoss 0.4995 (0.6773)\tAcc@1 79.688 (78.125)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][3/16]\tTime 0.143 (0.177)\tData 0.004 (0.039)\tLoss 0.6041 (0.6590)\tAcc@1 75.000 (77.344)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.142 (0.170)\tData 0.001 (0.032)\tLoss 0.6362 (0.6545)\tAcc@1 75.000 (76.875)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [0][5/16]\tTime 0.149 (0.166)\tData 0.014 (0.029)\tLoss 1.0504 (0.7205)\tAcc@1 71.875 (76.042)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [0][6/16]\tTime 0.155 (0.165)\tData 0.002 (0.025)\tLoss 0.7497 (0.7246)\tAcc@1 78.125 (76.339)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [0][7/16]\tTime 0.141 (0.162)\tData 0.002 (0.022)\tLoss 0.5815 (0.7067)\tAcc@1 81.250 (76.953)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][8/16]\tTime 0.142 (0.159)\tData 0.002 (0.020)\tLoss 0.7147 (0.7076)\tAcc@1 78.125 (77.083)\tAcc@5 98.438 (99.132)\n",
            "Epoch: [0][9/16]\tTime 0.142 (0.158)\tData 0.003 (0.018)\tLoss 0.4854 (0.6854)\tAcc@1 84.375 (77.812)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][10/16]\tTime 0.142 (0.156)\tData 0.002 (0.017)\tLoss 1.0004 (0.7140)\tAcc@1 73.438 (77.415)\tAcc@5 95.312 (98.864)\n",
            "Epoch: [0][11/16]\tTime 0.142 (0.155)\tData 0.003 (0.016)\tLoss 0.5138 (0.6974)\tAcc@1 85.938 (78.125)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [0][12/16]\tTime 0.144 (0.154)\tData 0.003 (0.015)\tLoss 0.7547 (0.7018)\tAcc@1 70.312 (77.524)\tAcc@5 98.438 (98.798)\n",
            "Epoch: [0][13/16]\tTime 0.145 (0.154)\tData 0.002 (0.014)\tLoss 0.6154 (0.6956)\tAcc@1 79.688 (77.679)\tAcc@5 96.875 (98.661)\n",
            "Epoch: [0][14/16]\tTime 0.144 (0.153)\tData 0.002 (0.013)\tLoss 0.7512 (0.6993)\tAcc@1 81.250 (77.917)\tAcc@5 98.438 (98.646)\n",
            "Epoch: [0][15/16]\tTime 0.099 (0.150)\tData 0.003 (0.012)\tLoss 0.6618 (0.6978)\tAcc@1 80.000 (78.000)\tAcc@5 97.500 (98.600)\n",
            "Epoch: [1][0/16]\tTime 0.278 (0.278)\tData 0.137 (0.137)\tLoss 0.0463 (0.0463)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.370 (0.324)\tData 0.011 (0.074)\tLoss 0.0401 (0.0432)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][2/16]\tTime 0.387 (0.345)\tData 0.001 (0.050)\tLoss 0.1853 (0.0906)\tAcc@1 93.750 (97.917)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][3/16]\tTime 0.387 (0.356)\tData 0.004 (0.038)\tLoss 0.1269 (0.0996)\tAcc@1 98.438 (98.047)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [1][4/16]\tTime 0.370 (0.359)\tData 0.001 (0.031)\tLoss 0.0866 (0.0970)\tAcc@1 98.438 (98.125)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 0.382 (0.363)\tData 0.003 (0.026)\tLoss 0.1681 (0.1089)\tAcc@1 95.312 (97.656)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 0.372 (0.364)\tData 0.004 (0.023)\tLoss 0.0572 (0.1015)\tAcc@1 98.438 (97.768)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 0.373 (0.365)\tData 0.003 (0.021)\tLoss 0.0409 (0.0939)\tAcc@1 98.438 (97.852)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [1][8/16]\tTime 0.383 (0.367)\tData 0.003 (0.019)\tLoss 0.0372 (0.0876)\tAcc@1 98.438 (97.917)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [1][9/16]\tTime 0.377 (0.368)\tData 0.003 (0.017)\tLoss 0.0323 (0.0821)\tAcc@1 100.000 (98.125)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [1][10/16]\tTime 0.379 (0.369)\tData 0.003 (0.016)\tLoss 0.0581 (0.0799)\tAcc@1 98.438 (98.153)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [1][11/16]\tTime 0.383 (0.370)\tData 0.003 (0.015)\tLoss 0.0176 (0.0747)\tAcc@1 100.000 (98.307)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [1][12/16]\tTime 0.377 (0.371)\tData 0.004 (0.014)\tLoss 0.0309 (0.0713)\tAcc@1 100.000 (98.438)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [1][13/16]\tTime 0.380 (0.371)\tData 0.003 (0.013)\tLoss 0.0169 (0.0675)\tAcc@1 100.000 (98.549)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [1][14/16]\tTime 0.381 (0.372)\tData 0.003 (0.012)\tLoss 0.0344 (0.0652)\tAcc@1 98.438 (98.542)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [1][15/16]\tTime 0.333 (0.370)\tData 0.003 (0.012)\tLoss 0.1075 (0.0669)\tAcc@1 95.000 (98.400)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [1][0/16]\tTime 0.314 (0.314)\tData 0.183 (0.183)\tLoss 0.8716 (0.8716)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.151 (0.233)\tData 0.014 (0.098)\tLoss 0.6311 (0.7513)\tAcc@1 79.688 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][2/16]\tTime 0.144 (0.203)\tData 0.002 (0.066)\tLoss 0.6093 (0.7040)\tAcc@1 85.938 (80.729)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][3/16]\tTime 0.144 (0.188)\tData 0.003 (0.050)\tLoss 0.6339 (0.6864)\tAcc@1 82.812 (81.250)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [1][4/16]\tTime 0.144 (0.179)\tData 0.001 (0.040)\tLoss 0.8074 (0.7106)\tAcc@1 82.812 (81.562)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [1][5/16]\tTime 0.148 (0.174)\tData 0.003 (0.034)\tLoss 0.7762 (0.7216)\tAcc@1 76.562 (80.729)\tAcc@5 96.875 (98.698)\n",
            "Epoch: [1][6/16]\tTime 0.157 (0.172)\tData 0.002 (0.030)\tLoss 0.5822 (0.7017)\tAcc@1 84.375 (81.250)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [1][7/16]\tTime 0.144 (0.168)\tData 0.002 (0.026)\tLoss 0.6294 (0.6926)\tAcc@1 81.250 (81.250)\tAcc@5 95.312 (98.047)\n",
            "Epoch: [1][8/16]\tTime 0.144 (0.166)\tData 0.002 (0.024)\tLoss 0.5352 (0.6751)\tAcc@1 81.250 (81.250)\tAcc@5 98.438 (98.090)\n",
            "Epoch: [1][9/16]\tTime 0.143 (0.163)\tData 0.003 (0.021)\tLoss 0.6439 (0.6720)\tAcc@1 87.500 (81.875)\tAcc@5 100.000 (98.281)\n",
            "Epoch: [1][10/16]\tTime 0.144 (0.162)\tData 0.002 (0.020)\tLoss 1.0482 (0.7062)\tAcc@1 71.875 (80.966)\tAcc@5 96.875 (98.153)\n",
            "Epoch: [1][11/16]\tTime 0.145 (0.160)\tData 0.002 (0.018)\tLoss 0.7218 (0.7075)\tAcc@1 81.250 (80.990)\tAcc@5 98.438 (98.177)\n",
            "Epoch: [1][12/16]\tTime 0.148 (0.159)\tData 0.002 (0.017)\tLoss 0.6684 (0.7045)\tAcc@1 76.562 (80.649)\tAcc@5 98.438 (98.197)\n",
            "Epoch: [1][13/16]\tTime 0.148 (0.159)\tData 0.002 (0.016)\tLoss 0.4171 (0.6840)\tAcc@1 87.500 (81.138)\tAcc@5 100.000 (98.326)\n",
            "Epoch: [1][14/16]\tTime 0.148 (0.158)\tData 0.002 (0.015)\tLoss 0.4571 (0.6688)\tAcc@1 85.938 (81.458)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [1][15/16]\tTime 0.102 (0.154)\tData 0.003 (0.014)\tLoss 0.7743 (0.6731)\tAcc@1 82.500 (81.500)\tAcc@5 97.500 (98.400)\n",
            "Epoch: [2][0/16]\tTime 0.289 (0.289)\tData 0.139 (0.139)\tLoss 0.0240 (0.0240)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.373 (0.331)\tData 0.005 (0.072)\tLoss 0.0214 (0.0227)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.396 (0.353)\tData 0.001 (0.049)\tLoss 0.0352 (0.0269)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.384 (0.360)\tData 0.004 (0.037)\tLoss 0.0909 (0.0429)\tAcc@1 96.875 (99.219)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 0.378 (0.364)\tData 0.001 (0.030)\tLoss 0.1362 (0.0615)\tAcc@1 98.438 (99.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 0.390 (0.368)\tData 0.003 (0.026)\tLoss 0.0674 (0.0625)\tAcc@1 98.438 (98.958)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 0.379 (0.370)\tData 0.003 (0.022)\tLoss 0.0454 (0.0601)\tAcc@1 98.438 (98.884)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 0.380 (0.371)\tData 0.003 (0.020)\tLoss 0.0286 (0.0561)\tAcc@1 100.000 (99.023)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][8/16]\tTime 0.387 (0.373)\tData 0.002 (0.018)\tLoss 0.0170 (0.0518)\tAcc@1 100.000 (99.132)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][9/16]\tTime 0.379 (0.373)\tData 0.003 (0.016)\tLoss 0.0221 (0.0488)\tAcc@1 100.000 (99.219)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][10/16]\tTime 0.386 (0.375)\tData 0.003 (0.015)\tLoss 0.0674 (0.0505)\tAcc@1 98.438 (99.148)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][11/16]\tTime 0.385 (0.376)\tData 0.003 (0.014)\tLoss 0.0252 (0.0484)\tAcc@1 100.000 (99.219)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][12/16]\tTime 0.381 (0.376)\tData 0.003 (0.013)\tLoss 0.0171 (0.0460)\tAcc@1 100.000 (99.279)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][13/16]\tTime 0.385 (0.377)\tData 0.003 (0.013)\tLoss 0.1153 (0.0509)\tAcc@1 95.312 (98.996)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][14/16]\tTime 0.385 (0.377)\tData 0.002 (0.012)\tLoss 0.0202 (0.0489)\tAcc@1 100.000 (99.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][15/16]\tTime 0.337 (0.375)\tData 0.002 (0.011)\tLoss 0.0255 (0.0480)\tAcc@1 100.000 (99.100)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][0/16]\tTime 0.272 (0.272)\tData 0.137 (0.137)\tLoss 0.6371 (0.6371)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.148 (0.210)\tData 0.006 (0.072)\tLoss 0.4623 (0.5497)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.145 (0.188)\tData 0.001 (0.048)\tLoss 0.4616 (0.5203)\tAcc@1 90.625 (83.333)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.147 (0.178)\tData 0.003 (0.037)\tLoss 0.7501 (0.5778)\tAcc@1 75.000 (81.250)\tAcc@5 96.875 (99.219)\n",
            "Epoch: [2][4/16]\tTime 0.147 (0.172)\tData 0.001 (0.030)\tLoss 0.9149 (0.6452)\tAcc@1 71.875 (79.375)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][5/16]\tTime 0.151 (0.168)\tData 0.003 (0.025)\tLoss 0.7388 (0.6608)\tAcc@1 78.125 (79.167)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][6/16]\tTime 0.165 (0.168)\tData 0.002 (0.022)\tLoss 0.6838 (0.6641)\tAcc@1 75.000 (78.571)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [2][7/16]\tTime 0.146 (0.165)\tData 0.003 (0.019)\tLoss 0.6502 (0.6624)\tAcc@1 81.250 (78.906)\tAcc@5 96.875 (99.023)\n",
            "Epoch: [2][8/16]\tTime 0.146 (0.163)\tData 0.002 (0.018)\tLoss 0.6001 (0.6554)\tAcc@1 81.250 (79.167)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [2][9/16]\tTime 0.145 (0.161)\tData 0.002 (0.016)\tLoss 0.5374 (0.6436)\tAcc@1 84.375 (79.688)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [2][10/16]\tTime 0.145 (0.160)\tData 0.002 (0.015)\tLoss 1.0688 (0.6823)\tAcc@1 78.125 (79.545)\tAcc@5 90.625 (98.295)\n",
            "Epoch: [2][11/16]\tTime 0.149 (0.159)\tData 0.003 (0.014)\tLoss 0.5454 (0.6709)\tAcc@1 85.938 (80.078)\tAcc@5 98.438 (98.307)\n",
            "Epoch: [2][12/16]\tTime 0.154 (0.158)\tData 0.003 (0.013)\tLoss 0.6887 (0.6723)\tAcc@1 81.250 (80.168)\tAcc@5 96.875 (98.197)\n",
            "Epoch: [2][13/16]\tTime 0.154 (0.158)\tData 0.003 (0.012)\tLoss 0.4107 (0.6536)\tAcc@1 87.500 (80.692)\tAcc@5 100.000 (98.326)\n",
            "Epoch: [2][14/16]\tTime 0.147 (0.157)\tData 0.003 (0.012)\tLoss 0.5080 (0.6439)\tAcc@1 84.375 (80.938)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [2][15/16]\tTime 0.100 (0.154)\tData 0.003 (0.011)\tLoss 0.5153 (0.6387)\tAcc@1 85.000 (81.100)\tAcc@5 95.000 (98.300)\n",
            "Top classes:  tensor([5., 8., 8., 0., 0., 8., 5., 0., 5., 8., 0., 8., 5., 7., 8., 8., 3., 3.,\n",
            "        8., 5., 3., 0., 8., 3., 0., 8., 2., 0., 3., 4., 4., 4., 0., 3., 8., 3.,\n",
            "        2., 3., 3., 5., 0., 6., 5., 0., 8., 8., 5., 0., 0., 0., 8., 8., 3., 8.,\n",
            "        8., 8., 5., 3., 0., 2., 5., 5., 3., 8., 5., 5., 8., 2., 8., 8., 0., 4.,\n",
            "        8., 8., 8., 0., 0., 5., 5., 8., 0., 3., 8., 5., 0., 4., 5., 8., 8., 8.,\n",
            "        8., 8., 8., 6., 8., 5., 3., 0., 0., 3.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.2500, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 30.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 30.00%\n",
            "apgd-ce - 1/1 - 3 out of 6 successfully perturbed\n",
            "robust accuracy after APGD-CE: 15.00% (total time 14.2 s)\n",
            "apgd-dlr - 1/1 - 0 out of 3 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 15.00% (total time 27.0 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 15.00%\n",
            "Adversarial accuracy: 15.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3, 0.15)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMA Training: Direct Input Space Margin Maximization through Adversarial Training (WideResNet-28-4)"
      ],
      "metadata": {
        "id": "I2nOuLxdeSz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "R-6Nq9NPJ_Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_L2 = load_model(model_name='Ding2020MMA', dataset='cifar10', threat_model='L2')\n",
        "model_3_L2 = model_3_L2.to(device)\n",
        "model_3_L2.eval()\n",
        "\n",
        "# Model training\n",
        "model_3_L2 = train_model(trainloader, testloader, model_3_L2, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_3_L2, sigma, x_test, y_test, 'L2')\n",
        "\n",
        "# AutoAttack on model 3 with L2\n",
        "benchmark(model_3_L2, threat_model=ThreatModel.L2, n_examples=n_examples, eps=eps_L2, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "SA8WQsoZeWIc",
        "outputId": "81e9e7c1-e736-42a5-de2d-42193da8551f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/L2/Ding2020MMA.pt (gdrive_id=13wgY0Q_eor52ltZ0PkfJx5BCZ8cLM52E).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13wgY0Q_eor52ltZ0PkfJx5BCZ8cLM52E\n",
            "To: /content/models/cifar10/L2/Ding2020MMA.pt\n",
            "100%|██████████| 23.4M/23.4M [00:00<00:00, 101MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.217 (0.217)\tData 0.153 (0.153)\tLoss 1.0921 (1.0921)\tAcc@1 76.562 (76.562)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [0][1/16]\tTime 0.081 (0.149)\tData 0.004 (0.078)\tLoss 0.9147 (1.0034)\tAcc@1 82.812 (79.688)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [0][2/16]\tTime 0.091 (0.130)\tData 0.001 (0.052)\tLoss 0.6653 (0.8907)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (97.396)\n",
            "Epoch: [0][3/16]\tTime 0.087 (0.119)\tData 0.002 (0.040)\tLoss 0.8752 (0.8868)\tAcc@1 76.562 (78.906)\tAcc@5 100.000 (98.047)\n",
            "Epoch: [0][4/16]\tTime 0.070 (0.109)\tData 0.003 (0.032)\tLoss 0.9947 (0.9084)\tAcc@1 71.875 (77.500)\tAcc@5 95.312 (97.500)\n",
            "Epoch: [0][5/16]\tTime 0.068 (0.102)\tData 0.002 (0.027)\tLoss 0.7117 (0.8756)\tAcc@1 79.688 (77.865)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [0][6/16]\tTime 0.071 (0.098)\tData 0.002 (0.024)\tLoss 0.6950 (0.8498)\tAcc@1 78.125 (77.902)\tAcc@5 100.000 (97.991)\n",
            "Epoch: [0][7/16]\tTime 0.070 (0.094)\tData 0.010 (0.022)\tLoss 1.2003 (0.8936)\tAcc@1 71.875 (77.148)\tAcc@5 100.000 (98.242)\n",
            "Epoch: [0][8/16]\tTime 0.065 (0.091)\tData 0.002 (0.020)\tLoss 0.5401 (0.8543)\tAcc@1 85.938 (78.125)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][9/16]\tTime 0.071 (0.089)\tData 0.002 (0.018)\tLoss 1.0366 (0.8726)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (98.281)\n",
            "Epoch: [0][10/16]\tTime 0.066 (0.087)\tData 0.002 (0.017)\tLoss 0.7722 (0.8634)\tAcc@1 79.688 (78.267)\tAcc@5 98.438 (98.295)\n",
            "Epoch: [0][11/16]\tTime 0.069 (0.086)\tData 0.002 (0.015)\tLoss 0.8539 (0.8627)\tAcc@1 79.688 (78.385)\tAcc@5 96.875 (98.177)\n",
            "Epoch: [0][12/16]\tTime 0.071 (0.084)\tData 0.002 (0.014)\tLoss 1.3573 (0.9007)\tAcc@1 70.312 (77.764)\tAcc@5 95.312 (97.957)\n",
            "Epoch: [0][13/16]\tTime 0.065 (0.083)\tData 0.002 (0.014)\tLoss 0.7491 (0.8899)\tAcc@1 81.250 (78.013)\tAcc@5 98.438 (97.991)\n",
            "Epoch: [0][14/16]\tTime 0.068 (0.082)\tData 0.002 (0.013)\tLoss 1.0342 (0.8995)\tAcc@1 75.000 (77.812)\tAcc@5 96.875 (97.917)\n",
            "Epoch: [0][15/16]\tTime 0.072 (0.081)\tData 0.002 (0.012)\tLoss 0.1132 (0.8680)\tAcc@1 97.500 (78.600)\tAcc@5 100.000 (98.000)\n",
            "Epoch: [0][0/16]\tTime 0.176 (0.176)\tData 0.150 (0.150)\tLoss 0.7957 (0.7957)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.033 (0.104)\tData 0.010 (0.080)\tLoss 0.9109 (0.8533)\tAcc@1 79.688 (78.906)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.022 (0.077)\tData 0.001 (0.054)\tLoss 1.3036 (1.0034)\tAcc@1 73.438 (77.083)\tAcc@5 95.312 (97.396)\n",
            "Epoch: [0][3/16]\tTime 0.025 (0.064)\tData 0.004 (0.041)\tLoss 0.8822 (0.9731)\tAcc@1 81.250 (78.125)\tAcc@5 96.875 (97.266)\n",
            "Epoch: [0][4/16]\tTime 0.023 (0.055)\tData 0.002 (0.033)\tLoss 1.2626 (1.0310)\tAcc@1 68.750 (76.250)\tAcc@5 98.438 (97.500)\n",
            "Epoch: [0][5/16]\tTime 0.029 (0.051)\tData 0.003 (0.028)\tLoss 1.3801 (1.0892)\tAcc@1 73.438 (75.781)\tAcc@5 96.875 (97.396)\n",
            "Epoch: [0][6/16]\tTime 0.023 (0.047)\tData 0.002 (0.025)\tLoss 0.8073 (1.0489)\tAcc@1 75.000 (75.670)\tAcc@5 98.438 (97.545)\n",
            "Epoch: [0][7/16]\tTime 0.024 (0.044)\tData 0.003 (0.022)\tLoss 0.8148 (1.0197)\tAcc@1 78.125 (75.977)\tAcc@5 100.000 (97.852)\n",
            "Epoch: [0][8/16]\tTime 0.029 (0.042)\tData 0.007 (0.020)\tLoss 0.6975 (0.9839)\tAcc@1 82.812 (76.736)\tAcc@5 100.000 (98.090)\n",
            "Epoch: [0][9/16]\tTime 0.024 (0.041)\tData 0.003 (0.019)\tLoss 0.9710 (0.9826)\tAcc@1 75.000 (76.562)\tAcc@5 100.000 (98.281)\n",
            "Epoch: [0][10/16]\tTime 0.023 (0.039)\tData 0.002 (0.017)\tLoss 1.2386 (1.0059)\tAcc@1 73.438 (76.278)\tAcc@5 96.875 (98.153)\n",
            "Epoch: [0][11/16]\tTime 0.023 (0.038)\tData 0.002 (0.016)\tLoss 0.6012 (0.9721)\tAcc@1 84.375 (76.953)\tAcc@5 98.438 (98.177)\n",
            "Epoch: [0][12/16]\tTime 0.023 (0.036)\tData 0.002 (0.015)\tLoss 1.2833 (0.9961)\tAcc@1 71.875 (76.562)\tAcc@5 93.750 (97.837)\n",
            "Epoch: [0][13/16]\tTime 0.023 (0.035)\tData 0.002 (0.014)\tLoss 0.9541 (0.9931)\tAcc@1 73.438 (76.339)\tAcc@5 98.438 (97.879)\n",
            "Epoch: [0][14/16]\tTime 0.023 (0.035)\tData 0.002 (0.013)\tLoss 0.9152 (0.9879)\tAcc@1 78.125 (76.458)\tAcc@5 96.875 (97.812)\n",
            "Epoch: [0][15/16]\tTime 0.017 (0.034)\tData 0.002 (0.012)\tLoss 0.6732 (0.9753)\tAcc@1 85.000 (76.800)\tAcc@5 97.500 (97.800)\n",
            "Epoch: [1][0/16]\tTime 0.185 (0.185)\tData 0.138 (0.138)\tLoss 0.8830 (0.8830)\tAcc@1 73.438 (73.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.057 (0.121)\tData 0.005 (0.072)\tLoss 1.1371 (1.0101)\tAcc@1 82.812 (78.125)\tAcc@5 93.750 (96.875)\n",
            "Epoch: [1][2/16]\tTime 0.068 (0.103)\tData 0.001 (0.048)\tLoss 1.0319 (1.0173)\tAcc@1 75.000 (77.083)\tAcc@5 98.438 (97.396)\n",
            "Epoch: [1][3/16]\tTime 0.068 (0.094)\tData 0.002 (0.037)\tLoss 1.0277 (1.0199)\tAcc@1 68.750 (75.000)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [1][4/16]\tTime 0.069 (0.089)\tData 0.002 (0.030)\tLoss 0.9426 (1.0045)\tAcc@1 76.562 (75.312)\tAcc@5 95.312 (97.188)\n",
            "Epoch: [1][5/16]\tTime 0.072 (0.087)\tData 0.002 (0.025)\tLoss 1.2104 (1.0388)\tAcc@1 70.312 (74.479)\tAcc@5 96.875 (97.135)\n",
            "Epoch: [1][6/16]\tTime 0.070 (0.084)\tData 0.002 (0.022)\tLoss 1.1245 (1.0510)\tAcc@1 65.625 (73.214)\tAcc@5 96.875 (97.098)\n",
            "Epoch: [1][7/16]\tTime 0.067 (0.082)\tData 0.002 (0.020)\tLoss 0.4723 (0.9787)\tAcc@1 89.062 (75.195)\tAcc@5 96.875 (97.070)\n",
            "Epoch: [1][8/16]\tTime 0.068 (0.080)\tData 0.002 (0.018)\tLoss 1.0970 (0.9918)\tAcc@1 78.125 (75.521)\tAcc@5 96.875 (97.049)\n",
            "Epoch: [1][9/16]\tTime 0.069 (0.079)\tData 0.002 (0.016)\tLoss 0.8289 (0.9755)\tAcc@1 79.688 (75.938)\tAcc@5 98.438 (97.188)\n",
            "Epoch: [1][10/16]\tTime 0.070 (0.078)\tData 0.002 (0.015)\tLoss 0.5861 (0.9401)\tAcc@1 85.938 (76.847)\tAcc@5 96.875 (97.159)\n",
            "Epoch: [1][11/16]\tTime 0.066 (0.077)\tData 0.002 (0.014)\tLoss 0.5120 (0.9045)\tAcc@1 85.938 (77.604)\tAcc@5 100.000 (97.396)\n",
            "Epoch: [1][12/16]\tTime 0.074 (0.077)\tData 0.002 (0.013)\tLoss 0.5919 (0.8804)\tAcc@1 84.375 (78.125)\tAcc@5 98.438 (97.476)\n",
            "Epoch: [1][13/16]\tTime 0.076 (0.077)\tData 0.003 (0.012)\tLoss 0.7876 (0.8738)\tAcc@1 81.250 (78.348)\tAcc@5 98.438 (97.545)\n",
            "Epoch: [1][14/16]\tTime 0.072 (0.077)\tData 0.003 (0.012)\tLoss 0.7189 (0.8635)\tAcc@1 84.375 (78.750)\tAcc@5 100.000 (97.708)\n",
            "Epoch: [1][15/16]\tTime 0.063 (0.076)\tData 0.002 (0.011)\tLoss 0.5198 (0.8497)\tAcc@1 90.000 (79.200)\tAcc@5 92.500 (97.500)\n",
            "Epoch: [1][0/16]\tTime 0.217 (0.217)\tData 0.187 (0.187)\tLoss 0.5663 (0.5663)\tAcc@1 82.812 (82.812)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [1][1/16]\tTime 0.086 (0.151)\tData 0.065 (0.126)\tLoss 0.5868 (0.5765)\tAcc@1 81.250 (82.031)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [1][2/16]\tTime 0.026 (0.109)\tData 0.001 (0.084)\tLoss 0.8122 (0.6551)\tAcc@1 75.000 (79.688)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [1][3/16]\tTime 0.024 (0.088)\tData 0.002 (0.064)\tLoss 0.6777 (0.6607)\tAcc@1 84.375 (80.859)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [1][4/16]\tTime 0.031 (0.077)\tData 0.008 (0.053)\tLoss 0.8924 (0.7071)\tAcc@1 71.875 (79.062)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [1][5/16]\tTime 0.028 (0.069)\tData 0.008 (0.045)\tLoss 0.9482 (0.7473)\tAcc@1 79.688 (79.167)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [1][6/16]\tTime 0.040 (0.065)\tData 0.017 (0.041)\tLoss 0.7868 (0.7529)\tAcc@1 81.250 (79.464)\tAcc@5 98.438 (98.661)\n",
            "Epoch: [1][7/16]\tTime 0.022 (0.059)\tData 0.002 (0.036)\tLoss 0.4440 (0.7143)\tAcc@1 82.812 (79.883)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [1][8/16]\tTime 0.052 (0.059)\tData 0.031 (0.036)\tLoss 0.7901 (0.7227)\tAcc@1 78.125 (79.688)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][9/16]\tTime 0.027 (0.055)\tData 0.001 (0.032)\tLoss 0.7114 (0.7216)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [1][10/16]\tTime 0.044 (0.054)\tData 0.014 (0.031)\tLoss 0.9184 (0.7395)\tAcc@1 76.562 (79.403)\tAcc@5 98.438 (99.006)\n",
            "Epoch: [1][11/16]\tTime 0.023 (0.052)\tData 0.001 (0.028)\tLoss 0.7810 (0.7429)\tAcc@1 78.125 (79.297)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [1][12/16]\tTime 0.040 (0.051)\tData 0.020 (0.027)\tLoss 1.1116 (0.7713)\tAcc@1 73.438 (78.846)\tAcc@5 98.438 (98.918)\n",
            "Epoch: [1][13/16]\tTime 0.021 (0.049)\tData 0.001 (0.026)\tLoss 1.1355 (0.7973)\tAcc@1 76.562 (78.683)\tAcc@5 96.875 (98.772)\n",
            "Epoch: [1][14/16]\tTime 0.024 (0.047)\tData 0.004 (0.024)\tLoss 0.4981 (0.7774)\tAcc@1 85.938 (79.167)\tAcc@5 100.000 (98.854)\n",
            "Epoch: [1][15/16]\tTime 0.016 (0.045)\tData 0.001 (0.023)\tLoss 0.6170 (0.7709)\tAcc@1 85.000 (79.400)\tAcc@5 97.500 (98.800)\n",
            "Epoch: [2][0/16]\tTime 0.269 (0.269)\tData 0.201 (0.201)\tLoss 0.4042 (0.4042)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.067 (0.168)\tData 0.008 (0.104)\tLoss 0.8575 (0.6308)\tAcc@1 73.438 (79.688)\tAcc@5 95.312 (97.656)\n",
            "Epoch: [2][2/16]\tTime 0.066 (0.134)\tData 0.004 (0.071)\tLoss 0.8217 (0.6945)\tAcc@1 78.125 (79.167)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [2][3/16]\tTime 0.073 (0.119)\tData 0.003 (0.054)\tLoss 0.7583 (0.7104)\tAcc@1 78.125 (78.906)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [2][4/16]\tTime 0.075 (0.110)\tData 0.012 (0.046)\tLoss 1.1368 (0.7957)\tAcc@1 73.438 (77.812)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [2][5/16]\tTime 0.061 (0.102)\tData 0.004 (0.039)\tLoss 0.5799 (0.7597)\tAcc@1 85.938 (79.167)\tAcc@5 100.000 (98.698)\n",
            "Epoch: [2][6/16]\tTime 0.069 (0.097)\tData 0.012 (0.035)\tLoss 0.5268 (0.7265)\tAcc@1 81.250 (79.464)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [2][7/16]\tTime 0.071 (0.094)\tData 0.003 (0.031)\tLoss 0.5554 (0.7051)\tAcc@1 85.938 (80.273)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [2][8/16]\tTime 0.068 (0.091)\tData 0.003 (0.028)\tLoss 0.7548 (0.7106)\tAcc@1 81.250 (80.382)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [2][9/16]\tTime 0.072 (0.089)\tData 0.002 (0.025)\tLoss 0.3679 (0.6763)\tAcc@1 87.500 (81.094)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [2][10/16]\tTime 0.066 (0.087)\tData 0.003 (0.023)\tLoss 0.9464 (0.7009)\tAcc@1 85.938 (81.534)\tAcc@5 95.312 (98.722)\n",
            "Epoch: [2][11/16]\tTime 0.070 (0.086)\tData 0.003 (0.021)\tLoss 0.5064 (0.6847)\tAcc@1 81.250 (81.510)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [2][12/16]\tTime 0.073 (0.085)\tData 0.002 (0.020)\tLoss 1.2844 (0.7308)\tAcc@1 68.750 (80.529)\tAcc@5 96.875 (98.678)\n",
            "Epoch: [2][13/16]\tTime 0.071 (0.084)\tData 0.003 (0.019)\tLoss 1.0510 (0.7537)\tAcc@1 76.562 (80.246)\tAcc@5 96.875 (98.549)\n",
            "Epoch: [2][14/16]\tTime 0.070 (0.083)\tData 0.003 (0.018)\tLoss 0.7423 (0.7529)\tAcc@1 81.250 (80.312)\tAcc@5 100.000 (98.646)\n",
            "Epoch: [2][15/16]\tTime 0.066 (0.082)\tData 0.002 (0.017)\tLoss 0.7272 (0.7519)\tAcc@1 82.500 (80.400)\tAcc@5 95.000 (98.500)\n",
            "Epoch: [2][0/16]\tTime 0.226 (0.226)\tData 0.202 (0.202)\tLoss 0.6964 (0.6964)\tAcc@1 84.375 (84.375)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [2][1/16]\tTime 0.081 (0.153)\tData 0.060 (0.131)\tLoss 0.8128 (0.7546)\tAcc@1 75.000 (79.688)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [2][2/16]\tTime 0.033 (0.113)\tData 0.010 (0.090)\tLoss 0.8044 (0.7712)\tAcc@1 75.000 (78.125)\tAcc@5 98.438 (97.917)\n",
            "Epoch: [2][3/16]\tTime 0.023 (0.091)\tData 0.003 (0.068)\tLoss 0.9185 (0.8080)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (97.656)\n",
            "Epoch: [2][4/16]\tTime 0.022 (0.077)\tData 0.001 (0.055)\tLoss 1.0432 (0.8551)\tAcc@1 73.438 (77.188)\tAcc@5 100.000 (98.125)\n",
            "Epoch: [2][5/16]\tTime 0.025 (0.068)\tData 0.003 (0.046)\tLoss 1.1580 (0.9056)\tAcc@1 75.000 (76.823)\tAcc@5 95.312 (97.656)\n",
            "Epoch: [2][6/16]\tTime 0.033 (0.063)\tData 0.001 (0.040)\tLoss 0.8048 (0.8912)\tAcc@1 71.875 (76.116)\tAcc@5 98.438 (97.768)\n",
            "Epoch: [2][7/16]\tTime 0.028 (0.059)\tData 0.007 (0.036)\tLoss 0.5254 (0.8454)\tAcc@1 81.250 (76.758)\tAcc@5 100.000 (98.047)\n",
            "Epoch: [2][8/16]\tTime 0.022 (0.055)\tData 0.001 (0.032)\tLoss 0.6088 (0.8191)\tAcc@1 81.250 (77.257)\tAcc@5 100.000 (98.264)\n",
            "Epoch: [2][9/16]\tTime 0.031 (0.052)\tData 0.011 (0.030)\tLoss 0.8293 (0.8202)\tAcc@1 81.250 (77.656)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [2][10/16]\tTime 0.021 (0.050)\tData 0.001 (0.027)\tLoss 1.3216 (0.8657)\tAcc@1 73.438 (77.273)\tAcc@5 95.312 (98.153)\n",
            "Epoch: [2][11/16]\tTime 0.024 (0.047)\tData 0.003 (0.025)\tLoss 0.9539 (0.8731)\tAcc@1 73.438 (76.953)\tAcc@5 98.438 (98.177)\n",
            "Epoch: [2][12/16]\tTime 0.022 (0.046)\tData 0.002 (0.023)\tLoss 1.0891 (0.8897)\tAcc@1 78.125 (77.043)\tAcc@5 96.875 (98.077)\n",
            "Epoch: [2][13/16]\tTime 0.023 (0.044)\tData 0.002 (0.022)\tLoss 0.7461 (0.8794)\tAcc@1 78.125 (77.121)\tAcc@5 98.438 (98.103)\n",
            "Epoch: [2][14/16]\tTime 0.022 (0.042)\tData 0.002 (0.021)\tLoss 0.6149 (0.8618)\tAcc@1 81.250 (77.396)\tAcc@5 98.438 (98.125)\n",
            "Epoch: [2][15/16]\tTime 0.017 (0.041)\tData 0.002 (0.019)\tLoss 0.8048 (0.8595)\tAcc@1 85.000 (77.700)\tAcc@5 97.500 (98.100)\n",
            "Top classes:  tensor([5., 9., 9., 4., 4., 6., 3., 6., 6., 9., 4., 9., 4., 7., 9., 4., 5., 7.,\n",
            "        9., 6., 6., 2., 4., 9., 4., 2., 4., 4., 9., 6., 6., 4., 4., 5., 9., 6.,\n",
            "        6., 9., 9., 5., 4., 6., 5., 6., 0., 9., 6., 3., 4., 6., 9., 4., 6., 3.,\n",
            "        8., 4., 6., 4., 6., 4., 4., 3., 6., 9., 6., 6., 6., 2., 3., 9., 6., 6.,\n",
            "        6., 8., 6., 4., 4., 4., 6., 8., 4., 9., 1., 7., 2., 9., 2., 9., 8., 6.,\n",
            "        4., 4., 8., 6., 6., 6., 6., 4., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4900, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 85.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 85.00%\n",
            "apgd-ce - 1/1 - 11 out of 17 successfully perturbed\n",
            "robust accuracy after APGD-CE: 30.00% (total time 5.3 s)\n",
            "apgd-dlr - 1/1 - 0 out of 6 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 30.00% (total time 11.1 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 30.00%\n",
            "Adversarial accuracy: 30.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.85, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n4dNHMZQKP9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_Linf = load_model(model_name='Sehwag2021Proxy', dataset='cifar10', threat_model='Linf')\n",
        "model_3_Linf = model_3_Linf.to(device)\n",
        "model_3_Linf.eval()\n",
        "\n",
        "# Model training\n",
        "model_3_Linf = train_model(trainloader, testloader, model_3_Linf, epochs, sigma, device)\n",
        "\n",
        "# Model prediction and certification\n",
        "certify(model_3_Linf, sigma, x_test, y_test, 'Linf')\n",
        "\n",
        "# AutoAttack on model 3 with Linf\n",
        "benchmark(model_3_Linf, threat_model=ThreatModel.Linf, n_examples=n_examples, eps=eps_Linf, batch_size=batch_size, device=device, version=version, attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "DbXlugPutzr6",
        "outputId": "50ba8669-44be-4e12-d42d-e28f6a5bf388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 0.291 (0.291)\tData 0.148 (0.148)\tLoss 0.2397 (0.2397)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.374 (0.333)\tData 0.005 (0.077)\tLoss 0.4240 (0.3318)\tAcc@1 89.062 (92.188)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.395 (0.354)\tData 0.001 (0.052)\tLoss 0.2899 (0.3178)\tAcc@1 96.875 (93.750)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 0.383 (0.361)\tData 0.003 (0.039)\tLoss 0.3915 (0.3363)\tAcc@1 89.062 (92.578)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][4/16]\tTime 0.375 (0.364)\tData 0.001 (0.032)\tLoss 0.3671 (0.3424)\tAcc@1 84.375 (90.938)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [0][5/16]\tTime 0.388 (0.368)\tData 0.003 (0.027)\tLoss 0.3238 (0.3393)\tAcc@1 89.062 (90.625)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][6/16]\tTime 0.378 (0.369)\tData 0.003 (0.023)\tLoss 0.2725 (0.3298)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [0][7/16]\tTime 0.376 (0.370)\tData 0.003 (0.021)\tLoss 0.3198 (0.3285)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][8/16]\tTime 0.386 (0.372)\tData 0.003 (0.019)\tLoss 0.3176 (0.3273)\tAcc@1 90.625 (90.625)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [0][9/16]\tTime 0.382 (0.373)\tData 0.003 (0.017)\tLoss 0.3124 (0.3258)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [0][10/16]\tTime 0.376 (0.373)\tData 0.005 (0.016)\tLoss 0.2379 (0.3178)\tAcc@1 95.312 (91.051)\tAcc@5 100.000 (99.574)\n",
            "Epoch: [0][11/16]\tTime 0.381 (0.374)\tData 0.003 (0.015)\tLoss 0.2358 (0.3110)\tAcc@1 95.312 (91.406)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][12/16]\tTime 0.379 (0.374)\tData 0.003 (0.014)\tLoss 0.3262 (0.3122)\tAcc@1 87.500 (91.106)\tAcc@5 100.000 (99.639)\n",
            "Epoch: [0][13/16]\tTime 0.383 (0.375)\tData 0.002 (0.013)\tLoss 0.2838 (0.3101)\tAcc@1 90.625 (91.071)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [0][14/16]\tTime 0.382 (0.375)\tData 0.002 (0.012)\tLoss 0.2708 (0.3075)\tAcc@1 98.438 (91.562)\tAcc@5 98.438 (99.583)\n",
            "Epoch: [0][15/16]\tTime 0.335 (0.373)\tData 0.002 (0.012)\tLoss 0.1983 (0.3032)\tAcc@1 97.500 (91.800)\tAcc@5 100.000 (99.600)\n",
            "Epoch: [0][0/16]\tTime 0.270 (0.270)\tData 0.139 (0.139)\tLoss 0.6317 (0.6317)\tAcc@1 75.000 (75.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.148 (0.209)\tData 0.004 (0.071)\tLoss 0.6535 (0.6426)\tAcc@1 78.125 (76.562)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 0.144 (0.187)\tData 0.001 (0.048)\tLoss 0.5538 (0.6130)\tAcc@1 84.375 (79.167)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][3/16]\tTime 0.144 (0.176)\tData 0.003 (0.037)\tLoss 0.5368 (0.5939)\tAcc@1 84.375 (80.469)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [0][4/16]\tTime 0.143 (0.170)\tData 0.002 (0.030)\tLoss 0.5528 (0.5857)\tAcc@1 75.000 (79.375)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][5/16]\tTime 0.148 (0.166)\tData 0.003 (0.025)\tLoss 0.7440 (0.6121)\tAcc@1 78.125 (79.167)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [0][6/16]\tTime 0.158 (0.165)\tData 0.011 (0.023)\tLoss 0.7030 (0.6251)\tAcc@1 73.438 (78.348)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [0][7/16]\tTime 0.146 (0.163)\tData 0.003 (0.021)\tLoss 0.5698 (0.6182)\tAcc@1 79.688 (78.516)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][8/16]\tTime 0.148 (0.161)\tData 0.010 (0.020)\tLoss 0.6769 (0.6247)\tAcc@1 78.125 (78.472)\tAcc@5 96.875 (99.306)\n",
            "Epoch: [0][9/16]\tTime 0.150 (0.160)\tData 0.012 (0.019)\tLoss 0.5380 (0.6160)\tAcc@1 78.125 (78.438)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [0][10/16]\tTime 0.152 (0.159)\tData 0.014 (0.019)\tLoss 0.8420 (0.6366)\tAcc@1 73.438 (77.983)\tAcc@5 96.875 (99.006)\n",
            "Epoch: [0][11/16]\tTime 0.147 (0.158)\tData 0.009 (0.018)\tLoss 0.5649 (0.6306)\tAcc@1 84.375 (78.516)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [0][12/16]\tTime 0.149 (0.158)\tData 0.002 (0.017)\tLoss 0.6708 (0.6337)\tAcc@1 75.000 (78.245)\tAcc@5 98.438 (98.918)\n",
            "Epoch: [0][13/16]\tTime 0.149 (0.157)\tData 0.003 (0.016)\tLoss 0.5553 (0.6281)\tAcc@1 79.688 (78.348)\tAcc@5 98.438 (98.884)\n",
            "Epoch: [0][14/16]\tTime 0.148 (0.156)\tData 0.003 (0.015)\tLoss 0.6293 (0.6282)\tAcc@1 79.688 (78.438)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][15/16]\tTime 0.103 (0.153)\tData 0.003 (0.014)\tLoss 0.6809 (0.6303)\tAcc@1 80.000 (78.500)\tAcc@5 97.500 (98.900)\n",
            "Epoch: [1][0/16]\tTime 0.355 (0.355)\tData 0.204 (0.204)\tLoss 0.3513 (0.3513)\tAcc@1 89.062 (89.062)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.376 (0.365)\tData 0.003 (0.104)\tLoss 0.2727 (0.3120)\tAcc@1 89.062 (89.062)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.400 (0.377)\tData 0.004 (0.070)\tLoss 0.1749 (0.2663)\tAcc@1 96.875 (91.667)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.391 (0.380)\tData 0.001 (0.053)\tLoss 0.1291 (0.2320)\tAcc@1 95.312 (92.578)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [1][4/16]\tTime 0.374 (0.379)\tData 0.002 (0.043)\tLoss 0.1874 (0.2231)\tAcc@1 95.312 (93.125)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 0.383 (0.380)\tData 0.002 (0.036)\tLoss 0.1252 (0.2068)\tAcc@1 96.875 (93.750)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 0.381 (0.380)\tData 0.003 (0.031)\tLoss 0.1065 (0.1925)\tAcc@1 98.438 (94.420)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 0.380 (0.380)\tData 0.003 (0.028)\tLoss 0.2429 (0.1988)\tAcc@1 89.062 (93.750)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [1][8/16]\tTime 0.385 (0.381)\tData 0.003 (0.025)\tLoss 0.1439 (0.1927)\tAcc@1 96.875 (94.097)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [1][9/16]\tTime 0.382 (0.381)\tData 0.003 (0.023)\tLoss 0.1265 (0.1860)\tAcc@1 98.438 (94.531)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [1][10/16]\tTime 0.386 (0.381)\tData 0.003 (0.021)\tLoss 0.1001 (0.1782)\tAcc@1 98.438 (94.886)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [1][11/16]\tTime 0.386 (0.382)\tData 0.003 (0.019)\tLoss 0.1224 (0.1736)\tAcc@1 98.438 (95.182)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [1][12/16]\tTime 0.379 (0.381)\tData 0.003 (0.018)\tLoss 0.1062 (0.1684)\tAcc@1 98.438 (95.433)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [1][13/16]\tTime 0.386 (0.382)\tData 0.002 (0.017)\tLoss 0.0701 (0.1614)\tAcc@1 100.000 (95.759)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [1][14/16]\tTime 0.383 (0.382)\tData 0.003 (0.016)\tLoss 0.1637 (0.1615)\tAcc@1 98.438 (95.938)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [1][15/16]\tTime 0.338 (0.379)\tData 0.002 (0.015)\tLoss 0.1930 (0.1628)\tAcc@1 95.000 (95.900)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [1][0/16]\tTime 0.287 (0.287)\tData 0.154 (0.154)\tLoss 0.5446 (0.5446)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.146 (0.216)\tData 0.003 (0.079)\tLoss 0.5775 (0.5611)\tAcc@1 81.250 (82.812)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][2/16]\tTime 0.146 (0.193)\tData 0.002 (0.053)\tLoss 0.5020 (0.5414)\tAcc@1 89.062 (84.896)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][3/16]\tTime 0.146 (0.181)\tData 0.002 (0.041)\tLoss 0.5892 (0.5533)\tAcc@1 79.688 (83.594)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [1][4/16]\tTime 0.146 (0.174)\tData 0.002 (0.033)\tLoss 0.4918 (0.5410)\tAcc@1 75.000 (81.875)\tAcc@5 100.000 (98.750)\n",
            "Epoch: [1][5/16]\tTime 0.149 (0.170)\tData 0.002 (0.028)\tLoss 0.7752 (0.5801)\tAcc@1 78.125 (81.250)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [1][6/16]\tTime 0.169 (0.170)\tData 0.002 (0.024)\tLoss 0.4701 (0.5644)\tAcc@1 84.375 (81.696)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [1][7/16]\tTime 0.145 (0.167)\tData 0.002 (0.021)\tLoss 0.4880 (0.5548)\tAcc@1 79.688 (81.445)\tAcc@5 100.000 (99.023)\n",
            "Epoch: [1][8/16]\tTime 0.145 (0.164)\tData 0.002 (0.019)\tLoss 0.5833 (0.5580)\tAcc@1 79.688 (81.250)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [1][9/16]\tTime 0.145 (0.162)\tData 0.002 (0.018)\tLoss 0.4321 (0.5454)\tAcc@1 87.500 (81.875)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][10/16]\tTime 0.147 (0.161)\tData 0.002 (0.016)\tLoss 1.0438 (0.5907)\tAcc@1 75.000 (81.250)\tAcc@5 96.875 (99.006)\n",
            "Epoch: [1][11/16]\tTime 0.146 (0.160)\tData 0.002 (0.015)\tLoss 0.4973 (0.5829)\tAcc@1 84.375 (81.510)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [1][12/16]\tTime 0.151 (0.159)\tData 0.002 (0.014)\tLoss 0.6318 (0.5867)\tAcc@1 78.125 (81.250)\tAcc@5 98.438 (98.918)\n",
            "Epoch: [1][13/16]\tTime 0.151 (0.158)\tData 0.002 (0.013)\tLoss 0.4511 (0.5770)\tAcc@1 84.375 (81.473)\tAcc@5 98.438 (98.884)\n",
            "Epoch: [1][14/16]\tTime 0.149 (0.158)\tData 0.002 (0.012)\tLoss 0.6373 (0.5810)\tAcc@1 75.000 (81.042)\tAcc@5 98.438 (98.854)\n",
            "Epoch: [1][15/16]\tTime 0.100 (0.154)\tData 0.002 (0.012)\tLoss 0.6237 (0.5827)\tAcc@1 75.000 (80.800)\tAcc@5 97.500 (98.800)\n",
            "Epoch: [2][0/16]\tTime 0.293 (0.293)\tData 0.138 (0.138)\tLoss 0.0807 (0.0807)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.376 (0.334)\tData 0.005 (0.071)\tLoss 0.1559 (0.1183)\tAcc@1 95.312 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.402 (0.357)\tData 0.001 (0.048)\tLoss 0.0788 (0.1051)\tAcc@1 98.438 (97.396)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.387 (0.364)\tData 0.004 (0.037)\tLoss 0.1183 (0.1084)\tAcc@1 95.312 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 0.378 (0.367)\tData 0.001 (0.030)\tLoss 0.0895 (0.1046)\tAcc@1 98.438 (97.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 0.392 (0.371)\tData 0.003 (0.025)\tLoss 0.1251 (0.1080)\tAcc@1 98.438 (97.396)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 0.382 (0.373)\tData 0.003 (0.022)\tLoss 0.0625 (0.1015)\tAcc@1 98.438 (97.545)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 0.381 (0.374)\tData 0.003 (0.020)\tLoss 0.0779 (0.0986)\tAcc@1 96.875 (97.461)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][8/16]\tTime 0.387 (0.375)\tData 0.003 (0.018)\tLoss 0.1046 (0.0993)\tAcc@1 98.438 (97.569)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][9/16]\tTime 0.389 (0.377)\tData 0.003 (0.016)\tLoss 0.1315 (0.1025)\tAcc@1 96.875 (97.500)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][10/16]\tTime 0.383 (0.377)\tData 0.005 (0.015)\tLoss 0.0336 (0.0962)\tAcc@1 100.000 (97.727)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][11/16]\tTime 0.380 (0.377)\tData 0.003 (0.014)\tLoss 0.0327 (0.0909)\tAcc@1 100.000 (97.917)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][12/16]\tTime 0.385 (0.378)\tData 0.003 (0.013)\tLoss 0.0936 (0.0911)\tAcc@1 98.438 (97.957)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][13/16]\tTime 0.385 (0.379)\tData 0.002 (0.013)\tLoss 0.0914 (0.0912)\tAcc@1 98.438 (97.991)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][14/16]\tTime 0.382 (0.379)\tData 0.004 (0.012)\tLoss 0.0924 (0.0912)\tAcc@1 98.438 (98.021)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][15/16]\tTime 0.340 (0.376)\tData 0.003 (0.011)\tLoss 0.0336 (0.0889)\tAcc@1 100.000 (98.100)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][0/16]\tTime 0.364 (0.364)\tData 0.232 (0.232)\tLoss 0.6069 (0.6069)\tAcc@1 81.250 (81.250)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][1/16]\tTime 0.150 (0.257)\tData 0.011 (0.121)\tLoss 0.4383 (0.5226)\tAcc@1 85.938 (83.594)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.152 (0.222)\tData 0.014 (0.086)\tLoss 0.4913 (0.5122)\tAcc@1 84.375 (83.854)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.147 (0.203)\tData 0.009 (0.066)\tLoss 0.7100 (0.5616)\tAcc@1 81.250 (83.203)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][4/16]\tTime 0.153 (0.193)\tData 0.013 (0.056)\tLoss 0.6835 (0.5860)\tAcc@1 73.438 (81.250)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][5/16]\tTime 0.162 (0.188)\tData 0.009 (0.048)\tLoss 0.7738 (0.6173)\tAcc@1 79.688 (80.990)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [2][6/16]\tTime 0.156 (0.184)\tData 0.014 (0.043)\tLoss 0.4780 (0.5974)\tAcc@1 79.688 (80.804)\tAcc@5 98.438 (98.884)\n",
            "Epoch: [2][7/16]\tTime 0.150 (0.179)\tData 0.013 (0.039)\tLoss 0.4880 (0.5837)\tAcc@1 81.250 (80.859)\tAcc@5 100.000 (99.023)\n",
            "Epoch: [2][8/16]\tTime 0.152 (0.176)\tData 0.014 (0.036)\tLoss 0.7643 (0.6038)\tAcc@1 78.125 (80.556)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [2][9/16]\tTime 0.147 (0.173)\tData 0.004 (0.033)\tLoss 0.4800 (0.5914)\tAcc@1 87.500 (81.250)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][10/16]\tTime 0.151 (0.171)\tData 0.013 (0.031)\tLoss 0.7903 (0.6095)\tAcc@1 75.000 (80.682)\tAcc@5 96.875 (99.006)\n",
            "Epoch: [2][11/16]\tTime 0.147 (0.169)\tData 0.003 (0.029)\tLoss 0.5562 (0.6051)\tAcc@1 81.250 (80.729)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [2][12/16]\tTime 0.152 (0.168)\tData 0.003 (0.027)\tLoss 0.8564 (0.6244)\tAcc@1 68.750 (79.808)\tAcc@5 96.875 (98.798)\n",
            "Epoch: [2][13/16]\tTime 0.148 (0.166)\tData 0.003 (0.025)\tLoss 0.3713 (0.6063)\tAcc@1 87.500 (80.357)\tAcc@5 100.000 (98.884)\n",
            "Epoch: [2][14/16]\tTime 0.149 (0.165)\tData 0.003 (0.024)\tLoss 0.5854 (0.6049)\tAcc@1 84.375 (80.625)\tAcc@5 96.875 (98.750)\n",
            "Epoch: [2][15/16]\tTime 0.100 (0.161)\tData 0.003 (0.022)\tLoss 0.6615 (0.6072)\tAcc@1 80.000 (80.600)\tAcc@5 97.500 (98.700)\n",
            "Top classes:  tensor([5., 8., 8., 0., 5., 8., 5., 0., 5., 8., 0., 8., 5., 7., 8., 8., 3., 5.,\n",
            "        8., 5., 3., 0., 8., 3., 4., 8., 2., 0., 3., 4., 4., 4., 0., 0., 8., 3.,\n",
            "        4., 3., 3., 5., 0., 4., 5., 0., 8., 8., 5., 5., 0., 8., 8., 8., 3., 8.,\n",
            "        8., 8., 5., 5., 0., 4., 5., 5., 5., 8., 3., 5., 8., 2., 8., 8., 0., 4.,\n",
            "        8., 8., 8., 0., 0., 5., 5., 8., 0., 5., 8., 5., 0., 2., 5., 8., 8., 8.,\n",
            "        0., 5., 8., 6., 8., 5., 5., 0., 0., 3.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.2600, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 35.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 35.00%\n",
            "apgd-ce - 1/1 - 3 out of 7 successfully perturbed\n",
            "robust accuracy after APGD-CE: 20.00% (total time 16.5 s)\n",
            "apgd-dlr - 1/1 - 0 out of 4 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 20.00% (total time 30.9 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 20.00%\n",
            "Adversarial accuracy: 20.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35, 0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}