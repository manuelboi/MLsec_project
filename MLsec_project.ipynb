{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelboi/MLsec_project/blob/main/MLsec_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models:\n",
        "1. Fixing Data Augmentation to Improve Adversarial Robustness\n",
        "2. Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?\n",
        "3. MMA Training: Direct Input Space Margin Maximization through Adversarial Training"
      ],
      "metadata": {
        "id": "CcZOaHCtHRqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General imports"
      ],
      "metadata": {
        "id": "CHr8lWVj_FFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CzCcoczZsmbn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Various\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import importlib.util\n",
        "import re\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# RobustBench\n",
        "!pip install git+https://github.com/manuelboi/robustbench\n",
        "from robustbench.utils import load_model\n",
        "from robustbench.eval import benchmark\n",
        "from robustbench.data import load_cifar10\n",
        "from robustbench.model_zoo.enums import ThreatModel\n",
        "\n",
        "# Smoothing\n",
        "!git clone https://github.com/matteoturnu/smoothing.git\n",
        "!conda create -n smoothing\n",
        "!conda activate smoothing\n",
        "!conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n",
        "!conda install scipy pandas statsmodels matplotlib seaborn\n",
        "!pip install setGPU\n",
        "from smoothing.code.core import Smooth\n",
        "from smoothing.code.train import train, test\n",
        "from smoothing.code.train_utils import AverageMeter, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "bRZkGSpiPFiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Set labels\n",
        "labels_dct = {0: \"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}\n",
        "\n",
        "# Use GPU if available, otherwise use CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Computing device used: \", device)\n",
        "\n",
        "# Preparing trainset and testset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Set trainset and testset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the number of samples you want to take from the whole dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Create a subset of the dataset with the chosen number of samples\n",
        "indices = list(range(num_samples))\n",
        "train_subset = Subset(trainset, indices)\n",
        "test_subset = Subset(testset, indices)\n",
        "\n",
        "# Preparing trainloader and testloader\n",
        "batch_size = 64\n",
        "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load test samples for predict and certify\n",
        "n_test_samples_benchmark = 100\n",
        "x_test, y_test = load_cifar10(n_test_samples_benchmark)\n",
        "x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "# Setting various parameters\n",
        "epochs = 3 # used for training\n",
        "sigma = 0.5 # gaussian noise standard deviation\n",
        "n_examples = 20 # to be perturbed by AutoAttack\n",
        "eps_L2 = 0.5 # epsilon of the perturbancy for L2 norm\n",
        "eps_Linf = 8/255 # epsilon of the perturbancy with Linf norm\n",
        "version = 'custom'\n",
        "attacks_to_run=['apgd-ce', 'apgd-dlr'] # Attacks to run on the models"
      ],
      "metadata": {
        "id": "ur-xfxzJPEo3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "QwmN0U3EC3To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compact donwload and configuration of the model"
      ],
      "metadata": {
        "id": "eWnSWe-pEldG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_configure_model(name, dataset, threat_model, device):\n",
        "  # Download model from robustbench\n",
        "  model = load_model(model_name=name, dataset=dataset, threat_model=threat_model)\n",
        "\n",
        "  # Set model to the chosen device\n",
        "  model = model.to(device)\n",
        "\n",
        "  # Set model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "WfH7lE2U_b71"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for smooth model training"
      ],
      "metadata": {
        "id": "Symqohu2KxSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(trainloader, testloader, model, epochs, sigma, device):\n",
        "  criterion = CrossEntropyLoss().to(device)\n",
        "  optimizer = SGD(model.parameters())\n",
        "  scheduler = StepLR(optimizer, step_size=30)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    scheduler.step(epoch)\n",
        "    before = time.time()\n",
        "    train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, sigma, device)\n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, sigma, device)\n",
        "    after = time.time()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cntdRl_hD0TB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for measuring performances on smooth model"
      ],
      "metadata": {
        "id": "1w6B16vREnO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def certify(model, sigma, x_text, y_test, L):\n",
        "  n_classes = 10\n",
        "  alpha = 1 # (1 - alpha) is the confidence level (in this case is 0)\n",
        "  n0 = 10 # number of samples for selection\n",
        "  n = 20 # number of samples for estimation (certify) (too few samples but computation time is strongly affected with more)\n",
        "\n",
        "  smooth_model = Smooth(model, n_classes, sigma)\n",
        "\n",
        "  top_classes = list()\n",
        "  radiuses = list()\n",
        "  for x, y in zip(x_test, y_test):\n",
        "    top_class = smooth_model.predict(x, n0, alpha, batch_size=n0, device=device,)\n",
        "    top_class, radius = smooth_model.certify(x, n0, n, alpha, batch_size=n0, device=device, L=L)\n",
        "    top_classes.append(top_class)\n",
        "    radiuses.append(radius)\n",
        "\n",
        "  top_classes = torch.tensor(top_classes, dtype=torch.float64).to(device)\n",
        "  accuracy = torch.mean(top_classes == y_test, dtype=torch.float64)\n",
        "  radious = torch.mean(radiuses, dtype=torch.float64)\n",
        "\n",
        "  print(\"Top classes: \", top_classes)\n",
        "  print(\"Y classes: \", y_test)\n",
        "  print(\"Average radious found by certify: \" + float(radious.item()))\n",
        "  percentage = float(accuracy.item()) * 100\n",
        "  print(f\"Accuracy found by certify function: {percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "tGu5x_t8EabV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compact test of the model with certification and AutoAttack"
      ],
      "metadata": {
        "id": "NqyswXEcFB_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, sigma, x_test, y_test, norm, threat_model, n_examples, eps, batch_size, device, version, attacks_to_run):\n",
        "  # Model prediction and certification on smoothed samples\n",
        "  certify(model, sigma, x_test, y_test, norm)\n",
        "\n",
        "  # AutoAttack on given model\n",
        "  benchmark(model,\n",
        "            threat_model=threat_model,\n",
        "            n_examples=n_examples,\n",
        "            eps=eps,\n",
        "            batch_size=batch_size,\n",
        "            device=device,\n",
        "            version=version,\n",
        "            attacks_to_run=attacks_to_run)"
      ],
      "metadata": {
        "id": "MW9m9mnr3jlc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing Data Augmentation to Improve Adversarial Robustness (WideResNet-70-16)"
      ],
      "metadata": {
        "id": "RmnI2rBDeOEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "AvnvKSRLBp9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_L2 = load_configure_model(name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='L2', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_1_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_1_L2 = train_model(trainloader, testloader, model_1_L2, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_1_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "TbLV6iYN_UuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331e9001-8cfc-4390-e35d-aec98cdabaa5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top classes:  tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.1000, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 100.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
            "    sys.settrace(tracefunc)\n",
            "\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy: 100.00%\n",
            "apgd-ce - 1/1 - 1 out of 20 successfully perturbed\n",
            "robust accuracy after APGD-CE: 95.00% (total time 308.6 s)\n",
            "apgd-dlr - 1/1 - 1 out of 19 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 90.00% (total time 612.0 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 90.00%\n",
            "Adversarial accuracy: 90.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/16]\tTime 2.202 (2.202)\tData 0.152 (0.152)\tLoss 0.5561 (0.5561)\tAcc@1 84.375 (84.375)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.668 (1.435)\tData 0.007 (0.079)\tLoss 0.3291 (0.4426)\tAcc@1 98.438 (91.406)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 1.931 (1.600)\tData 0.001 (0.053)\tLoss 0.4241 (0.4364)\tAcc@1 93.750 (92.188)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [0][3/16]\tTime 1.908 (1.677)\tData 0.013 (0.043)\tLoss 0.5114 (0.4552)\tAcc@1 87.500 (91.016)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][4/16]\tTime 1.923 (1.726)\tData 0.003 (0.035)\tLoss 0.4678 (0.4577)\tAcc@1 89.062 (90.625)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][5/16]\tTime 1.921 (1.759)\tData 0.003 (0.030)\tLoss 0.4563 (0.4575)\tAcc@1 87.500 (90.104)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [0][6/16]\tTime 1.921 (1.782)\tData 0.003 (0.026)\tLoss 0.4236 (0.4526)\tAcc@1 89.062 (89.955)\tAcc@5 98.438 (99.554)\n",
            "Epoch: [0][7/16]\tTime 1.921 (1.799)\tData 0.003 (0.023)\tLoss 0.3536 (0.4403)\tAcc@1 95.312 (90.625)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][8/16]\tTime 1.924 (1.813)\tData 0.003 (0.021)\tLoss 0.4833 (0.4450)\tAcc@1 87.500 (90.278)\tAcc@5 100.000 (99.653)\n",
            "Epoch: [0][9/16]\tTime 1.918 (1.824)\tData 0.003 (0.019)\tLoss 0.4709 (0.4476)\tAcc@1 90.625 (90.312)\tAcc@5 98.438 (99.531)\n",
            "Epoch: [0][10/16]\tTime 1.916 (1.832)\tData 0.009 (0.018)\tLoss 0.3103 (0.4352)\tAcc@1 95.312 (90.767)\tAcc@5 100.000 (99.574)\n",
            "Epoch: [0][11/16]\tTime 1.923 (1.840)\tData 0.012 (0.017)\tLoss 0.4768 (0.4386)\tAcc@1 90.625 (90.755)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [0][12/16]\tTime 1.907 (1.845)\tData 0.002 (0.016)\tLoss 0.3481 (0.4317)\tAcc@1 98.438 (91.346)\tAcc@5 100.000 (99.639)\n",
            "Epoch: [0][13/16]\tTime 1.919 (1.850)\tData 0.002 (0.015)\tLoss 0.3789 (0.4279)\tAcc@1 92.188 (91.406)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [0][14/16]\tTime 1.918 (1.855)\tData 0.003 (0.014)\tLoss 0.4349 (0.4284)\tAcc@1 89.062 (91.250)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][15/16]\tTime 2.587 (1.900)\tData 0.003 (0.014)\tLoss 0.4017 (0.4273)\tAcc@1 90.000 (91.200)\tAcc@5 100.000 (99.700)\n",
            "Epoch: [0][0/16]\tTime 0.780 (0.780)\tData 0.219 (0.219)\tLoss 0.7501 (0.7501)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.616 (0.698)\tData 0.009 (0.114)\tLoss 0.6433 (0.6967)\tAcc@1 78.125 (76.562)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.577 (0.658)\tData 0.008 (0.079)\tLoss 0.6325 (0.6753)\tAcc@1 81.250 (78.125)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][3/16]\tTime 0.612 (0.646)\tData 0.008 (0.061)\tLoss 0.7210 (0.6867)\tAcc@1 81.250 (78.906)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.595 (0.636)\tData 0.003 (0.049)\tLoss 0.7220 (0.6938)\tAcc@1 76.562 (78.438)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [0][5/16]\tTime 0.587 (0.628)\tData 0.010 (0.043)\tLoss 0.8489 (0.7196)\tAcc@1 75.000 (77.865)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][6/16]\tTime 0.611 (0.625)\tData 0.003 (0.037)\tLoss 0.7471 (0.7235)\tAcc@1 71.875 (77.009)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][7/16]\tTime 0.578 (0.619)\tData 0.003 (0.033)\tLoss 0.6565 (0.7152)\tAcc@1 81.250 (77.539)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][8/16]\tTime 0.608 (0.618)\tData 0.003 (0.029)\tLoss 0.6171 (0.7043)\tAcc@1 81.250 (77.951)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][9/16]\tTime 0.599 (0.616)\tData 0.003 (0.027)\tLoss 0.6232 (0.6962)\tAcc@1 81.250 (78.281)\tAcc@5 100.000 (98.594)\n",
            "Epoch: [0][10/16]\tTime 0.590 (0.614)\tData 0.003 (0.025)\tLoss 0.8014 (0.7057)\tAcc@1 71.875 (77.699)\tAcc@5 98.438 (98.580)\n",
            "Epoch: [0][11/16]\tTime 0.611 (0.614)\tData 0.003 (0.023)\tLoss 0.4437 (0.6839)\tAcc@1 92.188 (78.906)\tAcc@5 98.438 (98.568)\n",
            "Epoch: [0][12/16]\tTime 0.588 (0.612)\tData 0.003 (0.021)\tLoss 0.8149 (0.6940)\tAcc@1 70.312 (78.245)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][13/16]\tTime 0.602 (0.611)\tData 0.003 (0.020)\tLoss 0.5921 (0.6867)\tAcc@1 82.812 (78.571)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][14/16]\tTime 0.599 (0.610)\tData 0.003 (0.019)\tLoss 0.5771 (0.6794)\tAcc@1 82.812 (78.854)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][15/16]\tTime 0.440 (0.600)\tData 0.003 (0.018)\tLoss 0.5602 (0.6746)\tAcc@1 85.000 (79.100)\tAcc@5 97.500 (98.400)\n",
            "Epoch: [1][0/16]\tTime 0.785 (0.785)\tData 0.138 (0.138)\tLoss 0.2815 (0.2815)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 1.923 (1.354)\tData 0.002 (0.070)\tLoss 0.3794 (0.3305)\tAcc@1 87.500 (92.969)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][2/16]\tTime 1.932 (1.547)\tData 0.003 (0.048)\tLoss 0.3097 (0.3236)\tAcc@1 93.750 (93.229)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 1.918 (1.640)\tData 0.003 (0.036)\tLoss 0.2961 (0.3167)\tAcc@1 96.875 (94.141)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [1][4/16]\tTime 1.921 (1.696)\tData 0.003 (0.030)\tLoss 0.3009 (0.3135)\tAcc@1 98.438 (95.000)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 1.921 (1.733)\tData 0.003 (0.025)\tLoss 0.3714 (0.3232)\tAcc@1 93.750 (94.792)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 1.904 (1.758)\tData 0.003 (0.022)\tLoss 0.3136 (0.3218)\tAcc@1 95.312 (94.866)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 1.927 (1.779)\tData 0.003 (0.020)\tLoss 0.3094 (0.3203)\tAcc@1 96.875 (95.117)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [1][8/16]\tTime 1.926 (1.795)\tData 0.003 (0.018)\tLoss 0.3128 (0.3194)\tAcc@1 93.750 (94.965)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [1][9/16]\tTime 1.923 (1.808)\tData 0.003 (0.016)\tLoss 0.2863 (0.3161)\tAcc@1 98.438 (95.312)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [1][10/16]\tTime 1.923 (1.818)\tData 0.012 (0.016)\tLoss 0.2579 (0.3108)\tAcc@1 98.438 (95.597)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [1][11/16]\tTime 1.923 (1.827)\tData 0.010 (0.015)\tLoss 0.3149 (0.3112)\tAcc@1 93.750 (95.443)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [1][12/16]\tTime 1.922 (1.834)\tData 0.003 (0.014)\tLoss 0.3303 (0.3126)\tAcc@1 93.750 (95.312)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [1][13/16]\tTime 1.922 (1.841)\tData 0.002 (0.013)\tLoss 0.4272 (0.3208)\tAcc@1 92.188 (95.089)\tAcc@5 98.438 (99.777)\n",
            "Epoch: [1][14/16]\tTime 1.935 (1.847)\tData 0.002 (0.013)\tLoss 0.2769 (0.3179)\tAcc@1 95.312 (95.104)\tAcc@5 100.000 (99.792)\n",
            "Epoch: [1][15/16]\tTime 1.754 (1.841)\tData 0.003 (0.012)\tLoss 0.3205 (0.3180)\tAcc@1 92.500 (95.000)\tAcc@5 100.000 (99.800)\n",
            "Epoch: [1][0/16]\tTime 1.395 (1.395)\tData 0.125 (0.125)\tLoss 0.5260 (0.5260)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.605 (1.000)\tData 0.005 (0.065)\tLoss 0.5051 (0.5155)\tAcc@1 84.375 (84.375)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.600 (0.867)\tData 0.001 (0.044)\tLoss 0.4652 (0.4988)\tAcc@1 85.938 (84.896)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.595 (0.799)\tData 0.013 (0.036)\tLoss 0.6313 (0.5319)\tAcc@1 78.125 (83.203)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.601 (0.759)\tData 0.003 (0.029)\tLoss 0.5611 (0.5377)\tAcc@1 87.500 (84.062)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.601 (0.733)\tData 0.013 (0.027)\tLoss 0.6711 (0.5600)\tAcc@1 78.125 (83.073)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [1][6/16]\tTime 0.596 (0.713)\tData 0.003 (0.023)\tLoss 0.4748 (0.5478)\tAcc@1 87.500 (83.705)\tAcc@5 98.438 (98.884)\n",
            "Epoch: [1][7/16]\tTime 0.594 (0.699)\tData 0.014 (0.022)\tLoss 0.5546 (0.5486)\tAcc@1 87.500 (84.180)\tAcc@5 96.875 (98.633)\n",
            "Epoch: [1][8/16]\tTime 0.596 (0.687)\tData 0.003 (0.020)\tLoss 0.4173 (0.5341)\tAcc@1 85.938 (84.375)\tAcc@5 100.000 (98.785)\n",
            "Epoch: [1][9/16]\tTime 0.603 (0.679)\tData 0.003 (0.018)\tLoss 0.4464 (0.5253)\tAcc@1 90.625 (85.000)\tAcc@5 100.000 (98.906)\n",
            "Epoch: [1][10/16]\tTime 0.596 (0.671)\tData 0.003 (0.017)\tLoss 0.6405 (0.5358)\tAcc@1 79.688 (84.517)\tAcc@5 95.312 (98.580)\n",
            "Epoch: [1][11/16]\tTime 0.599 (0.665)\tData 0.003 (0.016)\tLoss 0.4583 (0.5293)\tAcc@1 89.062 (84.896)\tAcc@5 98.438 (98.568)\n",
            "Epoch: [1][12/16]\tTime 0.600 (0.660)\tData 0.003 (0.015)\tLoss 0.5085 (0.5277)\tAcc@1 87.500 (85.096)\tAcc@5 100.000 (98.678)\n",
            "Epoch: [1][13/16]\tTime 0.594 (0.655)\tData 0.003 (0.014)\tLoss 0.4959 (0.5254)\tAcc@1 84.375 (85.045)\tAcc@5 100.000 (98.772)\n",
            "Epoch: [1][14/16]\tTime 0.601 (0.652)\tData 0.003 (0.013)\tLoss 0.4652 (0.5214)\tAcc@1 85.938 (85.104)\tAcc@5 100.000 (98.854)\n",
            "Epoch: [1][15/16]\tTime 0.446 (0.639)\tData 0.003 (0.012)\tLoss 0.4202 (0.5174)\tAcc@1 85.000 (85.100)\tAcc@5 100.000 (98.900)\n",
            "Epoch: [2][0/16]\tTime 0.779 (0.779)\tData 0.129 (0.129)\tLoss 0.2551 (0.2551)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 1.933 (1.356)\tData 0.005 (0.067)\tLoss 0.3638 (0.3094)\tAcc@1 93.750 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 1.932 (1.548)\tData 0.001 (0.045)\tLoss 0.3580 (0.3256)\tAcc@1 93.750 (94.792)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 1.928 (1.643)\tData 0.003 (0.035)\tLoss 0.2869 (0.3159)\tAcc@1 93.750 (94.531)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 1.925 (1.699)\tData 0.002 (0.028)\tLoss 0.3243 (0.3176)\tAcc@1 95.312 (94.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 1.929 (1.738)\tData 0.003 (0.024)\tLoss 0.3396 (0.3213)\tAcc@1 93.750 (94.531)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 1.922 (1.764)\tData 0.003 (0.021)\tLoss 0.2597 (0.3125)\tAcc@1 98.438 (95.089)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 1.920 (1.783)\tData 0.003 (0.019)\tLoss 0.2608 (0.3060)\tAcc@1 95.312 (95.117)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][8/16]\tTime 1.923 (1.799)\tData 0.003 (0.017)\tLoss 0.2787 (0.3030)\tAcc@1 95.312 (95.139)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][9/16]\tTime 1.921 (1.811)\tData 0.004 (0.016)\tLoss 0.3018 (0.3029)\tAcc@1 96.875 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][10/16]\tTime 1.938 (1.823)\tData 0.003 (0.014)\tLoss 0.2598 (0.2989)\tAcc@1 96.875 (95.455)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][11/16]\tTime 1.929 (1.832)\tData 0.015 (0.014)\tLoss 0.2743 (0.2969)\tAcc@1 96.875 (95.573)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][12/16]\tTime 1.935 (1.839)\tData 0.003 (0.014)\tLoss 0.2642 (0.2944)\tAcc@1 95.312 (95.553)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][13/16]\tTime 1.924 (1.845)\tData 0.003 (0.013)\tLoss 0.2361 (0.2902)\tAcc@1 96.875 (95.647)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][14/16]\tTime 1.939 (1.852)\tData 0.002 (0.012)\tLoss 0.3084 (0.2914)\tAcc@1 95.312 (95.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][15/16]\tTime 1.760 (1.846)\tData 0.002 (0.011)\tLoss 0.2963 (0.2916)\tAcc@1 90.000 (95.400)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][0/16]\tTime 1.396 (1.396)\tData 0.116 (0.116)\tLoss 0.4689 (0.4689)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][1/16]\tTime 0.595 (0.995)\tData 0.003 (0.060)\tLoss 0.3689 (0.4189)\tAcc@1 90.625 (89.062)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.600 (0.864)\tData 0.005 (0.041)\tLoss 0.3902 (0.4093)\tAcc@1 92.188 (90.104)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.601 (0.798)\tData 0.003 (0.032)\tLoss 0.5469 (0.4437)\tAcc@1 82.812 (88.281)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [2][4/16]\tTime 0.598 (0.758)\tData 0.003 (0.026)\tLoss 0.5243 (0.4598)\tAcc@1 81.250 (86.875)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [2][5/16]\tTime 0.605 (0.732)\tData 0.009 (0.023)\tLoss 0.5914 (0.4817)\tAcc@1 84.375 (86.458)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [2][6/16]\tTime 0.592 (0.712)\tData 0.006 (0.021)\tLoss 0.3637 (0.4649)\tAcc@1 95.312 (87.723)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [2][7/16]\tTime 0.600 (0.698)\tData 0.009 (0.019)\tLoss 0.4753 (0.4662)\tAcc@1 84.375 (87.305)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][8/16]\tTime 0.593 (0.687)\tData 0.010 (0.018)\tLoss 0.3905 (0.4578)\tAcc@1 89.062 (87.500)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [2][9/16]\tTime 0.602 (0.678)\tData 0.003 (0.017)\tLoss 0.4132 (0.4533)\tAcc@1 93.750 (88.125)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][10/16]\tTime 0.598 (0.671)\tData 0.003 (0.015)\tLoss 0.6198 (0.4684)\tAcc@1 76.562 (87.074)\tAcc@5 100.000 (99.432)\n",
            "Epoch: [2][11/16]\tTime 0.599 (0.665)\tData 0.003 (0.014)\tLoss 0.4412 (0.4662)\tAcc@1 87.500 (87.109)\tAcc@5 98.438 (99.349)\n",
            "Epoch: [2][12/16]\tTime 0.603 (0.660)\tData 0.003 (0.013)\tLoss 0.5196 (0.4703)\tAcc@1 87.500 (87.139)\tAcc@5 100.000 (99.399)\n",
            "Epoch: [2][13/16]\tTime 0.592 (0.655)\tData 0.003 (0.013)\tLoss 0.4490 (0.4688)\tAcc@1 87.500 (87.165)\tAcc@5 100.000 (99.442)\n",
            "Epoch: [2][14/16]\tTime 0.605 (0.652)\tData 0.003 (0.012)\tLoss 0.3800 (0.4628)\tAcc@1 92.188 (87.500)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][15/16]\tTime 0.448 (0.639)\tData 0.003 (0.011)\tLoss 0.3864 (0.4598)\tAcc@1 85.000 (87.400)\tAcc@5 100.000 (99.500)\n",
            "Top classes:  tensor([3., 0., 0., 0., 4., 4., 3., 6., 4., 9., 4., 9., 3., 7., 9., 8., 3., 7.,\n",
            "        8., 4., 7., 0., 4., 9., 4., 4., 4., 0., 9., 4., 6., 4., 4., 3., 0., 3.,\n",
            "        4., 9., 9., 5., 0., 4., 3., 4., 0., 9., 3., 3., 4., 4., 9., 8., 3., 4.,\n",
            "        8., 8., 7., 7., 3., 4., 4., 4., 4., 9., 6., 4., 0., 2., 3., 7., 4., 4.,\n",
            "        8., 8., 0., 4., 0., 3., 3., 8., 0., 9., 0., 7., 2., 4., 4., 3., 8., 0.,\n",
            "        0., 4., 8., 6., 4., 3., 4., 4., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4900, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 55.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 55.00%\n",
            "apgd-ce - 1/1 - 3 out of 11 successfully perturbed\n",
            "robust accuracy after APGD-CE: 40.00% (total time 177.3 s)\n",
            "apgd-dlr - 1/1 - 1 out of 8 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 35.00% (total time 359.6 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 35.00%\n",
            "Adversarial accuracy: 35.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n6gPMiYKByXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_1_Linf = load_configure_model(name='Rebuffi2021Fixing_70_16_cutmix_extra', dataset='cifar10', threat_model='Linf', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_1_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_1_Linf = train_model(trainloader, testloader, model_1_Linf, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_1_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "rA09MQ0lZ34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18186d55-c3a7-45e5-eab7-977fcfe8a2bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt (gdrive_id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg\n",
            "From (redirected): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg&confirm=t&uuid=1823685d-f2fb-44a2-8178-2e1144260e4c\n",
            "To: /content/models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt\n",
            "100%|██████████| 1.07G/1.07G [00:18<00:00, 57.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top classes:  tensor([3., 3., 3., 3., 3., 6., 3., 6., 3., 3., 3., 3., 3., 6., 6., 3., 3., 3.,\n",
            "        3., 6., 6., 2., 6., 6., 3., 3., 6., 6., 3., 6., 6., 3., 3., 6., 6., 3.,\n",
            "        6., 3., 3., 3., 3., 6., 3., 6., 3., 3., 3., 3., 6., 6., 6., 3., 6., 6.,\n",
            "        3., 3., 3., 6., 3., 3., 3., 6., 6., 6., 6., 6., 3., 3., 3., 6., 3., 6.,\n",
            "        3., 3., 6., 6., 3., 3., 3., 3., 3., 6., 3., 3., 3., 6., 3., 3., 3., 3.,\n",
            "        3., 6., 3., 6., 6., 3., 6., 3., 0., 3.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.2000, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 100.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 100.00%\n",
            "apgd-ce - 1/1 - 7 out of 20 successfully perturbed\n",
            "robust accuracy after APGD-CE: 65.00% (total time 221.7 s)\n",
            "apgd-dlr - 1/1 - 0 out of 13 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 65.00% (total time 420.8 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 65.00%\n",
            "Adversarial accuracy: 65.00%\n",
            "Epoch: [0][0/16]\tTime 0.798 (0.798)\tData 0.142 (0.142)\tLoss 0.7855 (0.7855)\tAcc@1 82.812 (82.812)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 1.945 (1.371)\tData 0.012 (0.077)\tLoss 0.6541 (0.7198)\tAcc@1 90.625 (86.719)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 1.940 (1.561)\tData 0.002 (0.052)\tLoss 0.7554 (0.7317)\tAcc@1 90.625 (88.021)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][3/16]\tTime 1.937 (1.655)\tData 0.003 (0.040)\tLoss 0.6492 (0.7110)\tAcc@1 90.625 (88.672)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][4/16]\tTime 1.937 (1.711)\tData 0.003 (0.032)\tLoss 0.6620 (0.7012)\tAcc@1 90.625 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][5/16]\tTime 1.929 (1.748)\tData 0.003 (0.027)\tLoss 0.6439 (0.6917)\tAcc@1 84.375 (88.281)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][6/16]\tTime 1.940 (1.775)\tData 0.003 (0.024)\tLoss 0.8600 (0.7157)\tAcc@1 75.000 (86.384)\tAcc@5 96.875 (99.554)\n",
            "Epoch: [0][7/16]\tTime 1.931 (1.795)\tData 0.003 (0.021)\tLoss 0.6233 (0.7042)\tAcc@1 90.625 (86.914)\tAcc@5 98.438 (99.414)\n",
            "Epoch: [0][8/16]\tTime 1.932 (1.810)\tData 0.014 (0.020)\tLoss 0.7279 (0.7068)\tAcc@1 82.812 (86.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][9/16]\tTime 1.930 (1.822)\tData 0.016 (0.020)\tLoss 0.6536 (0.7015)\tAcc@1 82.812 (86.094)\tAcc@5 98.438 (99.375)\n",
            "Epoch: [0][10/16]\tTime 1.933 (1.832)\tData 0.003 (0.018)\tLoss 0.6011 (0.6924)\tAcc@1 90.625 (86.506)\tAcc@5 100.000 (99.432)\n",
            "Epoch: [0][11/16]\tTime 1.925 (1.840)\tData 0.003 (0.017)\tLoss 0.6316 (0.6873)\tAcc@1 84.375 (86.328)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][12/16]\tTime 1.938 (1.847)\tData 0.003 (0.016)\tLoss 0.6579 (0.6851)\tAcc@1 82.812 (86.058)\tAcc@5 100.000 (99.519)\n",
            "Epoch: [0][13/16]\tTime 1.925 (1.853)\tData 0.003 (0.015)\tLoss 0.6167 (0.6802)\tAcc@1 85.938 (86.049)\tAcc@5 98.438 (99.442)\n",
            "Epoch: [0][14/16]\tTime 1.934 (1.858)\tData 0.003 (0.014)\tLoss 0.6183 (0.6760)\tAcc@1 85.938 (86.042)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [0][15/16]\tTime 1.762 (1.852)\tData 0.003 (0.014)\tLoss 0.8164 (0.6817)\tAcc@1 77.500 (85.700)\tAcc@5 97.500 (99.400)\n",
            "Epoch: [0][0/16]\tTime 1.326 (1.326)\tData 0.227 (0.227)\tLoss 0.8945 (0.8945)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.607 (0.966)\tData 0.002 (0.115)\tLoss 0.8637 (0.8791)\tAcc@1 76.562 (75.781)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.598 (0.844)\tData 0.003 (0.077)\tLoss 0.8169 (0.8584)\tAcc@1 76.562 (76.042)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][3/16]\tTime 0.594 (0.781)\tData 0.003 (0.059)\tLoss 0.8257 (0.8502)\tAcc@1 78.125 (76.562)\tAcc@5 98.438 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.601 (0.745)\tData 0.004 (0.048)\tLoss 0.8701 (0.8542)\tAcc@1 68.750 (75.000)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [0][5/16]\tTime 0.588 (0.719)\tData 0.003 (0.040)\tLoss 0.8750 (0.8576)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (98.438)\n",
            "Epoch: [0][6/16]\tTime 0.605 (0.703)\tData 0.003 (0.035)\tLoss 0.9297 (0.8679)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][7/16]\tTime 0.602 (0.690)\tData 0.003 (0.031)\tLoss 0.8381 (0.8642)\tAcc@1 73.438 (74.805)\tAcc@5 96.875 (98.242)\n",
            "Epoch: [0][8/16]\tTime 0.591 (0.679)\tData 0.003 (0.028)\tLoss 0.7946 (0.8565)\tAcc@1 76.562 (75.000)\tAcc@5 98.438 (98.264)\n",
            "Epoch: [0][9/16]\tTime 0.598 (0.671)\tData 0.003 (0.025)\tLoss 0.8687 (0.8577)\tAcc@1 73.438 (74.844)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][10/16]\tTime 0.592 (0.664)\tData 0.003 (0.023)\tLoss 0.9659 (0.8675)\tAcc@1 68.750 (74.290)\tAcc@5 96.875 (98.295)\n",
            "Epoch: [0][11/16]\tTime 0.590 (0.658)\tData 0.003 (0.022)\tLoss 0.7544 (0.8581)\tAcc@1 84.375 (75.130)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][12/16]\tTime 0.595 (0.653)\tData 0.003 (0.020)\tLoss 0.8444 (0.8570)\tAcc@1 78.125 (75.361)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][13/16]\tTime 0.596 (0.649)\tData 0.003 (0.019)\tLoss 0.8289 (0.8550)\tAcc@1 70.312 (75.000)\tAcc@5 96.875 (98.326)\n",
            "Epoch: [0][14/16]\tTime 0.589 (0.645)\tData 0.003 (0.018)\tLoss 0.8244 (0.8530)\tAcc@1 70.312 (74.688)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][15/16]\tTime 0.451 (0.633)\tData 0.003 (0.017)\tLoss 0.8106 (0.8513)\tAcc@1 82.500 (75.000)\tAcc@5 97.500 (98.400)\n",
            "Epoch: [1][0/16]\tTime 0.788 (0.788)\tData 0.147 (0.147)\tLoss 0.6187 (0.6187)\tAcc@1 85.938 (85.938)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [1][1/16]\tTime 1.939 (1.363)\tData 0.016 (0.081)\tLoss 0.4588 (0.5388)\tAcc@1 95.312 (90.625)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [1][2/16]\tTime 1.915 (1.547)\tData 0.008 (0.057)\tLoss 0.5202 (0.5326)\tAcc@1 95.312 (92.188)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][3/16]\tTime 1.929 (1.643)\tData 0.003 (0.043)\tLoss 0.6357 (0.5584)\tAcc@1 87.500 (91.016)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][4/16]\tTime 1.914 (1.697)\tData 0.003 (0.035)\tLoss 0.5259 (0.5519)\tAcc@1 89.062 (90.625)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [1][5/16]\tTime 1.921 (1.734)\tData 0.003 (0.030)\tLoss 0.5309 (0.5484)\tAcc@1 90.625 (90.625)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [1][6/16]\tTime 1.919 (1.761)\tData 0.003 (0.026)\tLoss 0.5144 (0.5435)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [1][7/16]\tTime 1.923 (1.781)\tData 0.003 (0.023)\tLoss 0.5264 (0.5414)\tAcc@1 89.062 (90.430)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][8/16]\tTime 1.920 (1.796)\tData 0.003 (0.021)\tLoss 0.5965 (0.5475)\tAcc@1 87.500 (90.104)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [1][9/16]\tTime 1.922 (1.809)\tData 0.014 (0.020)\tLoss 0.5398 (0.5467)\tAcc@1 87.500 (89.844)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][10/16]\tTime 1.922 (1.819)\tData 0.003 (0.019)\tLoss 0.4740 (0.5401)\tAcc@1 90.625 (89.915)\tAcc@5 100.000 (99.432)\n",
            "Epoch: [1][11/16]\tTime 1.920 (1.828)\tData 0.003 (0.017)\tLoss 0.5676 (0.5424)\tAcc@1 93.750 (90.234)\tAcc@5 98.438 (99.349)\n",
            "Epoch: [1][12/16]\tTime 1.924 (1.835)\tData 0.002 (0.016)\tLoss 0.4232 (0.5332)\tAcc@1 95.312 (90.625)\tAcc@5 100.000 (99.399)\n",
            "Epoch: [1][13/16]\tTime 1.903 (1.840)\tData 0.002 (0.015)\tLoss 0.4734 (0.5290)\tAcc@1 92.188 (90.737)\tAcc@5 100.000 (99.442)\n",
            "Epoch: [1][14/16]\tTime 1.919 (1.845)\tData 0.002 (0.014)\tLoss 0.5844 (0.5327)\tAcc@1 89.062 (90.625)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][15/16]\tTime 1.748 (1.839)\tData 0.003 (0.014)\tLoss 0.4018 (0.5274)\tAcc@1 95.000 (90.800)\tAcc@5 100.000 (99.500)\n",
            "Epoch: [1][0/16]\tTime 1.335 (1.335)\tData 0.196 (0.196)\tLoss 0.7226 (0.7226)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.591 (0.963)\tData 0.006 (0.101)\tLoss 0.6457 (0.6842)\tAcc@1 87.500 (85.938)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.597 (0.841)\tData 0.001 (0.068)\tLoss 0.6517 (0.6734)\tAcc@1 87.500 (86.458)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.593 (0.779)\tData 0.004 (0.052)\tLoss 0.6359 (0.6640)\tAcc@1 85.938 (86.328)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.600 (0.743)\tData 0.001 (0.042)\tLoss 0.7127 (0.6738)\tAcc@1 75.000 (84.062)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.592 (0.718)\tData 0.003 (0.035)\tLoss 0.7326 (0.6836)\tAcc@1 82.812 (83.854)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][6/16]\tTime 0.596 (0.701)\tData 0.003 (0.031)\tLoss 0.6659 (0.6810)\tAcc@1 85.938 (84.152)\tAcc@5 100.000 (99.330)\n",
            "Epoch: [1][7/16]\tTime 0.595 (0.687)\tData 0.003 (0.027)\tLoss 0.6499 (0.6772)\tAcc@1 84.375 (84.180)\tAcc@5 100.000 (99.414)\n",
            "Epoch: [1][8/16]\tTime 0.588 (0.676)\tData 0.003 (0.024)\tLoss 0.6158 (0.6703)\tAcc@1 81.250 (83.854)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][9/16]\tTime 0.588 (0.667)\tData 0.003 (0.022)\tLoss 0.6166 (0.6650)\tAcc@1 90.625 (84.531)\tAcc@5 100.000 (99.531)\n",
            "Epoch: [1][10/16]\tTime 0.593 (0.661)\tData 0.003 (0.021)\tLoss 0.7895 (0.6763)\tAcc@1 78.125 (83.949)\tAcc@5 98.438 (99.432)\n",
            "Epoch: [1][11/16]\tTime 0.595 (0.655)\tData 0.003 (0.019)\tLoss 0.6123 (0.6710)\tAcc@1 87.500 (84.245)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][12/16]\tTime 0.591 (0.650)\tData 0.003 (0.018)\tLoss 0.6800 (0.6716)\tAcc@1 78.125 (83.774)\tAcc@5 100.000 (99.519)\n",
            "Epoch: [1][13/16]\tTime 0.599 (0.647)\tData 0.003 (0.017)\tLoss 0.5890 (0.6657)\tAcc@1 87.500 (84.040)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [1][14/16]\tTime 0.593 (0.643)\tData 0.003 (0.016)\tLoss 0.5392 (0.6573)\tAcc@1 87.500 (84.271)\tAcc@5 100.000 (99.583)\n",
            "Epoch: [1][15/16]\tTime 0.441 (0.630)\tData 0.003 (0.015)\tLoss 0.6412 (0.6567)\tAcc@1 90.000 (84.500)\tAcc@5 97.500 (99.500)\n",
            "Epoch: [2][0/16]\tTime 0.780 (0.780)\tData 0.136 (0.136)\tLoss 0.5188 (0.5188)\tAcc@1 89.062 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 1.928 (1.354)\tData 0.005 (0.070)\tLoss 0.4340 (0.4764)\tAcc@1 98.438 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 1.924 (1.544)\tData 0.001 (0.047)\tLoss 0.4575 (0.4701)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 1.917 (1.637)\tData 0.004 (0.037)\tLoss 0.3835 (0.4484)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 1.907 (1.691)\tData 0.001 (0.029)\tLoss 0.3770 (0.4342)\tAcc@1 96.875 (94.375)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 1.922 (1.730)\tData 0.003 (0.025)\tLoss 0.4627 (0.4389)\tAcc@1 92.188 (94.010)\tAcc@5 98.438 (99.740)\n",
            "Epoch: [2][6/16]\tTime 1.917 (1.756)\tData 0.003 (0.022)\tLoss 0.4725 (0.4437)\tAcc@1 90.625 (93.527)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [2][7/16]\tTime 1.906 (1.775)\tData 0.003 (0.019)\tLoss 0.4490 (0.4444)\tAcc@1 93.750 (93.555)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [2][8/16]\tTime 1.911 (1.790)\tData 0.003 (0.018)\tLoss 0.4557 (0.4456)\tAcc@1 93.750 (93.576)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [2][9/16]\tTime 1.914 (1.803)\tData 0.013 (0.017)\tLoss 0.4449 (0.4456)\tAcc@1 95.312 (93.750)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [2][10/16]\tTime 1.917 (1.813)\tData 0.003 (0.016)\tLoss 0.4714 (0.4479)\tAcc@1 92.188 (93.608)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [2][11/16]\tTime 1.904 (1.821)\tData 0.003 (0.015)\tLoss 0.4750 (0.4502)\tAcc@1 92.188 (93.490)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [2][12/16]\tTime 1.919 (1.828)\tData 0.003 (0.014)\tLoss 0.4916 (0.4533)\tAcc@1 92.188 (93.389)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [2][13/16]\tTime 1.921 (1.835)\tData 0.002 (0.013)\tLoss 0.5024 (0.4569)\tAcc@1 87.500 (92.969)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [2][14/16]\tTime 1.904 (1.840)\tData 0.003 (0.012)\tLoss 0.4425 (0.4559)\tAcc@1 90.625 (92.812)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [2][15/16]\tTime 1.743 (1.834)\tData 0.005 (0.012)\tLoss 0.5236 (0.4586)\tAcc@1 92.500 (92.800)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [2][0/16]\tTime 1.305 (1.305)\tData 0.186 (0.186)\tLoss 0.5767 (0.5767)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.602 (0.953)\tData 0.006 (0.096)\tLoss 0.5877 (0.5822)\tAcc@1 87.500 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.584 (0.830)\tData 0.002 (0.065)\tLoss 0.5579 (0.5741)\tAcc@1 87.500 (88.542)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.591 (0.770)\tData 0.003 (0.049)\tLoss 0.6150 (0.5843)\tAcc@1 85.938 (87.891)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [2][4/16]\tTime 0.598 (0.736)\tData 0.002 (0.040)\tLoss 0.6311 (0.5937)\tAcc@1 81.250 (86.562)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][5/16]\tTime 0.591 (0.712)\tData 0.003 (0.034)\tLoss 0.6933 (0.6103)\tAcc@1 76.562 (84.896)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [2][6/16]\tTime 0.601 (0.696)\tData 0.003 (0.029)\tLoss 0.6000 (0.6088)\tAcc@1 81.250 (84.375)\tAcc@5 100.000 (99.554)\n",
            "Epoch: [2][7/16]\tTime 0.589 (0.683)\tData 0.003 (0.026)\tLoss 0.5834 (0.6056)\tAcc@1 84.375 (84.375)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][8/16]\tTime 0.594 (0.673)\tData 0.003 (0.023)\tLoss 0.5566 (0.6002)\tAcc@1 84.375 (84.375)\tAcc@5 100.000 (99.653)\n",
            "Epoch: [2][9/16]\tTime 0.595 (0.665)\tData 0.003 (0.021)\tLoss 0.5449 (0.5947)\tAcc@1 87.500 (84.688)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][10/16]\tTime 0.599 (0.659)\tData 0.014 (0.021)\tLoss 0.7214 (0.6062)\tAcc@1 75.000 (83.807)\tAcc@5 100.000 (99.716)\n",
            "Epoch: [2][11/16]\tTime 0.598 (0.654)\tData 0.003 (0.019)\tLoss 0.6178 (0.6071)\tAcc@1 85.938 (83.984)\tAcc@5 98.438 (99.609)\n",
            "Epoch: [2][12/16]\tTime 0.600 (0.650)\tData 0.003 (0.018)\tLoss 0.6536 (0.6107)\tAcc@1 84.375 (84.014)\tAcc@5 100.000 (99.639)\n",
            "Epoch: [2][13/16]\tTime 0.588 (0.645)\tData 0.003 (0.017)\tLoss 0.5202 (0.6043)\tAcc@1 85.938 (84.152)\tAcc@5 100.000 (99.665)\n",
            "Epoch: [2][14/16]\tTime 0.589 (0.642)\tData 0.003 (0.016)\tLoss 0.5247 (0.5990)\tAcc@1 87.500 (84.375)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [2][15/16]\tTime 0.446 (0.629)\tData 0.003 (0.015)\tLoss 0.5784 (0.5981)\tAcc@1 85.000 (84.400)\tAcc@5 97.500 (99.600)\n",
            "Top classes:  tensor([6., 8., 8., 0., 4., 4., 3., 4., 4., 8., 4., 8., 4., 7., 8., 8., 3., 7.,\n",
            "        8., 5., 7., 0., 8., 9., 4., 4., 4., 0., 3., 4., 4., 4., 4., 3., 8., 5.,\n",
            "        4., 8., 8., 5., 4., 4., 2., 4., 0., 9., 3., 3., 4., 4., 8., 8., 3., 4.,\n",
            "        8., 8., 5., 4., 4., 4., 4., 4., 4., 3., 4., 4., 8., 2., 3., 7., 4., 4.,\n",
            "        8., 8., 8., 2., 5., 5., 3., 8., 8., 8., 0., 7., 2., 2., 2., 8., 8., 8.,\n",
            "        0., 4., 8., 6., 4., 6., 4., 8., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4400, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 50.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 50.00%\n",
            "apgd-ce - 1/1 - 4 out of 10 successfully perturbed\n",
            "robust accuracy after APGD-CE: 30.00% (total time 157.8 s)\n",
            "apgd-dlr - 1/1 - 0 out of 6 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 30.00% (total time 309.7 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 30.00%\n",
            "Adversarial accuracy: 30.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness? (ResNet-18)"
      ],
      "metadata": {
        "id": "mtma9ehWeKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "qSW7z1l1Iten"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_L2 = load_configure_model(name='Sehwag2021Proxy', dataset='cifar10', threat_model='L2', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_2_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_2_L2 = train_model(trainloader, testloader, model_2_L2, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_2_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "hOl_1rinc4IX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "8b77f845-e2fa-4000-f6f2-a2baa20336d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/L2/Sehwag2021Proxy.pt (gdrive_id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S\n",
            "From (redirected): https://drive.google.com/uc?id=1UviikNzpltVFsgMuqQ8YhpmvGczGRS4S&confirm=t&uuid=683e4eb1-0dc3-449e-9096-404e69ba2874\n",
            "To: /content/models/cifar10/L2/Sehwag2021Proxy.pt\n",
            "100%|██████████| 1.11G/1.11G [00:28<00:00, 39.4MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-79ac2c35c466>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test on stock model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2_L2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThreatModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_L2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattacks_to_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Smoothed model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-664ebd0e8d7b>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, sigma, x_test, y_test, norm, threat_model, n_examples, eps, batch_size, device, version, attacks_to_run)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattacks_to_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Model prediction and certification on smoothed samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcertify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# AutoAttack on given model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-47b87dd07704>\u001b[0m in \u001b[0;36mcertify\u001b[0;34m(model, sigma, x_text, y_test, L)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtop_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtop_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtop_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mradiuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/smoothing/code/core.py\u001b[0m in \u001b[0;36mcertify\u001b[0;34m(self, x, n0, n, alpha, batch_size, device, L)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcounts_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# draw more samples of f(x + epsilon)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcounts_estimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Linf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mcounts_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_noise_linf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/smoothing/code/core.py\u001b[0m in \u001b[0;36m_sample_noise\u001b[0;34m(self, x, num, batch_size, device)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mcounts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/robustbench/model_zoo/architectures/wide_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/robustbench/model_zoo/architectures/wide_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/robustbench/model_zoo/architectures/wide_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalInOut\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvShortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "fajFJ2DaI5x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_2_Linf = load_configure_model(name='Sehwag2021Proxy', dataset='cifar10', threat_model='Linf', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_2_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_2_Linf = train_model(trainloader, testloader, model_2_Linf, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_2_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "mAv_TuSXtC9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8bcd9b-43be-405f-ad79-d010f0a0e0b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Sehwag2021Proxy.pt (gdrive_id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm\n",
            "From (redirected): https://drive.google.com/uc?id=1QFA5fPMj2Qw4aYNG33PkFqiv_RTDWvzm&confirm=t&uuid=c56df24e-a77a-41a2-8ada-23ce8afedb01\n",
            "To: /content/models/cifar10/Linf/Sehwag2021Proxy.pt\n",
            "100%|██████████| 1.11G/1.11G [00:25<00:00, 43.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top classes:  tensor([2., 9., 9., 2., 2., 6., 6., 2., 2., 2., 2., 2., 6., 7., 2., 2., 3., 2.,\n",
            "        9., 6., 2., 2., 2., 9., 2., 2., 2., 2., 2., 6., 6., 2., 2., 2., 2., 2.,\n",
            "        2., 9., 2., 2., 2., 6., 2., 6., 0., 2., 6., 2., 6., 2., 2., 2., 6., 6.,\n",
            "        9., 2., 2., 6., 2., 2., 2., 6., 6., 2., 2., 2., 2., 2., 2., 9., 2., 6.,\n",
            "        2., 2., 9., 2., 2., 6., 6., 0., 2., 9., 6., 2., 2., 2., 2., 2., 2., 2.,\n",
            "        2., 2., 2., 2., 2., 2., 2., 2., 0., 2.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.2000, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 100.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 100.00%\n",
            "apgd-ce - 1/1 - 6 out of 20 successfully perturbed\n",
            "robust accuracy after APGD-CE: 70.00% (total time 43.4 s)\n",
            "apgd-dlr - 1/1 - 1 out of 14 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 65.00% (total time 80.2 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 65.00%\n",
            "Adversarial accuracy: 65.00%\n",
            "Epoch: [0][0/16]\tTime 0.320 (0.320)\tData 0.168 (0.168)\tLoss 0.2963 (0.2963)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.389 (0.355)\tData 0.005 (0.087)\tLoss 0.2455 (0.2709)\tAcc@1 92.188 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][2/16]\tTime 0.444 (0.385)\tData 0.001 (0.058)\tLoss 0.3255 (0.2891)\tAcc@1 90.625 (92.708)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][3/16]\tTime 0.390 (0.386)\tData 0.010 (0.046)\tLoss 0.2662 (0.2834)\tAcc@1 95.312 (93.359)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][4/16]\tTime 0.395 (0.388)\tData 0.003 (0.037)\tLoss 0.2861 (0.2839)\tAcc@1 87.500 (92.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][5/16]\tTime 0.430 (0.395)\tData 0.010 (0.033)\tLoss 0.2889 (0.2848)\tAcc@1 90.625 (91.927)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][6/16]\tTime 0.388 (0.394)\tData 0.003 (0.029)\tLoss 0.3719 (0.2972)\tAcc@1 90.625 (91.741)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][7/16]\tTime 0.429 (0.398)\tData 0.008 (0.026)\tLoss 0.3535 (0.3042)\tAcc@1 89.062 (91.406)\tAcc@5 98.438 (99.805)\n",
            "Epoch: [0][8/16]\tTime 0.401 (0.398)\tData 0.003 (0.023)\tLoss 0.3090 (0.3048)\tAcc@1 90.625 (91.319)\tAcc@5 98.438 (99.653)\n",
            "Epoch: [0][9/16]\tTime 0.408 (0.399)\tData 0.009 (0.022)\tLoss 0.2680 (0.3011)\tAcc@1 89.062 (91.094)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [0][10/16]\tTime 0.412 (0.401)\tData 0.003 (0.020)\tLoss 0.2813 (0.2993)\tAcc@1 92.188 (91.193)\tAcc@5 100.000 (99.716)\n",
            "Epoch: [0][11/16]\tTime 0.399 (0.400)\tData 0.003 (0.019)\tLoss 0.2429 (0.2946)\tAcc@1 92.188 (91.276)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [0][12/16]\tTime 0.423 (0.402)\tData 0.002 (0.017)\tLoss 0.3000 (0.2950)\tAcc@1 90.625 (91.226)\tAcc@5 100.000 (99.760)\n",
            "Epoch: [0][13/16]\tTime 0.397 (0.402)\tData 0.002 (0.016)\tLoss 0.2253 (0.2900)\tAcc@1 92.188 (91.295)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [0][14/16]\tTime 0.405 (0.402)\tData 0.002 (0.015)\tLoss 0.2604 (0.2881)\tAcc@1 89.062 (91.146)\tAcc@5 100.000 (99.792)\n",
            "Epoch: [0][15/16]\tTime 0.358 (0.399)\tData 0.002 (0.015)\tLoss 0.3999 (0.2925)\tAcc@1 87.500 (91.000)\tAcc@5 100.000 (99.800)\n",
            "Epoch: [0][0/16]\tTime 0.307 (0.307)\tData 0.168 (0.168)\tLoss 0.6284 (0.6284)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.155 (0.231)\tData 0.004 (0.086)\tLoss 0.6599 (0.6442)\tAcc@1 82.812 (81.250)\tAcc@5 95.312 (97.656)\n",
            "Epoch: [0][2/16]\tTime 0.150 (0.204)\tData 0.001 (0.058)\tLoss 0.5840 (0.6241)\tAcc@1 76.562 (79.688)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][3/16]\tTime 0.153 (0.191)\tData 0.003 (0.044)\tLoss 0.5743 (0.6116)\tAcc@1 78.125 (79.297)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.151 (0.183)\tData 0.002 (0.036)\tLoss 0.5431 (0.5979)\tAcc@1 78.125 (79.062)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [0][5/16]\tTime 0.193 (0.185)\tData 0.002 (0.030)\tLoss 0.8563 (0.6410)\tAcc@1 67.188 (77.083)\tAcc@5 98.438 (98.958)\n",
            "Epoch: [0][6/16]\tTime 0.152 (0.180)\tData 0.002 (0.026)\tLoss 0.6421 (0.6412)\tAcc@1 71.875 (76.339)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [0][7/16]\tTime 0.152 (0.176)\tData 0.002 (0.023)\tLoss 0.5368 (0.6281)\tAcc@1 82.812 (77.148)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][8/16]\tTime 0.150 (0.173)\tData 0.002 (0.021)\tLoss 0.6483 (0.6304)\tAcc@1 78.125 (77.257)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [0][9/16]\tTime 0.153 (0.171)\tData 0.003 (0.019)\tLoss 0.5020 (0.6175)\tAcc@1 85.938 (78.125)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [0][10/16]\tTime 0.150 (0.169)\tData 0.002 (0.018)\tLoss 0.8590 (0.6395)\tAcc@1 73.438 (77.699)\tAcc@5 95.312 (98.722)\n",
            "Epoch: [0][11/16]\tTime 0.172 (0.170)\tData 0.002 (0.016)\tLoss 0.6118 (0.6372)\tAcc@1 79.688 (77.865)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [0][12/16]\tTime 0.167 (0.170)\tData 0.002 (0.015)\tLoss 0.6601 (0.6389)\tAcc@1 65.625 (76.923)\tAcc@5 100.000 (98.798)\n",
            "Epoch: [0][13/16]\tTime 0.157 (0.169)\tData 0.002 (0.014)\tLoss 0.6251 (0.6379)\tAcc@1 73.438 (76.674)\tAcc@5 96.875 (98.661)\n",
            "Epoch: [0][14/16]\tTime 0.150 (0.167)\tData 0.002 (0.013)\tLoss 0.6539 (0.6390)\tAcc@1 79.688 (76.875)\tAcc@5 96.875 (98.542)\n",
            "Epoch: [0][15/16]\tTime 0.108 (0.164)\tData 0.003 (0.013)\tLoss 0.6798 (0.6406)\tAcc@1 82.500 (77.100)\tAcc@5 97.500 (98.500)\n",
            "Epoch: [1][0/16]\tTime 0.315 (0.315)\tData 0.156 (0.156)\tLoss 0.1865 (0.1865)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.384 (0.349)\tData 0.005 (0.081)\tLoss 0.2453 (0.2159)\tAcc@1 96.875 (96.094)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.440 (0.380)\tData 0.001 (0.054)\tLoss 0.2759 (0.2359)\tAcc@1 92.188 (94.792)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.393 (0.383)\tData 0.003 (0.041)\tLoss 0.2100 (0.2294)\tAcc@1 93.750 (94.531)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [1][4/16]\tTime 0.399 (0.386)\tData 0.001 (0.033)\tLoss 0.1899 (0.2215)\tAcc@1 95.312 (94.688)\tAcc@5 100.000 (99.688)\n",
            "Epoch: [1][5/16]\tTime 0.428 (0.393)\tData 0.003 (0.028)\tLoss 0.1316 (0.2065)\tAcc@1 95.312 (94.792)\tAcc@5 100.000 (99.740)\n",
            "Epoch: [1][6/16]\tTime 0.397 (0.394)\tData 0.003 (0.025)\tLoss 0.1503 (0.1985)\tAcc@1 98.438 (95.312)\tAcc@5 100.000 (99.777)\n",
            "Epoch: [1][7/16]\tTime 0.425 (0.397)\tData 0.003 (0.022)\tLoss 0.1138 (0.1879)\tAcc@1 98.438 (95.703)\tAcc@5 100.000 (99.805)\n",
            "Epoch: [1][8/16]\tTime 0.405 (0.398)\tData 0.003 (0.020)\tLoss 0.1212 (0.1805)\tAcc@1 98.438 (96.007)\tAcc@5 100.000 (99.826)\n",
            "Epoch: [1][9/16]\tTime 0.408 (0.399)\tData 0.003 (0.018)\tLoss 0.1283 (0.1753)\tAcc@1 98.438 (96.250)\tAcc@5 100.000 (99.844)\n",
            "Epoch: [1][10/16]\tTime 0.415 (0.401)\tData 0.003 (0.017)\tLoss 0.1632 (0.1742)\tAcc@1 96.875 (96.307)\tAcc@5 100.000 (99.858)\n",
            "Epoch: [1][11/16]\tTime 0.401 (0.401)\tData 0.003 (0.015)\tLoss 0.1650 (0.1734)\tAcc@1 96.875 (96.354)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [1][12/16]\tTime 0.430 (0.403)\tData 0.002 (0.014)\tLoss 0.1405 (0.1709)\tAcc@1 95.312 (96.274)\tAcc@5 100.000 (99.880)\n",
            "Epoch: [1][13/16]\tTime 0.400 (0.403)\tData 0.003 (0.014)\tLoss 0.0777 (0.1642)\tAcc@1 100.000 (96.540)\tAcc@5 100.000 (99.888)\n",
            "Epoch: [1][14/16]\tTime 0.413 (0.404)\tData 0.003 (0.013)\tLoss 0.1315 (0.1621)\tAcc@1 98.438 (96.667)\tAcc@5 100.000 (99.896)\n",
            "Epoch: [1][15/16]\tTime 0.361 (0.401)\tData 0.003 (0.012)\tLoss 0.0654 (0.1582)\tAcc@1 97.500 (96.700)\tAcc@5 100.000 (99.900)\n",
            "Epoch: [1][0/16]\tTime 0.339 (0.339)\tData 0.197 (0.197)\tLoss 0.7945 (0.7945)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.156 (0.247)\tData 0.009 (0.103)\tLoss 0.5049 (0.6497)\tAcc@1 84.375 (81.250)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][2/16]\tTime 0.158 (0.218)\tData 0.010 (0.072)\tLoss 0.4911 (0.5968)\tAcc@1 87.500 (83.333)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [1][3/16]\tTime 0.151 (0.201)\tData 0.003 (0.055)\tLoss 0.5896 (0.5950)\tAcc@1 78.125 (82.031)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][4/16]\tTime 0.157 (0.192)\tData 0.012 (0.046)\tLoss 0.5297 (0.5819)\tAcc@1 81.250 (81.875)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.193 (0.192)\tData 0.010 (0.040)\tLoss 0.7255 (0.6059)\tAcc@1 76.562 (80.990)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][6/16]\tTime 0.160 (0.188)\tData 0.016 (0.037)\tLoss 0.5305 (0.5951)\tAcc@1 82.812 (81.250)\tAcc@5 98.438 (99.107)\n",
            "Epoch: [1][7/16]\tTime 0.156 (0.184)\tData 0.010 (0.033)\tLoss 0.4758 (0.5802)\tAcc@1 82.812 (81.445)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][8/16]\tTime 0.154 (0.180)\tData 0.002 (0.030)\tLoss 0.6213 (0.5848)\tAcc@1 78.125 (81.076)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [1][9/16]\tTime 0.161 (0.178)\tData 0.010 (0.028)\tLoss 0.4222 (0.5685)\tAcc@1 87.500 (81.719)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [1][10/16]\tTime 0.150 (0.176)\tData 0.003 (0.025)\tLoss 0.7890 (0.5885)\tAcc@1 76.562 (81.250)\tAcc@5 96.875 (99.148)\n",
            "Epoch: [1][11/16]\tTime 0.176 (0.176)\tData 0.014 (0.025)\tLoss 0.4152 (0.5741)\tAcc@1 89.062 (81.901)\tAcc@5 98.438 (99.089)\n",
            "Epoch: [1][12/16]\tTime 0.162 (0.175)\tData 0.003 (0.023)\tLoss 0.6229 (0.5778)\tAcc@1 75.000 (81.370)\tAcc@5 98.438 (99.038)\n",
            "Epoch: [1][13/16]\tTime 0.155 (0.173)\tData 0.003 (0.021)\tLoss 0.3630 (0.5625)\tAcc@1 82.812 (81.473)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [1][14/16]\tTime 0.157 (0.172)\tData 0.002 (0.020)\tLoss 0.4582 (0.5555)\tAcc@1 87.500 (81.875)\tAcc@5 100.000 (99.167)\n",
            "Epoch: [1][15/16]\tTime 0.107 (0.168)\tData 0.002 (0.019)\tLoss 0.5660 (0.5560)\tAcc@1 82.500 (81.900)\tAcc@5 97.500 (99.100)\n",
            "Epoch: [2][0/16]\tTime 0.325 (0.325)\tData 0.167 (0.167)\tLoss 0.0617 (0.0617)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.397 (0.361)\tData 0.004 (0.086)\tLoss 0.0532 (0.0574)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.436 (0.386)\tData 0.001 (0.057)\tLoss 0.1188 (0.0779)\tAcc@1 98.438 (99.479)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][3/16]\tTime 0.393 (0.388)\tData 0.002 (0.044)\tLoss 0.0508 (0.0711)\tAcc@1 100.000 (99.609)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][4/16]\tTime 0.401 (0.390)\tData 0.002 (0.035)\tLoss 0.0864 (0.0742)\tAcc@1 100.000 (99.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][5/16]\tTime 0.433 (0.397)\tData 0.002 (0.030)\tLoss 0.0832 (0.0757)\tAcc@1 96.875 (99.219)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][6/16]\tTime 0.400 (0.398)\tData 0.002 (0.026)\tLoss 0.0967 (0.0787)\tAcc@1 96.875 (98.884)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][7/16]\tTime 0.430 (0.402)\tData 0.003 (0.023)\tLoss 0.0482 (0.0749)\tAcc@1 98.438 (98.828)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][8/16]\tTime 0.401 (0.402)\tData 0.003 (0.021)\tLoss 0.0653 (0.0738)\tAcc@1 98.438 (98.785)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][9/16]\tTime 0.412 (0.403)\tData 0.003 (0.019)\tLoss 0.0468 (0.0711)\tAcc@1 100.000 (98.906)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][10/16]\tTime 0.416 (0.404)\tData 0.004 (0.018)\tLoss 0.0446 (0.0687)\tAcc@1 100.000 (99.006)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][11/16]\tTime 0.404 (0.404)\tData 0.003 (0.016)\tLoss 0.1198 (0.0730)\tAcc@1 98.438 (98.958)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][12/16]\tTime 0.426 (0.406)\tData 0.002 (0.015)\tLoss 0.0413 (0.0705)\tAcc@1 100.000 (99.038)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][13/16]\tTime 0.399 (0.405)\tData 0.003 (0.014)\tLoss 0.0514 (0.0692)\tAcc@1 100.000 (99.107)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][14/16]\tTime 0.415 (0.406)\tData 0.002 (0.014)\tLoss 0.0373 (0.0670)\tAcc@1 100.000 (99.167)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][15/16]\tTime 0.360 (0.403)\tData 0.003 (0.013)\tLoss 0.1132 (0.0689)\tAcc@1 95.000 (99.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][0/16]\tTime 0.288 (0.288)\tData 0.149 (0.149)\tLoss 0.7765 (0.7765)\tAcc@1 73.438 (73.438)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][1/16]\tTime 0.157 (0.222)\tData 0.005 (0.077)\tLoss 0.5513 (0.6639)\tAcc@1 81.250 (77.344)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][2/16]\tTime 0.152 (0.199)\tData 0.001 (0.052)\tLoss 0.4574 (0.5950)\tAcc@1 87.500 (80.729)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.154 (0.188)\tData 0.003 (0.039)\tLoss 0.5099 (0.5738)\tAcc@1 79.688 (80.469)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][4/16]\tTime 0.154 (0.181)\tData 0.001 (0.032)\tLoss 0.5016 (0.5593)\tAcc@1 87.500 (81.875)\tAcc@5 98.438 (99.062)\n",
            "Epoch: [2][5/16]\tTime 0.188 (0.182)\tData 0.002 (0.027)\tLoss 0.8886 (0.6142)\tAcc@1 76.562 (80.990)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][6/16]\tTime 0.154 (0.178)\tData 0.002 (0.023)\tLoss 0.5756 (0.6087)\tAcc@1 82.812 (81.250)\tAcc@5 98.438 (99.107)\n",
            "Epoch: [2][7/16]\tTime 0.153 (0.175)\tData 0.002 (0.021)\tLoss 0.5342 (0.5994)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][8/16]\tTime 0.156 (0.173)\tData 0.002 (0.019)\tLoss 0.6156 (0.6012)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (99.306)\n",
            "Epoch: [2][9/16]\tTime 0.151 (0.171)\tData 0.002 (0.017)\tLoss 0.4443 (0.5855)\tAcc@1 87.500 (81.875)\tAcc@5 100.000 (99.375)\n",
            "Epoch: [2][10/16]\tTime 0.156 (0.169)\tData 0.002 (0.016)\tLoss 0.8269 (0.6074)\tAcc@1 76.562 (81.392)\tAcc@5 96.875 (99.148)\n",
            "Epoch: [2][11/16]\tTime 0.173 (0.170)\tData 0.002 (0.015)\tLoss 0.6012 (0.6069)\tAcc@1 81.250 (81.380)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [2][12/16]\tTime 0.166 (0.169)\tData 0.002 (0.014)\tLoss 0.5637 (0.6036)\tAcc@1 81.250 (81.370)\tAcc@5 100.000 (99.279)\n",
            "Epoch: [2][13/16]\tTime 0.154 (0.168)\tData 0.002 (0.013)\tLoss 0.3560 (0.5859)\tAcc@1 89.062 (81.920)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [2][14/16]\tTime 0.156 (0.168)\tData 0.002 (0.012)\tLoss 0.5785 (0.5854)\tAcc@1 84.375 (82.083)\tAcc@5 98.438 (99.167)\n",
            "Epoch: [2][15/16]\tTime 0.108 (0.164)\tData 0.003 (0.011)\tLoss 0.9005 (0.5980)\tAcc@1 77.500 (81.900)\tAcc@5 92.500 (98.900)\n",
            "Top classes:  tensor([5., 8., 8., 0., 5., 8., 5., 0., 5., 8., 0., 8., 5., 7., 8., 5., 3., 3.,\n",
            "        8., 5., 3., 0., 8., 3., 4., 8., 2., 0., 3., 4., 4., 4., 0., 3., 8., 3.,\n",
            "        4., 3., 3., 5., 0., 4., 5., 5., 8., 5., 5., 5., 4., 8., 8., 8., 3., 8.,\n",
            "        8., 8., 5., 5., 5., 4., 5., 5., 5., 8., 5., 5., 8., 2., 8., 8., 0., 5.,\n",
            "        8., 8., 8., 0., 0., 5., 5., 8., 0., 3., 8., 5., 0., 2., 5., 8., 8., 8.,\n",
            "        0., 5., 8., 6., 8., 5., 5., 0., 0., 3.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.2500, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 40.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 40.00%\n",
            "apgd-ce - 1/1 - 4 out of 8 successfully perturbed\n",
            "robust accuracy after APGD-CE: 20.00% (total time 17.9 s)\n",
            "apgd-dlr - 1/1 - 0 out of 4 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 20.00% (total time 33.0 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 20.00%\n",
            "Adversarial accuracy: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMA Training: Direct Input Space Margin Maximization through Adversarial Training (WideResNet-28-4)"
      ],
      "metadata": {
        "id": "I2nOuLxdeSz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2"
      ],
      "metadata": {
        "id": "R-6Nq9NPJ_Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_L2 = load_configure_model(name='Ding2020MMA', dataset='cifar10', threat_model='L2', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_3_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_3_L2 = train_model(trainloader, testloader, model_3_L2, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_3_L2, sigma, x_test, y_test, 'L2', ThreatModel.L2, n_examples, eps_L2, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "SA8WQsoZeWIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4d9e89-4e2d-4a5f-8a53-308994ebe1b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/L2/Ding2020MMA.pt (gdrive_id=13wgY0Q_eor52ltZ0PkfJx5BCZ8cLM52E).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13wgY0Q_eor52ltZ0PkfJx5BCZ8cLM52E\n",
            "To: /content/models/cifar10/L2/Ding2020MMA.pt\n",
            "100%|██████████| 23.4M/23.4M [00:01<00:00, 20.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top classes:  tensor([6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
            "        6., 6., 6., 2., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
            "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
            "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
            "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
            "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.1600, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 95.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 95.00%\n",
            "apgd-ce - 1/1 - 4 out of 19 successfully perturbed\n",
            "robust accuracy after APGD-CE: 75.00% (total time 7.5 s)\n",
            "apgd-dlr - 1/1 - 0 out of 15 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 75.00% (total time 14.8 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 75.00%\n",
            "Adversarial accuracy: 75.00%\n",
            "Epoch: [0][0/16]\tTime 0.234 (0.234)\tData 0.162 (0.162)\tLoss 1.0728 (1.0728)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.050 (0.142)\tData 0.003 (0.083)\tLoss 0.8232 (0.9480)\tAcc@1 76.562 (78.125)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [0][2/16]\tTime 0.071 (0.118)\tData 0.003 (0.056)\tLoss 0.7356 (0.8772)\tAcc@1 84.375 (80.208)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][3/16]\tTime 0.070 (0.106)\tData 0.003 (0.043)\tLoss 0.6216 (0.8133)\tAcc@1 82.812 (80.859)\tAcc@5 100.000 (98.828)\n",
            "Epoch: [0][4/16]\tTime 0.071 (0.099)\tData 0.002 (0.035)\tLoss 0.9078 (0.8322)\tAcc@1 82.812 (81.250)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][5/16]\tTime 0.071 (0.094)\tData 0.003 (0.029)\tLoss 0.8019 (0.8272)\tAcc@1 79.688 (80.990)\tAcc@5 100.000 (98.698)\n",
            "Epoch: [0][6/16]\tTime 0.073 (0.091)\tData 0.003 (0.026)\tLoss 0.8407 (0.8291)\tAcc@1 79.688 (80.804)\tAcc@5 95.312 (98.214)\n",
            "Epoch: [0][7/16]\tTime 0.071 (0.089)\tData 0.002 (0.023)\tLoss 0.6216 (0.8032)\tAcc@1 82.812 (81.055)\tAcc@5 98.438 (98.242)\n",
            "Epoch: [0][8/16]\tTime 0.071 (0.087)\tData 0.002 (0.020)\tLoss 1.2191 (0.8494)\tAcc@1 76.562 (80.556)\tAcc@5 96.875 (98.090)\n",
            "Epoch: [0][9/16]\tTime 0.074 (0.086)\tData 0.002 (0.019)\tLoss 0.5895 (0.8234)\tAcc@1 82.812 (80.781)\tAcc@5 98.438 (98.125)\n",
            "Epoch: [0][10/16]\tTime 0.073 (0.084)\tData 0.002 (0.017)\tLoss 0.7289 (0.8148)\tAcc@1 78.125 (80.540)\tAcc@5 96.875 (98.011)\n",
            "Epoch: [0][11/16]\tTime 0.068 (0.083)\tData 0.009 (0.016)\tLoss 0.7036 (0.8055)\tAcc@1 76.562 (80.208)\tAcc@5 100.000 (98.177)\n",
            "Epoch: [0][12/16]\tTime 0.081 (0.083)\tData 0.002 (0.015)\tLoss 0.6267 (0.7918)\tAcc@1 85.938 (80.649)\tAcc@5 100.000 (98.317)\n",
            "Epoch: [0][13/16]\tTime 0.090 (0.083)\tData 0.002 (0.014)\tLoss 0.8486 (0.7958)\tAcc@1 78.125 (80.469)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][14/16]\tTime 0.072 (0.083)\tData 0.003 (0.014)\tLoss 0.8164 (0.7972)\tAcc@1 73.438 (80.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][15/16]\tTime 0.071 (0.082)\tData 0.002 (0.013)\tLoss 1.0635 (0.8079)\tAcc@1 75.000 (79.800)\tAcc@5 95.000 (98.300)\n",
            "Epoch: [0][0/16]\tTime 0.191 (0.191)\tData 0.161 (0.161)\tLoss 0.8547 (0.8547)\tAcc@1 75.000 (75.000)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [0][1/16]\tTime 0.026 (0.109)\tData 0.005 (0.083)\tLoss 0.9476 (0.9011)\tAcc@1 78.125 (76.562)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [0][2/16]\tTime 0.023 (0.080)\tData 0.001 (0.056)\tLoss 1.1451 (0.9825)\tAcc@1 75.000 (76.042)\tAcc@5 98.438 (97.396)\n",
            "Epoch: [0][3/16]\tTime 0.024 (0.066)\tData 0.003 (0.042)\tLoss 0.8575 (0.9512)\tAcc@1 79.688 (76.953)\tAcc@5 96.875 (97.266)\n",
            "Epoch: [0][4/16]\tTime 0.024 (0.057)\tData 0.002 (0.034)\tLoss 1.0511 (0.9712)\tAcc@1 75.000 (76.562)\tAcc@5 98.438 (97.500)\n",
            "Epoch: [0][5/16]\tTime 0.023 (0.052)\tData 0.002 (0.029)\tLoss 1.2661 (1.0203)\tAcc@1 73.438 (76.042)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [0][6/16]\tTime 0.024 (0.048)\tData 0.002 (0.025)\tLoss 1.0239 (1.0209)\tAcc@1 75.000 (75.893)\tAcc@5 98.438 (97.768)\n",
            "Epoch: [0][7/16]\tTime 0.024 (0.045)\tData 0.002 (0.022)\tLoss 0.9725 (1.0148)\tAcc@1 70.312 (75.195)\tAcc@5 100.000 (98.047)\n",
            "Epoch: [0][8/16]\tTime 0.024 (0.042)\tData 0.002 (0.020)\tLoss 0.7577 (0.9862)\tAcc@1 84.375 (76.215)\tAcc@5 98.438 (98.090)\n",
            "Epoch: [0][9/16]\tTime 0.024 (0.041)\tData 0.002 (0.018)\tLoss 1.0686 (0.9945)\tAcc@1 75.000 (76.094)\tAcc@5 98.438 (98.125)\n",
            "Epoch: [0][10/16]\tTime 0.024 (0.039)\tData 0.003 (0.017)\tLoss 1.4692 (1.0376)\tAcc@1 65.625 (75.142)\tAcc@5 96.875 (98.011)\n",
            "Epoch: [0][11/16]\tTime 0.023 (0.038)\tData 0.002 (0.016)\tLoss 0.7138 (1.0107)\tAcc@1 81.250 (75.651)\tAcc@5 98.438 (98.047)\n",
            "Epoch: [0][12/16]\tTime 0.024 (0.037)\tData 0.002 (0.015)\tLoss 1.3473 (1.0366)\tAcc@1 65.625 (74.880)\tAcc@5 96.875 (97.957)\n",
            "Epoch: [0][13/16]\tTime 0.024 (0.036)\tData 0.002 (0.014)\tLoss 1.0902 (1.0404)\tAcc@1 71.875 (74.665)\tAcc@5 96.875 (97.879)\n",
            "Epoch: [0][14/16]\tTime 0.024 (0.035)\tData 0.003 (0.013)\tLoss 0.8663 (1.0288)\tAcc@1 73.438 (74.583)\tAcc@5 96.875 (97.812)\n",
            "Epoch: [0][15/16]\tTime 0.018 (0.034)\tData 0.002 (0.012)\tLoss 0.6517 (1.0137)\tAcc@1 82.500 (74.900)\tAcc@5 97.500 (97.800)\n",
            "Epoch: [1][0/16]\tTime 0.227 (0.227)\tData 0.159 (0.159)\tLoss 1.0602 (1.0602)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [1][1/16]\tTime 0.056 (0.142)\tData 0.012 (0.085)\tLoss 1.0930 (1.0766)\tAcc@1 75.000 (76.562)\tAcc@5 93.750 (96.094)\n",
            "Epoch: [1][2/16]\tTime 0.070 (0.118)\tData 0.001 (0.057)\tLoss 0.9258 (1.0263)\tAcc@1 84.375 (79.167)\tAcc@5 95.312 (95.833)\n",
            "Epoch: [1][3/16]\tTime 0.071 (0.106)\tData 0.009 (0.045)\tLoss 0.3708 (0.8625)\tAcc@1 89.062 (81.641)\tAcc@5 100.000 (96.875)\n",
            "Epoch: [1][4/16]\tTime 0.070 (0.099)\tData 0.001 (0.036)\tLoss 1.0468 (0.8993)\tAcc@1 81.250 (81.562)\tAcc@5 93.750 (96.250)\n",
            "Epoch: [1][5/16]\tTime 0.071 (0.094)\tData 0.013 (0.033)\tLoss 1.1458 (0.9404)\tAcc@1 76.562 (80.729)\tAcc@5 95.312 (96.094)\n",
            "Epoch: [1][6/16]\tTime 0.072 (0.091)\tData 0.002 (0.028)\tLoss 0.8380 (0.9258)\tAcc@1 78.125 (80.357)\tAcc@5 96.875 (96.205)\n",
            "Epoch: [1][7/16]\tTime 0.070 (0.089)\tData 0.002 (0.025)\tLoss 0.8294 (0.9137)\tAcc@1 79.688 (80.273)\tAcc@5 98.438 (96.484)\n",
            "Epoch: [1][8/16]\tTime 0.072 (0.087)\tData 0.009 (0.023)\tLoss 0.7366 (0.8940)\tAcc@1 79.688 (80.208)\tAcc@5 98.438 (96.701)\n",
            "Epoch: [1][9/16]\tTime 0.077 (0.086)\tData 0.003 (0.021)\tLoss 0.8017 (0.8848)\tAcc@1 84.375 (80.625)\tAcc@5 100.000 (97.031)\n",
            "Epoch: [1][10/16]\tTime 0.077 (0.085)\tData 0.006 (0.020)\tLoss 0.5921 (0.8582)\tAcc@1 87.500 (81.250)\tAcc@5 98.438 (97.159)\n",
            "Epoch: [1][11/16]\tTime 0.066 (0.083)\tData 0.016 (0.019)\tLoss 0.6680 (0.8424)\tAcc@1 84.375 (81.510)\tAcc@5 98.438 (97.266)\n",
            "Epoch: [1][12/16]\tTime 0.090 (0.084)\tData 0.003 (0.018)\tLoss 0.4771 (0.8143)\tAcc@1 87.500 (81.971)\tAcc@5 98.438 (97.356)\n",
            "Epoch: [1][13/16]\tTime 0.080 (0.084)\tData 0.002 (0.017)\tLoss 0.5429 (0.7949)\tAcc@1 81.250 (81.920)\tAcc@5 100.000 (97.545)\n",
            "Epoch: [1][14/16]\tTime 0.072 (0.083)\tData 0.003 (0.016)\tLoss 0.9145 (0.8029)\tAcc@1 76.562 (81.562)\tAcc@5 98.438 (97.604)\n",
            "Epoch: [1][15/16]\tTime 0.065 (0.082)\tData 0.002 (0.015)\tLoss 0.9748 (0.8097)\tAcc@1 77.500 (81.400)\tAcc@5 95.000 (97.500)\n",
            "Epoch: [1][0/16]\tTime 0.248 (0.248)\tData 0.214 (0.214)\tLoss 0.8611 (0.8611)\tAcc@1 75.000 (75.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.044 (0.146)\tData 0.017 (0.115)\tLoss 0.7159 (0.7885)\tAcc@1 84.375 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][2/16]\tTime 0.035 (0.109)\tData 0.005 (0.079)\tLoss 1.0139 (0.8636)\tAcc@1 73.438 (77.604)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.040 (0.092)\tData 0.004 (0.060)\tLoss 0.8546 (0.8614)\tAcc@1 78.125 (77.734)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [1][4/16]\tTime 0.028 (0.079)\tData 0.002 (0.048)\tLoss 1.1877 (0.9266)\tAcc@1 75.000 (77.188)\tAcc@5 98.438 (99.375)\n",
            "Epoch: [1][5/16]\tTime 0.035 (0.072)\tData 0.007 (0.042)\tLoss 1.1590 (0.9653)\tAcc@1 79.688 (77.604)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [1][6/16]\tTime 0.047 (0.068)\tData 0.015 (0.038)\tLoss 0.9192 (0.9588)\tAcc@1 73.438 (77.009)\tAcc@5 100.000 (99.107)\n",
            "Epoch: [1][7/16]\tTime 0.032 (0.064)\tData 0.005 (0.034)\tLoss 0.3512 (0.8828)\tAcc@1 87.500 (78.320)\tAcc@5 100.000 (99.219)\n",
            "Epoch: [1][8/16]\tTime 0.032 (0.060)\tData 0.008 (0.031)\tLoss 0.7496 (0.8680)\tAcc@1 81.250 (78.646)\tAcc@5 96.875 (98.958)\n",
            "Epoch: [1][9/16]\tTime 0.034 (0.058)\tData 0.006 (0.028)\tLoss 0.6459 (0.8458)\tAcc@1 84.375 (79.219)\tAcc@5 100.000 (99.062)\n",
            "Epoch: [1][10/16]\tTime 0.032 (0.055)\tData 0.004 (0.026)\tLoss 0.9416 (0.8545)\tAcc@1 79.688 (79.261)\tAcc@5 93.750 (98.580)\n",
            "Epoch: [1][11/16]\tTime 0.033 (0.053)\tData 0.007 (0.025)\tLoss 0.7336 (0.8444)\tAcc@1 82.812 (79.557)\tAcc@5 98.438 (98.568)\n",
            "Epoch: [1][12/16]\tTime 0.023 (0.051)\tData 0.002 (0.023)\tLoss 0.8159 (0.8422)\tAcc@1 78.125 (79.447)\tAcc@5 98.438 (98.558)\n",
            "Epoch: [1][13/16]\tTime 0.024 (0.049)\tData 0.002 (0.021)\tLoss 0.9772 (0.8519)\tAcc@1 73.438 (79.018)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [1][14/16]\tTime 0.024 (0.047)\tData 0.002 (0.020)\tLoss 0.7157 (0.8428)\tAcc@1 73.438 (78.646)\tAcc@5 100.000 (98.542)\n",
            "Epoch: [1][15/16]\tTime 0.018 (0.046)\tData 0.002 (0.019)\tLoss 0.8584 (0.8434)\tAcc@1 82.500 (78.800)\tAcc@5 95.000 (98.400)\n",
            "Epoch: [2][0/16]\tTime 0.276 (0.276)\tData 0.202 (0.202)\tLoss 0.6229 (0.6229)\tAcc@1 82.812 (82.812)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][1/16]\tTime 0.064 (0.170)\tData 0.004 (0.103)\tLoss 0.7320 (0.6775)\tAcc@1 79.688 (81.250)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [2][2/16]\tTime 0.070 (0.137)\tData 0.003 (0.070)\tLoss 1.0603 (0.8051)\tAcc@1 76.562 (79.688)\tAcc@5 98.438 (99.479)\n",
            "Epoch: [2][3/16]\tTime 0.075 (0.121)\tData 0.002 (0.053)\tLoss 0.8439 (0.8148)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (99.609)\n",
            "Epoch: [2][4/16]\tTime 0.067 (0.110)\tData 0.003 (0.043)\tLoss 0.9062 (0.8331)\tAcc@1 79.688 (79.688)\tAcc@5 93.750 (98.438)\n",
            "Epoch: [2][5/16]\tTime 0.071 (0.104)\tData 0.002 (0.036)\tLoss 0.4906 (0.7760)\tAcc@1 90.625 (81.510)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][6/16]\tTime 0.079 (0.100)\tData 0.002 (0.031)\tLoss 1.0843 (0.8200)\tAcc@1 78.125 (81.027)\tAcc@5 96.875 (98.214)\n",
            "Epoch: [2][7/16]\tTime 0.067 (0.096)\tData 0.003 (0.028)\tLoss 0.4861 (0.7783)\tAcc@1 87.500 (81.836)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [2][8/16]\tTime 0.067 (0.093)\tData 0.002 (0.025)\tLoss 0.5930 (0.7577)\tAcc@1 81.250 (81.771)\tAcc@5 100.000 (98.611)\n",
            "Epoch: [2][9/16]\tTime 0.074 (0.091)\tData 0.002 (0.023)\tLoss 1.1853 (0.8005)\tAcc@1 76.562 (81.250)\tAcc@5 98.438 (98.594)\n",
            "Epoch: [2][10/16]\tTime 0.068 (0.089)\tData 0.002 (0.021)\tLoss 0.9550 (0.8145)\tAcc@1 82.812 (81.392)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [2][11/16]\tTime 0.072 (0.088)\tData 0.003 (0.019)\tLoss 0.5593 (0.7932)\tAcc@1 85.938 (81.771)\tAcc@5 100.000 (98.568)\n",
            "Epoch: [2][12/16]\tTime 0.086 (0.087)\tData 0.002 (0.018)\tLoss 0.9716 (0.8070)\tAcc@1 71.875 (81.010)\tAcc@5 95.312 (98.317)\n",
            "Epoch: [2][13/16]\tTime 0.084 (0.087)\tData 0.002 (0.017)\tLoss 1.0491 (0.8243)\tAcc@1 76.562 (80.692)\tAcc@5 95.312 (98.103)\n",
            "Epoch: [2][14/16]\tTime 0.073 (0.086)\tData 0.002 (0.016)\tLoss 0.4586 (0.7999)\tAcc@1 87.500 (81.146)\tAcc@5 100.000 (98.229)\n",
            "Epoch: [2][15/16]\tTime 0.065 (0.085)\tData 0.002 (0.015)\tLoss 0.9872 (0.8074)\tAcc@1 70.000 (80.700)\tAcc@5 97.500 (98.200)\n",
            "Epoch: [2][0/16]\tTime 0.193 (0.193)\tData 0.171 (0.171)\tLoss 0.7225 (0.7225)\tAcc@1 82.812 (82.812)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [2][1/16]\tTime 0.026 (0.110)\tData 0.005 (0.088)\tLoss 0.6414 (0.6820)\tAcc@1 84.375 (83.594)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [2][2/16]\tTime 0.026 (0.082)\tData 0.005 (0.060)\tLoss 1.2490 (0.8710)\tAcc@1 67.188 (78.125)\tAcc@5 98.438 (97.917)\n",
            "Epoch: [2][3/16]\tTime 0.036 (0.070)\tData 0.013 (0.048)\tLoss 0.9003 (0.8783)\tAcc@1 81.250 (78.906)\tAcc@5 95.312 (97.266)\n",
            "Epoch: [2][4/16]\tTime 0.025 (0.061)\tData 0.002 (0.039)\tLoss 1.0052 (0.9037)\tAcc@1 75.000 (78.125)\tAcc@5 95.312 (96.875)\n",
            "Epoch: [2][5/16]\tTime 0.031 (0.056)\tData 0.010 (0.034)\tLoss 1.0432 (0.9269)\tAcc@1 82.812 (78.906)\tAcc@5 93.750 (96.354)\n",
            "Epoch: [2][6/16]\tTime 0.026 (0.052)\tData 0.005 (0.030)\tLoss 0.8027 (0.9092)\tAcc@1 84.375 (79.688)\tAcc@5 100.000 (96.875)\n",
            "Epoch: [2][7/16]\tTime 0.023 (0.048)\tData 0.002 (0.027)\tLoss 0.4136 (0.8472)\tAcc@1 89.062 (80.859)\tAcc@5 100.000 (97.266)\n",
            "Epoch: [2][8/16]\tTime 0.031 (0.046)\tData 0.007 (0.025)\tLoss 0.4910 (0.8077)\tAcc@1 85.938 (81.424)\tAcc@5 100.000 (97.569)\n",
            "Epoch: [2][9/16]\tTime 0.024 (0.044)\tData 0.003 (0.022)\tLoss 0.9388 (0.8208)\tAcc@1 84.375 (81.719)\tAcc@5 100.000 (97.812)\n",
            "Epoch: [2][10/16]\tTime 0.023 (0.042)\tData 0.002 (0.021)\tLoss 1.2387 (0.8588)\tAcc@1 76.562 (81.250)\tAcc@5 95.312 (97.585)\n",
            "Epoch: [2][11/16]\tTime 0.024 (0.041)\tData 0.002 (0.019)\tLoss 0.8994 (0.8622)\tAcc@1 78.125 (80.990)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [2][12/16]\tTime 0.023 (0.039)\tData 0.002 (0.018)\tLoss 1.0524 (0.8768)\tAcc@1 76.562 (80.649)\tAcc@5 96.875 (97.596)\n",
            "Epoch: [2][13/16]\tTime 0.023 (0.038)\tData 0.002 (0.017)\tLoss 0.7370 (0.8668)\tAcc@1 78.125 (80.469)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [2][14/16]\tTime 0.023 (0.037)\tData 0.002 (0.016)\tLoss 0.7017 (0.8558)\tAcc@1 81.250 (80.521)\tAcc@5 98.438 (97.708)\n",
            "Epoch: [2][15/16]\tTime 0.017 (0.036)\tData 0.002 (0.015)\tLoss 0.7629 (0.8521)\tAcc@1 82.500 (80.600)\tAcc@5 97.500 (97.700)\n",
            "Top classes:  tensor([5., 9., 9., 4., 6., 6., 1., 4., 6., 9., 4., 9., 4., 7., 9., 8., 3., 3.,\n",
            "        9., 6., 6., 2., 2., 9., 4., 4., 4., 4., 9., 6., 6., 4., 4., 5., 9., 6.,\n",
            "        6., 9., 9., 4., 4., 6., 5., 6., 4., 9., 3., 3., 4., 6., 9., 4., 6., 3.,\n",
            "        8., 6., 6., 4., 6., 4., 4., 3., 6., 9., 6., 6., 6., 2., 3., 6., 6., 6.,\n",
            "        6., 9., 4., 2., 6., 3., 6., 8., 6., 9., 6., 7., 2., 4., 2., 4., 8., 6.,\n",
            "        0., 4., 8., 6., 6., 6., 6., 6., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.4700, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 85.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 85.00%\n",
            "apgd-ce - 1/1 - 11 out of 17 successfully perturbed\n",
            "robust accuracy after APGD-CE: 30.00% (total time 5.5 s)\n",
            "apgd-dlr - 1/1 - 0 out of 6 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 30.00% (total time 11.3 s)\n",
            "max L2 perturbation: 0.50000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 30.00%\n",
            "Adversarial accuracy: 30.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linf"
      ],
      "metadata": {
        "id": "n4dNHMZQKP9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading\n",
        "model_3_Linf = load_configure_model(name='Ding2020MMA', dataset='cifar10', threat_model='Linf', device=device)\n",
        "\n",
        "# Test on stock model\n",
        "test_model(model_3_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)\n",
        "\n",
        "# Smoothed model training\n",
        "smoothed_model_3_Linf = train_model(trainloader, testloader, model_3_Linf, epochs, sigma, device)\n",
        "\n",
        "# Test on smoothed model\n",
        "test_model(smoothed_model_3_Linf, sigma, x_test, y_test, 'Linf', ThreatModel.Linf, n_examples, eps_Linf, batch_size, device, version, attacks_to_run)"
      ],
      "metadata": {
        "id": "DbXlugPutzr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bef5a8-55b0-4a7e-9aa3-9f4135bcc45f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Ding2020MMA.pt (gdrive_id=19Q_rIIHXsYzxZ0WcZdqT-N2OD7MfgoZ0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19Q_rIIHXsYzxZ0WcZdqT-N2OD7MfgoZ0\n",
            "To: /content/models/cifar10/Linf/Ding2020MMA.pt\n",
            "100%|██████████| 23.4M/23.4M [00:01<00:00, 19.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top classes:  tensor([6., 8., 0., 8., 6., 6., 6., 6., 6., 6., 6., 6., 6., 7., 6., 6., 6., 6.,\n",
            "        8., 6., 6., 2., 0., 9., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 9., 6.,\n",
            "        6., 6., 9., 6., 6., 6., 6., 6., 0., 9., 6., 6., 6., 6., 2., 6., 6., 6.,\n",
            "        8., 8., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 0., 6., 6., 6., 6.,\n",
            "        6., 8., 6., 6., 6., 6., 6., 6., 6., 1., 1., 7., 2., 6., 2., 6., 6., 6.,\n",
            "        0., 6., 8., 6., 6., 6., 6., 8., 0., 6.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.3500, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 95.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 95.00%\n",
            "apgd-ce - 1/1 - 12 out of 19 successfully perturbed\n",
            "robust accuracy after APGD-CE: 35.00% (total time 5.4 s)\n",
            "apgd-dlr - 1/1 - 0 out of 7 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 35.00% (total time 11.1 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 35.00%\n",
            "Adversarial accuracy: 35.00%\n",
            "Epoch: [0][0/16]\tTime 0.211 (0.211)\tData 0.171 (0.171)\tLoss 0.8740 (0.8740)\tAcc@1 73.438 (73.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [0][1/16]\tTime 0.060 (0.135)\tData 0.003 (0.087)\tLoss 1.3261 (1.1000)\tAcc@1 76.562 (75.000)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.071 (0.114)\tData 0.002 (0.059)\tLoss 0.6045 (0.9349)\tAcc@1 84.375 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][3/16]\tTime 0.071 (0.103)\tData 0.002 (0.045)\tLoss 1.0341 (0.9597)\tAcc@1 71.875 (76.562)\tAcc@5 95.312 (97.656)\n",
            "Epoch: [0][4/16]\tTime 0.071 (0.097)\tData 0.004 (0.036)\tLoss 0.9853 (0.9648)\tAcc@1 78.125 (76.875)\tAcc@5 98.438 (97.812)\n",
            "Epoch: [0][5/16]\tTime 0.071 (0.092)\tData 0.003 (0.031)\tLoss 1.3698 (1.0323)\tAcc@1 70.312 (75.781)\tAcc@5 95.312 (97.396)\n",
            "Epoch: [0][6/16]\tTime 0.071 (0.089)\tData 0.002 (0.027)\tLoss 0.6931 (0.9839)\tAcc@1 85.938 (77.232)\tAcc@5 96.875 (97.321)\n",
            "Epoch: [0][7/16]\tTime 0.071 (0.087)\tData 0.002 (0.024)\tLoss 1.4187 (1.0382)\tAcc@1 70.312 (76.367)\tAcc@5 95.312 (97.070)\n",
            "Epoch: [0][8/16]\tTime 0.073 (0.085)\tData 0.002 (0.021)\tLoss 0.4959 (0.9779)\tAcc@1 84.375 (77.257)\tAcc@5 100.000 (97.396)\n",
            "Epoch: [0][9/16]\tTime 0.070 (0.084)\tData 0.002 (0.019)\tLoss 0.7440 (0.9546)\tAcc@1 78.125 (77.344)\tAcc@5 96.875 (97.344)\n",
            "Epoch: [0][10/16]\tTime 0.072 (0.083)\tData 0.002 (0.018)\tLoss 0.8565 (0.9456)\tAcc@1 79.688 (77.557)\tAcc@5 98.438 (97.443)\n",
            "Epoch: [0][11/16]\tTime 0.071 (0.082)\tData 0.002 (0.016)\tLoss 0.9558 (0.9465)\tAcc@1 75.000 (77.344)\tAcc@5 95.312 (97.266)\n",
            "Epoch: [0][12/16]\tTime 0.077 (0.081)\tData 0.002 (0.015)\tLoss 1.0549 (0.9548)\tAcc@1 75.000 (77.163)\tAcc@5 93.750 (96.995)\n",
            "Epoch: [0][13/16]\tTime 0.087 (0.082)\tData 0.002 (0.014)\tLoss 0.8779 (0.9493)\tAcc@1 82.812 (77.567)\tAcc@5 96.875 (96.987)\n",
            "Epoch: [0][14/16]\tTime 0.071 (0.081)\tData 0.002 (0.014)\tLoss 0.7390 (0.9353)\tAcc@1 79.688 (77.708)\tAcc@5 98.438 (97.083)\n",
            "Epoch: [0][15/16]\tTime 0.065 (0.080)\tData 0.002 (0.013)\tLoss 1.5288 (0.9591)\tAcc@1 70.000 (77.400)\tAcc@5 97.500 (97.100)\n",
            "Epoch: [0][0/16]\tTime 0.177 (0.177)\tData 0.155 (0.155)\tLoss 0.7578 (0.7578)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][1/16]\tTime 0.033 (0.105)\tData 0.013 (0.084)\tLoss 0.8329 (0.7953)\tAcc@1 73.438 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [0][2/16]\tTime 0.022 (0.077)\tData 0.001 (0.056)\tLoss 1.0876 (0.8927)\tAcc@1 78.125 (77.083)\tAcc@5 100.000 (98.958)\n",
            "Epoch: [0][3/16]\tTime 0.024 (0.064)\tData 0.003 (0.043)\tLoss 1.1338 (0.9530)\tAcc@1 75.000 (76.562)\tAcc@5 95.312 (98.047)\n",
            "Epoch: [0][4/16]\tTime 0.024 (0.056)\tData 0.002 (0.035)\tLoss 0.9753 (0.9575)\tAcc@1 73.438 (75.938)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [0][5/16]\tTime 0.024 (0.051)\tData 0.002 (0.029)\tLoss 1.1912 (0.9964)\tAcc@1 76.562 (76.042)\tAcc@5 96.875 (98.177)\n",
            "Epoch: [0][6/16]\tTime 0.025 (0.047)\tData 0.003 (0.026)\tLoss 1.0350 (1.0019)\tAcc@1 75.000 (75.893)\tAcc@5 98.438 (98.214)\n",
            "Epoch: [0][7/16]\tTime 0.031 (0.045)\tData 0.006 (0.023)\tLoss 0.9003 (0.9892)\tAcc@1 78.125 (76.172)\tAcc@5 98.438 (98.242)\n",
            "Epoch: [0][8/16]\tTime 0.023 (0.043)\tData 0.003 (0.021)\tLoss 1.0412 (0.9950)\tAcc@1 71.875 (75.694)\tAcc@5 96.875 (98.090)\n",
            "Epoch: [0][9/16]\tTime 0.024 (0.041)\tData 0.003 (0.019)\tLoss 0.9602 (0.9915)\tAcc@1 78.125 (75.938)\tAcc@5 100.000 (98.281)\n",
            "Epoch: [0][10/16]\tTime 0.024 (0.039)\tData 0.002 (0.017)\tLoss 1.4200 (1.0305)\tAcc@1 64.062 (74.858)\tAcc@5 96.875 (98.153)\n",
            "Epoch: [0][11/16]\tTime 0.024 (0.038)\tData 0.002 (0.016)\tLoss 0.7921 (1.0106)\tAcc@1 81.250 (75.391)\tAcc@5 98.438 (98.177)\n",
            "Epoch: [0][12/16]\tTime 0.023 (0.037)\tData 0.002 (0.015)\tLoss 1.2197 (1.0267)\tAcc@1 68.750 (74.880)\tAcc@5 93.750 (97.837)\n",
            "Epoch: [0][13/16]\tTime 0.023 (0.036)\tData 0.002 (0.014)\tLoss 0.8842 (1.0165)\tAcc@1 76.562 (75.000)\tAcc@5 96.875 (97.768)\n",
            "Epoch: [0][14/16]\tTime 0.023 (0.035)\tData 0.002 (0.013)\tLoss 0.6382 (0.9913)\tAcc@1 85.938 (75.729)\tAcc@5 95.312 (97.604)\n",
            "Epoch: [0][15/16]\tTime 0.017 (0.034)\tData 0.002 (0.013)\tLoss 0.7767 (0.9827)\tAcc@1 77.500 (75.800)\tAcc@5 97.500 (97.600)\n",
            "Epoch: [1][0/16]\tTime 0.208 (0.208)\tData 0.165 (0.165)\tLoss 1.2107 (1.2107)\tAcc@1 71.875 (71.875)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [1][1/16]\tTime 0.063 (0.135)\tData 0.004 (0.085)\tLoss 0.8565 (1.0336)\tAcc@1 79.688 (75.781)\tAcc@5 96.875 (96.094)\n",
            "Epoch: [1][2/16]\tTime 0.072 (0.114)\tData 0.001 (0.057)\tLoss 0.8563 (0.9745)\tAcc@1 81.250 (77.604)\tAcc@5 98.438 (96.875)\n",
            "Epoch: [1][3/16]\tTime 0.077 (0.105)\tData 0.004 (0.043)\tLoss 0.9584 (0.9705)\tAcc@1 79.688 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [1][4/16]\tTime 0.066 (0.097)\tData 0.003 (0.035)\tLoss 1.3622 (1.0488)\tAcc@1 70.312 (76.562)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [1][5/16]\tTime 0.071 (0.093)\tData 0.002 (0.030)\tLoss 0.9994 (1.0406)\tAcc@1 75.000 (76.302)\tAcc@5 95.312 (96.615)\n",
            "Epoch: [1][6/16]\tTime 0.074 (0.090)\tData 0.002 (0.026)\tLoss 1.0322 (1.0394)\tAcc@1 76.562 (76.339)\tAcc@5 98.438 (96.875)\n",
            "Epoch: [1][7/16]\tTime 0.071 (0.088)\tData 0.003 (0.023)\tLoss 1.1804 (1.0570)\tAcc@1 75.000 (76.172)\tAcc@5 93.750 (96.484)\n",
            "Epoch: [1][8/16]\tTime 0.070 (0.086)\tData 0.003 (0.021)\tLoss 1.0000 (1.0507)\tAcc@1 76.562 (76.215)\tAcc@5 98.438 (96.701)\n",
            "Epoch: [1][9/16]\tTime 0.071 (0.084)\tData 0.002 (0.019)\tLoss 0.3479 (0.9804)\tAcc@1 89.062 (77.500)\tAcc@5 100.000 (97.031)\n",
            "Epoch: [1][10/16]\tTime 0.072 (0.083)\tData 0.003 (0.017)\tLoss 1.0059 (0.9827)\tAcc@1 75.000 (77.273)\tAcc@5 92.188 (96.591)\n",
            "Epoch: [1][11/16]\tTime 0.076 (0.083)\tData 0.002 (0.016)\tLoss 0.9383 (0.9790)\tAcc@1 75.000 (77.083)\tAcc@5 95.312 (96.484)\n",
            "Epoch: [1][12/16]\tTime 0.073 (0.082)\tData 0.002 (0.015)\tLoss 0.7984 (0.9651)\tAcc@1 78.125 (77.163)\tAcc@5 100.000 (96.755)\n",
            "Epoch: [1][13/16]\tTime 0.085 (0.082)\tData 0.002 (0.014)\tLoss 0.8615 (0.9577)\tAcc@1 81.250 (77.455)\tAcc@5 96.875 (96.763)\n",
            "Epoch: [1][14/16]\tTime 0.072 (0.081)\tData 0.002 (0.013)\tLoss 0.6708 (0.9386)\tAcc@1 85.938 (78.021)\tAcc@5 96.875 (96.771)\n",
            "Epoch: [1][15/16]\tTime 0.067 (0.081)\tData 0.002 (0.013)\tLoss 0.9088 (0.9374)\tAcc@1 77.500 (78.000)\tAcc@5 100.000 (96.900)\n",
            "Epoch: [1][0/16]\tTime 0.188 (0.188)\tData 0.156 (0.156)\tLoss 0.9275 (0.9275)\tAcc@1 71.875 (71.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [1][1/16]\tTime 0.027 (0.108)\tData 0.007 (0.082)\tLoss 0.8889 (0.9082)\tAcc@1 76.562 (74.219)\tAcc@5 98.438 (99.219)\n",
            "Epoch: [1][2/16]\tTime 0.022 (0.079)\tData 0.001 (0.055)\tLoss 0.8859 (0.9008)\tAcc@1 76.562 (75.000)\tAcc@5 100.000 (99.479)\n",
            "Epoch: [1][3/16]\tTime 0.023 (0.065)\tData 0.002 (0.042)\tLoss 0.6782 (0.8451)\tAcc@1 84.375 (77.344)\tAcc@5 96.875 (98.828)\n",
            "Epoch: [1][4/16]\tTime 0.023 (0.057)\tData 0.001 (0.034)\tLoss 0.9412 (0.8644)\tAcc@1 76.562 (77.188)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [1][5/16]\tTime 0.025 (0.051)\tData 0.003 (0.028)\tLoss 1.2029 (0.9208)\tAcc@1 75.000 (76.823)\tAcc@5 93.750 (97.917)\n",
            "Epoch: [1][6/16]\tTime 0.025 (0.048)\tData 0.003 (0.025)\tLoss 1.0221 (0.9353)\tAcc@1 76.562 (76.786)\tAcc@5 98.438 (97.991)\n",
            "Epoch: [1][7/16]\tTime 0.024 (0.045)\tData 0.002 (0.022)\tLoss 0.6369 (0.8980)\tAcc@1 84.375 (77.734)\tAcc@5 100.000 (98.242)\n",
            "Epoch: [1][8/16]\tTime 0.024 (0.042)\tData 0.002 (0.020)\tLoss 0.7621 (0.8829)\tAcc@1 79.688 (77.951)\tAcc@5 95.312 (97.917)\n",
            "Epoch: [1][9/16]\tTime 0.023 (0.041)\tData 0.002 (0.018)\tLoss 1.1683 (0.9114)\tAcc@1 75.000 (77.656)\tAcc@5 96.875 (97.812)\n",
            "Epoch: [1][10/16]\tTime 0.024 (0.039)\tData 0.003 (0.017)\tLoss 1.2854 (0.9454)\tAcc@1 70.312 (76.989)\tAcc@5 95.312 (97.585)\n",
            "Epoch: [1][11/16]\tTime 0.024 (0.038)\tData 0.002 (0.015)\tLoss 0.7675 (0.9306)\tAcc@1 76.562 (76.953)\tAcc@5 98.438 (97.656)\n",
            "Epoch: [1][12/16]\tTime 0.025 (0.037)\tData 0.003 (0.015)\tLoss 0.9782 (0.9342)\tAcc@1 75.000 (76.803)\tAcc@5 96.875 (97.596)\n",
            "Epoch: [1][13/16]\tTime 0.023 (0.036)\tData 0.002 (0.014)\tLoss 1.0567 (0.9430)\tAcc@1 79.688 (77.009)\tAcc@5 96.875 (97.545)\n",
            "Epoch: [1][14/16]\tTime 0.023 (0.035)\tData 0.002 (0.013)\tLoss 0.7425 (0.9296)\tAcc@1 82.812 (77.396)\tAcc@5 96.875 (97.500)\n",
            "Epoch: [1][15/16]\tTime 0.017 (0.034)\tData 0.002 (0.012)\tLoss 0.7958 (0.9243)\tAcc@1 80.000 (77.500)\tAcc@5 97.500 (97.500)\n",
            "Epoch: [2][0/16]\tTime 0.199 (0.199)\tData 0.154 (0.154)\tLoss 0.9580 (0.9580)\tAcc@1 78.125 (78.125)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [2][1/16]\tTime 0.061 (0.130)\tData 0.008 (0.081)\tLoss 1.3681 (1.1630)\tAcc@1 75.000 (76.562)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [2][2/16]\tTime 0.073 (0.111)\tData 0.001 (0.054)\tLoss 0.5624 (0.9628)\tAcc@1 84.375 (79.167)\tAcc@5 98.438 (96.354)\n",
            "Epoch: [2][3/16]\tTime 0.076 (0.102)\tData 0.002 (0.041)\tLoss 0.7432 (0.9079)\tAcc@1 81.250 (79.688)\tAcc@5 100.000 (97.266)\n",
            "Epoch: [2][4/16]\tTime 0.069 (0.095)\tData 0.001 (0.033)\tLoss 0.8509 (0.8965)\tAcc@1 81.250 (80.000)\tAcc@5 100.000 (97.812)\n",
            "Epoch: [2][5/16]\tTime 0.071 (0.091)\tData 0.002 (0.028)\tLoss 1.1783 (0.9435)\tAcc@1 73.438 (78.906)\tAcc@5 98.438 (97.917)\n",
            "Epoch: [2][6/16]\tTime 0.072 (0.089)\tData 0.002 (0.024)\tLoss 0.6479 (0.9013)\tAcc@1 85.938 (79.911)\tAcc@5 96.875 (97.768)\n",
            "Epoch: [2][7/16]\tTime 0.072 (0.087)\tData 0.003 (0.022)\tLoss 0.4007 (0.8387)\tAcc@1 92.188 (81.445)\tAcc@5 98.438 (97.852)\n",
            "Epoch: [2][8/16]\tTime 0.070 (0.085)\tData 0.002 (0.019)\tLoss 1.0522 (0.8624)\tAcc@1 78.125 (81.076)\tAcc@5 96.875 (97.743)\n",
            "Epoch: [2][9/16]\tTime 0.071 (0.083)\tData 0.002 (0.018)\tLoss 1.1059 (0.8868)\tAcc@1 76.562 (80.625)\tAcc@5 98.438 (97.812)\n",
            "Epoch: [2][10/16]\tTime 0.071 (0.082)\tData 0.002 (0.016)\tLoss 0.8879 (0.8869)\tAcc@1 81.250 (80.682)\tAcc@5 96.875 (97.727)\n",
            "Epoch: [2][11/16]\tTime 0.072 (0.081)\tData 0.002 (0.015)\tLoss 1.2606 (0.9180)\tAcc@1 70.312 (79.818)\tAcc@5 96.875 (97.656)\n",
            "Epoch: [2][12/16]\tTime 0.077 (0.081)\tData 0.002 (0.014)\tLoss 0.8533 (0.9130)\tAcc@1 76.562 (79.567)\tAcc@5 96.875 (97.596)\n",
            "Epoch: [2][13/16]\tTime 0.086 (0.081)\tData 0.002 (0.013)\tLoss 1.2122 (0.9344)\tAcc@1 73.438 (79.129)\tAcc@5 95.312 (97.433)\n",
            "Epoch: [2][14/16]\tTime 0.074 (0.081)\tData 0.002 (0.013)\tLoss 1.3693 (0.9634)\tAcc@1 73.438 (78.750)\tAcc@5 93.750 (97.188)\n",
            "Epoch: [2][15/16]\tTime 0.067 (0.080)\tData 0.002 (0.012)\tLoss 1.1609 (0.9713)\tAcc@1 75.000 (78.600)\tAcc@5 97.500 (97.200)\n",
            "Epoch: [2][0/16]\tTime 0.179 (0.179)\tData 0.153 (0.153)\tLoss 0.9150 (0.9150)\tAcc@1 79.688 (79.688)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [2][1/16]\tTime 0.026 (0.102)\tData 0.005 (0.079)\tLoss 0.8221 (0.8686)\tAcc@1 81.250 (80.469)\tAcc@5 100.000 (97.656)\n",
            "Epoch: [2][2/16]\tTime 0.022 (0.076)\tData 0.001 (0.053)\tLoss 0.7743 (0.8371)\tAcc@1 79.688 (80.208)\tAcc@5 100.000 (98.438)\n",
            "Epoch: [2][3/16]\tTime 0.024 (0.063)\tData 0.002 (0.040)\tLoss 0.6084 (0.7799)\tAcc@1 79.688 (80.078)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [2][4/16]\tTime 0.025 (0.055)\tData 0.003 (0.033)\tLoss 0.7788 (0.7797)\tAcc@1 78.125 (79.688)\tAcc@5 100.000 (98.750)\n",
            "Epoch: [2][5/16]\tTime 0.024 (0.050)\tData 0.003 (0.028)\tLoss 1.1857 (0.8474)\tAcc@1 76.562 (79.167)\tAcc@5 96.875 (98.438)\n",
            "Epoch: [2][6/16]\tTime 0.027 (0.047)\tData 0.005 (0.025)\tLoss 0.8955 (0.8543)\tAcc@1 78.125 (79.018)\tAcc@5 100.000 (98.661)\n",
            "Epoch: [2][7/16]\tTime 0.027 (0.044)\tData 0.005 (0.022)\tLoss 0.8209 (0.8501)\tAcc@1 79.688 (79.102)\tAcc@5 98.438 (98.633)\n",
            "Epoch: [2][8/16]\tTime 0.023 (0.042)\tData 0.002 (0.020)\tLoss 0.8023 (0.8448)\tAcc@1 81.250 (79.340)\tAcc@5 100.000 (98.785)\n",
            "Epoch: [2][9/16]\tTime 0.025 (0.040)\tData 0.002 (0.018)\tLoss 0.4651 (0.8068)\tAcc@1 89.062 (80.312)\tAcc@5 98.438 (98.750)\n",
            "Epoch: [2][10/16]\tTime 0.025 (0.039)\tData 0.003 (0.017)\tLoss 0.9276 (0.8178)\tAcc@1 71.875 (79.545)\tAcc@5 98.438 (98.722)\n",
            "Epoch: [2][11/16]\tTime 0.024 (0.038)\tData 0.003 (0.016)\tLoss 0.7843 (0.8150)\tAcc@1 79.688 (79.557)\tAcc@5 98.438 (98.698)\n",
            "Epoch: [2][12/16]\tTime 0.023 (0.036)\tData 0.002 (0.015)\tLoss 0.9586 (0.8260)\tAcc@1 78.125 (79.447)\tAcc@5 95.312 (98.438)\n",
            "Epoch: [2][13/16]\tTime 0.023 (0.035)\tData 0.002 (0.014)\tLoss 0.7600 (0.8213)\tAcc@1 82.812 (79.688)\tAcc@5 96.875 (98.326)\n",
            "Epoch: [2][14/16]\tTime 0.023 (0.035)\tData 0.002 (0.013)\tLoss 0.7913 (0.8193)\tAcc@1 84.375 (80.000)\tAcc@5 98.438 (98.333)\n",
            "Epoch: [2][15/16]\tTime 0.017 (0.034)\tData 0.002 (0.012)\tLoss 0.9129 (0.8231)\tAcc@1 80.000 (80.000)\tAcc@5 100.000 (98.400)\n",
            "Top classes:  tensor([3., 8., 8., 0., 6., 6., 9., 6., 3., 9., 0., 9., 4., 7., 9., 8., 5., 7.,\n",
            "        8., 6., 7., 0., 0., 9., 4., 2., 4., 0., 9., 6., 6., 5., 4., 3., 9., 2.,\n",
            "        4., 9., 9., 5., 4., 6., 5., 6., 0., 9., 3., 3., 7., 6., 9., 8., 0., 3.,\n",
            "        8., 8., 7., 7., 3., 2., 7., 5., 6., 9., 6., 2., 1., 2., 3., 9., 6., 6.,\n",
            "        8., 8., 0., 2., 9., 3., 4., 8., 8., 9., 1., 7., 2., 7., 2., 7., 8., 9.,\n",
            "        0., 4., 8., 6., 4., 6., 6., 8., 0., 7.], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Y classes:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7], device='cuda:0')\n",
            "Accuracy on smooth model:  tensor(0.8100, device='cuda:0', dtype=torch.float64)\n",
            "Files already downloaded and verified\n",
            "Clean accuracy: 75.00%\n",
            "using custom version including apgd-ce, apgd-dlr.\n",
            "initial accuracy: 75.00%\n",
            "apgd-ce - 1/1 - 13 out of 15 successfully perturbed\n",
            "robust accuracy after APGD-CE: 10.00% (total time 5.4 s)\n",
            "apgd-dlr - 1/1 - 0 out of 2 successfully perturbed\n",
            "robust accuracy after APGD-DLR: 10.00% (total time 10.2 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 10.00%\n",
            "Adversarial accuracy: 10.00%\n"
          ]
        }
      ]
    }
  ]
}